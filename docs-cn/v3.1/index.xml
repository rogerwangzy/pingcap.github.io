<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TiDB 简介 on SQL at Scale</title>
    <link>https://pingcap.com/docs-cn/v3.1/</link>
    <description>Recent content in TiDB 简介 on SQL at Scale</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://pingcap.com/docs-cn/v3.1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/v3.1/CONTRIBUTING/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/CONTRIBUTING/</guid>
      <description>TiDB 中文文档贡献指南 无论你是热爱技术的程序员，还是擅长书面表达的语言爱好者，亦或是纯粹想帮 TiDB 改进文档的热心小伙伴，都欢迎来为 TiDB 文档做贡献，一起打造更加易用友好的 TiDB 文档！
可贡献的内容 欢迎任何对提升 TiDB 文档质量、易用性、维护效率、翻译效率的贡献，比如，你可以在以下方面进行贡献：
 改进中文文档 翻译中文文档的更新 优化文档提交的流程、维护方式 建立 TiDB 文档的翻译记忆库、术语库  下面主要介绍了如何为前两项做出贡献。
改进中文文档 你可从以下任一方面入手：
 修复文档格式（如标点、空格、缩进、代码块等）和错别字 修改过时或不当的内容描述 增加缺失的文档内容 回复或解决 issue 并提 PR 更新相关文档 其它改进  翻译中文文档 TiDB 中文文档的日常更新特别活跃，相应地，TiDB 英文文档 也需要进行频繁的更新。这一过程会涉及很多的中译英，即将 pingcap/docs-cn 里已 merge 但尚未进行翻译处理的 Pull Request 翻译为英文，并提交 Pull Request 至 pingcap/docs 中。具体的认领方式如下。
 注意：
 由于受众不同，TiDB 的中文文档与英文文档并非完全相同。但绝大数情况下，中英版本会保持一致。 通常，TiDB 文档是先有中文版，后有英文版。但也有一小部分文档，是先有英文版，后有中文版。   中文翻译任务的认领方式 目前，中文文档翻译任务以 docs-cn 仓库的 Pull Request (PR) 为形式，通过仓库管理员为 PR 加上的 labels 来认领翻译任务、追踪翻译任务状态。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/v3.1/contributor-list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/contributor-list/</guid>
      <description>Docs SIG Contributor List NOTE:
 This contributor list is updated on a bi-weekly basis. Last update time: 2020-03-12  Contributors  shenli siddontang iamxy qiuyesuifeng nolouch huachaohuang disksing thinxer iroi44 zhangjinpeng1987 andelf wenfengwang tiancaiamao yuanwhy c4pt0r GregoryIan zimulala zhumengzhu overvenus qgxiaozhan ngaut wangyanjun weekface coocood xuechunL iamzhout winoros holys bobotu innerr LinuxGit skimmilk6877 sunhao2017 liubin zhexuany buggithubs queenypingcap choleraehyq breeswish zhzy0077 blacktear23 hicqu lilin90 liubo0127 zhengwanbo zz-jason XuHuaiyu winkyao lishuai87 hashbone lamxTyler hanfei1991 jackysp wentaoxu tshqin datahoecn atmzhou birdstorm WangXiangUSTC limitless083 Connor1996 yyf965 dbaoutdo tennix yanyanqing meyu44 lhyPingcap CaitinChen kangxiaoning jinsheng1995 sivagao MyonKeminta wsabc01 fipped yanchaozhong liukun4515 AndreMouche july2993 crazycs520 motian yikeke emhlbmc YiniXu9506 lerencao ahdong2007 rleungx oasangqi mccxj sweetIan exialin httpcheck ppiao kennytm bugwz beckxie ilovesoup dcalvin zzh1985 TomShawn KASSADAR TaoZhengCN xiekeyi98 bigzuo csuzhangxc tender-boluo pcqz ZhaoQi99 lysu reAsOn2010 IzabelWang anotherrachel lichunzhu onlymellb ericsyh aytrack amyangfei husiyu bb7133 erjiaqing huangxiuyan superlzs0476 spongedu lonng imtbkcat BigCodeLess aylei cofyc tangenta xiaojingchen DanielZhangQD shuijing198799 jebter zyguan shuke987 AstroProfundis lance6716 tptpp 3pointer marsishandsome scsldb WalterWj djshow832 juliezhang1112 wshwsh12 shonge Deardrops sydnever fzhedu lhy1024 francis0407 JaySon-Huang Yisaer zyh-hust yilongrong Win-Man King-Dylan Damon-PingCap lucklove llussy qiukun elvizlai suzaku foreyes youjiali1995 ichn-hu baiyuqing AilinKid leoppro together-wang 20100507 n0vad3v toutdesuite ran-huang wjhuang2016 kissmydb SunRunAway eurekaka Little-Wallace sticnarf sre-bot 5kbpers cosven qw4990 hjk0205  For details, see Contributors to pingcap/docs-cn.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/v3.1/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/README/</guid>
      <description>TiDB 文档 欢迎来到 TiDB 文档库！这里存放的是 PingCAP 官网 TiDB 中文文档的源文件。官网英文文档的源文件则存放于 pingcap/docs。如果你发现或遇到了 TiDB 的文档问题，可随时提 Issue 来反馈，或者直接提交 Pull Request 来进行修改。
TiDB 文档结构 目前，TiDB 的文档维护以下四个版本，分别放置在相应的 branch：
 master：最新开发版 release-3.1：3.1 Beta 版 release-3.0：最新稳定版 release-2.1：2.1 稳定版  TiDB 的文档结构如下：
├── TOC.md ├── how-to ├── get-started ├── deploy ├── orchestrated ├── ansible.md ├── offline-ansible.md ├── docker.md ├── configure ├── maintain ├── troubleshoot ├── ... ├── reference ├── tools ├── tidb-binlog ├── ... ├── releases ├── tidb-in-kubernetes ├── faq ├── .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/v3.1/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/TOC/</guid>
      <description>TiDB 中文用户文档 目录  关于 TiDB  TiDB 简介   Benchmark 测试  如何用 Sysbench 测试 TiDB 如何对 TiDB 进行 TPC-C 测试 Sysbench 性能对比 - v3.0 对比 v2.1 TPC-C 性能对比 - v3.0 对比 v2.1 线上负载与 Add Index 相互影响测试 TiDB in Kubernetes Sysbench 性能测试 DM 1.0-GA 性能测试     主要概念  整体架构   核心特性  水平扩展 高可用     操作指南  快速上手  创建集群  使用 Docker Compose 部署 TiDB 集群     SQL 基本操作 读取历史数据 TiDB Binlog 教程 TiDB Data Migration 教程 TiDB Lightning 教程 TiSpark 教程   部署  软硬件环境需求   集群部署方式  使用 Ansible 部署（推荐） 使用 Ansible 离线部署 使用 Docker 部署   跨地域冗余  跨数据中心部署方案 配置集群拓扑     使用 Ansible 部署 DM 集群   配置  时区 内存控制   安全  安全传输层协议 (TLS)  为 MySQL 客户端开启 TLS 为 TiDB 组件间开启 TLS     生成自签名证书   监控  概述 监控 TiDB 集群   迁移  迁移工具使用指南   从 MySQL 迁移  以 Amazon Aurora MySQL 为例     从 CSV 迁移   运维  Ansible 常见运维操作   备份与恢复  使用 Mydumper/TiDB Lightning 进行备份与恢复 使用 BR 进行备份与恢复 BR 备份与恢复场景示例   定位异常查询  定位慢查询 定位消耗系统资源多的查询     扩容缩容  使用 Ansible 扩容缩容   升级  升级至 TiDB 3.</description>
    </item>
    
    <item>
      <title>ADD COLUMN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/add-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/add-column/</guid>
      <description>TiDB 数据库中 ADD COLUMN 的使用概况。</description>
    </item>
    
    <item>
      <title>ADD INDEX</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/add-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/add-index/</guid>
      <description>TiDB 数据库中 ADD INDEX 的使用概况。</description>
    </item>
    
    <item>
      <title>ADMIN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/admin/</guid>
      <description>ADMIN ADMIN 语句是 TiDB 扩展语法，用于查看 TiDB 自身的状态，并对 TiDB 中的表数据进行校验。示例如下。
 ADMIN SHOW DDL; ADMIN SHOW DDL 用于查看当前正在执行的 DDL 作业。
 ADMIN SHOW DDL JOBS; ADMIN SHOW DDL JOBS 用于查看当前 DDL 作业队列中的所有结果（包括正在运行以及等待运行的任务）以及已执行完成的 DDL 作业队列中的最近十条结果。
 ADMIN SHOW DDL JOB QUERIES job_id [, job_id] ...;  ADMIN CANCEL DDL JOBS job_id [, job_id] ...;  ADMIN CHECK TABLE tbl_name [, tbl_name] ...; 语句概览 AdminStmt：
使用示例  admin show ddl jobs; +--------+---------+------------+---------------+----------------------+-----------+----------+-----------+-----------------------------------+---------------+ | JOB_ID | DB_NAME | TABLE_NAME | JOB_TYPE | SCHEMA_STATE | SCHEMA_ID | TABLE_ID | ROW_COUNT | START_TIME | STATE | +--------+---------+------------+---------------+----------------------+-----------+----------+-----------+-----------------------------------+---------------+ | 45 | test | t1 | add index | write reorganization | 32 | 37 | 0 | 2019-01-10 12:38:36.</description>
    </item>
    
    <item>
      <title>ALTER DATABASE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-database/</guid>
      <description>TiDB 数据库中 ALTER DATABASE 的使用概况。</description>
    </item>
    
    <item>
      <title>ALTER TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-table/</guid>
      <description>TiDB 数据库中 ALTER TABLE 的使用概况。</description>
    </item>
    
    <item>
      <title>ALTER USER</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/alter-user/</guid>
      <description>TiDB 数据库中 ALTER USER 的使用概况。</description>
    </item>
    
    <item>
      <title>ANALYZE TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/analyze-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/analyze-table/</guid>
      <description>TiDB 数据库中 ANALYZE TABLE 的使用概况。</description>
    </item>
    
    <item>
      <title>AUTO_RANDOM</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/attributes/auto-random/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/attributes/auto-random/</guid>
      <description>AUTO_RANDOM 从 v3.1.0 版本开始引入  警告：
当前 AUTO_RANDOM 属性为实验功能，不建议在生产环境中使用。在后续版本中，AUTO_RANDOM 的语法或语义可能会变化。
 使用 AUTO_RANDOM 功能前，须在 TiDB 配置文件 experimental 部分设置 allow-auto-random = true。该参数详情可参见 allow-auto-random。
使用场景 AUTO_RANDOM 用于解决大批量写数据入 TiDB 时因含有整型自增主键列的表而产生的热点问题。详情参阅 TiDB 高并发写入场景最佳实践。
以下面语句建立的表为例：
create table t (a int primary key auto_increment, b varchar(255)) 在以上语句所建的表上执行大量未指定主键值的 INSERT 语句，示例如下：
insert into t(b) values (&amp;#39;a&amp;#39;), (&amp;#39;b&amp;#39;), (&amp;#39;c&amp;#39;) 如以上语句，由于未指定主键列的值（a 列），TiDB 会使用连续自增的行值作为行 ID，可能导致单个 TiKV 节点上产生写入热点，进而影响对外提供服务的性能。要避免这种性能下降，可以在执行建表语句时为 a 列指定 AUTO_RANDOM 属性而不是 AUTO_INCREMENT 属性。示例如下：
 create table t (a int primary key auto_random, b varchar(255)) 或者</description>
    </item>
    
    <item>
      <title>BEGIN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/begin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/begin/</guid>
      <description>TiDB 数据库中 BEGIN 的使用概况。</description>
    </item>
    
    <item>
      <title>Binlog Slave Client 用户文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/binlog-slave-client/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/binlog-slave-client/</guid>
      <description>Binlog Slave Client 用户文档 目前 Drainer 提供了多种输出方式，包括 MySQL、TiDB、file 等。但是用户往往有一些自定义的需求，比如输出到 Elasticsearch、Hive 等，这些需求 Drainer 现在还没有实现，因此 Drainer 增加了输出到 Kafka 的功能，将 binlog 数据解析后按一定的格式再输出到 Kafka 中，用户编写代码从 Kafka 中读出数据再进行处理。
配置 Kafka Drainer 修改 Drainer 的配置文件，设置输出为 Kafka，相关配置如下：
[syncer] db-type = &amp;#34;kafka&amp;#34; [syncer.to] # Kafka 地址 kafka-addrs = &amp;#34;127.0.0.1:9092&amp;#34; # Kafka 版本号 kafka-version = &amp;#34;0.8.2.0&amp;#34; 自定义开发 数据格式 首先需要了解 Drainer 写入到 Kafka 中的数据格式：
// Column 保存列的数据，针对数据的类型，保存在对应的变量中 message Column { // 数据是否为 null optional bool is_null = 1 [ default = false ]; // 保存 int 类型的数据 optional int64 int64_value = 2; // 保存 uint、enum, set 类型的数据 optional uint64 uint64_value = 3; // 保存 float、double 类型的数据 optional double double_value = 4; // 保存 bit、blob、binary、json 类型的数据 optional bytes bytes_value = 5; // 保存 date、time、decimal、text、char 类型的数据 optional string string_value = 6; } // ColumnInfo 保存列的信息，包括列名、类型、是否为主键 message ColumnInfo { optional string name = 1 [ (gogoproto.</description>
    </item>
    
    <item>
      <title>BR 备份与恢复场景示例</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/br/use-cases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/br/use-cases/</guid>
      <description>BR 备份与恢复场景示例 Backup &amp;amp; Restore（下文简称 BR）一款分布式的快速备份和恢复工具。本文展示了四种备份和恢复场景下的 BR 操作过程，以帮助读者达到以下目标：
 正确使用网络盘或本地盘进行备份或恢复 通过相关监控指标了解备份或恢复的状态 了解在备份或恢复时如何调优性能 处理备份时可能发生的异常   注意：
使用 BR 时应注意使用限制。
 目标读者 读者需要对 TiDB 和 TiKV 有一定的了解。在阅读本文前，推荐先阅读使用 BR 进行备份与恢复。
环境准备 本部分介绍推荐的 TiDB 的部署方式、示例中的集群版本、TiKV 集群硬件信息和集群配置。读者可根据自己的硬件和配置来预估备份恢复的性能。
部署方式 推荐使用 TiDB Ansible 部署 TiDB 集群，再下载 TiDB Toolkit 获取 BR 应用。
集群版本  TiKV: v3.1.0-beta.1 PD: v3.1.0-beta.1 br: v3.1.0-beta.1  TiKV 集群硬件信息  操作系统：CentOS Linux release 7.6.1810 (Core) CPU：16-Core Common KVM processor RAM：32GB 硬盘：500G SSD * 2 网卡：10000MB/s  配置 BR 可以直接将命令下发到 TiKV 集群来执行备份和恢复，不依赖 TiDB server 组件，因此无需对 TiDB server 进行配置。</description>
    </item>
    
    <item>
      <title>Cast 函数和操作符</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/cast-functions-and-operators/</guid>
      <description>Cast 函数和操作符 Cast 函数和操作符用于将某种数据类型的值转换为另一种数据类型。TiDB 支持使用 MySQL 5.7 中提供的所有 Cast 函数和操作符。
Cast 函数和操作符表    函数和操作符名 功能描述     BINARY 将一个字符串转换成一个二进制字符串   CAST() 将一个值转换成一个确定类型   CONVERT() 将一个值转换成一个确定类型    </description>
    </item>
    
    <item>
      <title>CHANGE COLUMN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/change-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/change-column/</guid>
      <description>TiDB 数据库中 CHANGE COLUMN 的使用概况。</description>
    </item>
    
    <item>
      <title>COMMIT</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/commit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/commit/</guid>
      <description>TiDB 数据库中 COMMIT 的使用概况。</description>
    </item>
    
    <item>
      <title>CREATE DATABASE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-database/</guid>
      <description>TiDB 数据库中 CREATE DATABASE 的使用概况。</description>
    </item>
    
    <item>
      <title>CREATE INDEX</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-index/</guid>
      <description>CREATE INDEX 在 TiDB 中的使用概况</description>
    </item>
    
    <item>
      <title>CREATE TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-table/</guid>
      <description>TiDB 数据库中 CREATE TABLE 的使用概况</description>
    </item>
    
    <item>
      <title>CREATE TABLE LIKE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-table-like/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-table-like/</guid>
      <description>TiDB 数据库中 CREATE TABLE LIKE 的使用概况。</description>
    </item>
    
    <item>
      <title>CREATE USER</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-user/</guid>
      <description>TiDB 数据库中 CREATE USER 的使用概况。</description>
    </item>
    
    <item>
      <title>CREATE VIEW</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/create-view/</guid>
      <description>TiDB 数据库中 CREATE VIEW 的使用概况。</description>
    </item>
    
    <item>
      <title>CSV 支持</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/csv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/csv/</guid>
      <description>CSV 支持 TiDB Lightning 支持读取 CSV（逗号分隔值）的数据源，以及其他定界符格式如 TSV（制表符分隔值）。
文件名 包含整张表的 CSV 文件需命名为 db_name.table_name.csv，该文件会被解析为数据库 db_name 里名为 table_name 的表。
如果一个表分布于多个 CSV 文件，这些 CSV 文件命名需加上文件编号的后缀，如 db_name.table_name.003.csv。
文件扩展名必须为 *.csv，即使文件的内容并非逗号分隔。
表结构 CSV 文件是没有表结构的。要导入 TiDB，就必须为其提供表结构。可以通过以下任一方法实现：
 创建包含 DDL 语句 CREATE TABLE 的文件 db_name.table_name-schema.sql。 首先在 TiDB 中直接创建空表，然后在 tidb-lightning.toml 中设置 [mydumper] no-schema = true。  配置 CSV 格式可在 tidb-lightning.toml 文件中 [mydumper.csv] 下配置。 大部分设置项在 MySQL LOAD DATA 语句中都有对应的项目。
[mydumper.csv] # 字段分隔符，必须为 ASCII 字符。 separator = &amp;#39;,&amp;#39; # 引用定界符，可以为 ASCII 字符或空字符。 delimiter = &amp;#39;&amp;#34;&amp;#39; # CSV 文件是否包含表头。 # 如果为 true，首行将会被跳过。 header = true # CSV 是否包含 NULL。 # 如果为 true，CSV 文件的任何列都不能解析为 NULL。 not-null = false # 如果 `not-null` 为 false（即 CSV 可以包含 NULL）， # 为以下值的字段将会被解析为 NULL。 null = &amp;#39;\N&amp;#39; # 是否解析字段内的反斜线转义符。 backslash-escape = true # 是否移除以分隔符结束的行。 trim-last-separator = false separator   指定字段分隔符。</description>
    </item>
    
    <item>
      <title>Data Migration 常见错误修复</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/error-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/error-handling/</guid>
      <description>Data Migration 常见错误修复 本文档介绍 DM 中常见的错误以及修复方法。
常见错误说明和处理方法    错误码 错误说明 解决方法     code=10001 数据库操作异常 进一步分析错误信息和错误堆栈   code=10002 数据库底层的 bad connection 错误，通常表示 DM 到下游 TiDB 的数据库连接出现了异常（如网络故障、TiDB 重启等）且当前请求的数据暂时未能发送到 TiDB。 DM 提供针对此类错误的自动恢复。如果长时间未恢复，需要用户检查网络或 TiDB 状态。   code=10003 数据库底层 invalid connection 错误，通常表示 DM 到下游 TiDB 的数据库连接出现了异常（如网络故障、TiDB 重启、TiKV busy 等）且当前请求已有部分数据发送到了 TiDB。 DM 提供针对此类错误的自动恢复。如果未能正常恢复，需要用户进一步检查错误信息并根据具体场景进行分析。   code=10005 数据库查询类语句出错    code=10006 数据库 EXECUTE 类型语句出错，包括 DDL 和 INSERT/UPDATE/DELETE 类型的 DML。更详细的错误信息可通过错误 message 获取。错误 message 中通常包含操作数据库所返回的错误码和错误信息。    code=11006 DM 内置的 parser 解析不兼容的 DDL 时出错 可参考 Data Migration 故障诊断-处理不兼容的 DDL 语句 提供的解决方案   code=20010 处理任务配置时，解密数据库的密码出错 检查任务配置中提供的下游数据库密码是否有使用 dmctl 正确加密   code=26002 任务检查创建数据库连接失败。更详细的错误信息可通过错误 message 获取。错误 message 中包含操作数据库所返回的错误码和错误信息。 检查 DM-master 所在的机器是否有权限访问上游   code=32001 dump 处理单元异常 如果报错 msg 包含 mydumper: argument list too long.</description>
    </item>
    
    <item>
      <title>Data Migration 常见问题</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/faq/</guid>
      <description>Data Migration 常见问题 DM 是否支持同步阿里 RDS 以及其他云数据库的数据？ DM 仅支持解析标准版本的 MySQL/MariaDB 的 binlog，对于阿里云 RDS 以及其他云数据库没有进行过测试，如果确认其 binlog 为标准格式，则可以支持。
task 配置中的黑白名单的正则表达式是否支持非获取匹配（?!）？ 目前不支持，DM 仅支持 golang 标准库的正则，可以通过 re2-syntax 了解 golang 支持的正则表达式。
如果在上游执行的一个 statement 包含多个 DDL 操作，DM 是否支持同步？ DM 会尝试将包含多个 DDL 变更操作的单条语句拆分成只包含一个 DDL 操作的多条语句，但是可能没有覆盖所有的场景。建议在上游执行的一条 statement 中只包含一个 DDL 操作，或者在测试环境中验证一下，如果不支持，可以给 DM 提 issue。
如何处理不兼容的 DDL 语句？ 你需要使用 dmctl 手动处理 TiDB 不兼容的 DDL 语句（包括手动跳过该 DDL 语句或使用用户指定的 DDL 语句替换原 DDL 语句，详见跳过 (skip) 或替代执行 (replace) 异常的 SQL 语句）。
 注意：
TiDB 目前并不兼容 MySQL 支持的所有 DDL 语句。</description>
    </item>
    
    <item>
      <title>Data Migration 故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/dm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/dm/</guid>
      <description>Data Migration 故障诊断 本文总结了在 DM 工具使用过程中遇到问题的诊断流程，并指引用户通过错误信息查找相应的解决方案。
如果你在运行 DM 工具时出现了错误，请尝试以下解决方案：
  执行 query-status 命令查看任务运行状态以及相关错误输出。
  查看与该错误相关的日志文件。日志文件位于 DM-master、DM-worker 部署节点上，通过 Data Migration 错误含义 获取错误的关键信息，然后查看 Data Migration 常见错误及修复以寻找相应的解决方案。
  如果该错误还没有相应的解决方案，并且你无法通过查询日志或监控指标自行解决此问题，你可以联系相关销售人员进行支持。
  一般情况下，错误处理完成后，只需使用 dmctl 重启任务即可。
 resume-task ${task name}   但在某些情况下，你还需要重置数据同步任务。有关何时需要重置以及如何重置，详见重置数据同步任务。</description>
    </item>
    
    <item>
      <title>Data Migration 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/overview/</guid>
      <description>Data Migration 简介 DM (Data Migration) 是一体化的数据同步任务管理平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步。使用 DM 工具有利于简化错误处理流程，降低运维成本。
DM 架构 DM 主要包括三个组件：DM-master，DM-worker 和 dmctl。
DM-master DM-master 负责管理和调度数据同步任务的各项操作。
 保存 DM 集群的拓扑信息 监控 DM-worker 进程的运行状态 监控数据同步任务的运行状态 提供数据同步任务管理的统一入口 协调分库分表场景下各个实例分表的 DDL 同步  DM-worker DM-worker 负责执行具体的数据同步任务。
 将 binlog 数据持久化保存在本地 保存数据同步子任务的配置信息 编排数据同步子任务的运行 监控数据同步子任务的运行状态  DM-worker 启动后，会自动同步上游 binlog 至本地配置目录（如果使用 DM-Ansible 部署 DM 集群，默认的同步目录为 &amp;lt;deploy_dir&amp;gt;/relay_log）。关于 DM-worker，详见 DM-worker 简介。关于 relay log，详见 DM Relay Log。
dmctl dmctl 是用来控制 DM 集群的命令行工具。</description>
    </item>
    
    <item>
      <title>Data Migration 简单使用场景</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/simple-synchronization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/simple-synchronization/</guid>
      <description>Data Migration 简单使用场景 本文介绍了 DM 工具的一个简单使用场景（非分库分表合并场景）：将三个上游 MySQL 实例的数据同步到一个下游 TiDB 集群中。
上游实例 假设上游结构为：
  实例 1
   Schema Tables     user information, log   store store_bj, store_tj   log messages      实例 2
   Schema Tables     user information, log   store store_sh, store_sz   log messages      实例 3</description>
    </item>
    
    <item>
      <title>Data Migration 错误说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/error-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/troubleshoot/error-system/</guid>
      <description>Data Migration 错误说明 本文介绍了 Data Migration (DM) 的错误系统，以及各种错误信息的详细含义。
DM 错误系统 DM 1.0.0-GA 版本中引入了新的错误系统。该系统：
 增加了错误码机制。 增加了 class、scope、level 等错误信息。 优化了错误描述内容、错误调用链信息和调用堆栈信息。  错误系统的详细设计和实现，可参阅 RFC 文档: Proposal: Improve Error System。
错误信息示例 以下是 DM 实际输出的一条错误信息。本文根据这条信息，对各个字段作详细说明。
[code=38008:class=dm-master:scope=internal:level=high] grpc request error: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = &amp;#34;transport: Error while dialing dial tcp 172.17.0.2:8262: connect: connection refused&amp;#34; github.com/pingcap/dm/pkg/terror.(*Error).Delegate /root/code/gopath/src/github.com/pingcap/dm/pkg/terror/terror.go:267 github.com/pingcap/dm/dm/master/workerrpc.callRPC /root/code/gopath/src/github.com/pingcap/dm/dm/master/workerrpc/rawgrpc.go:124 github.com/pingcap/dm/dm/master/workerrpc.(*GRPCClient).SendRequest /root/code/gopath/src/github.com/pingcap/dm/dm/master/workerrpc/rawgrpc.go:64 github.</description>
    </item>
    
    <item>
      <title>DEALLOCATE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/deallocate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/deallocate/</guid>
      <description>TiDB 数据库中 DEALLOCATE 的使用概况。</description>
    </item>
    
    <item>
      <title>DELETE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/delete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/delete/</guid>
      <description>TiDB 数据库中 DELETE 的使用概况。</description>
    </item>
    
    <item>
      <title>DESC</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/desc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/desc/</guid>
      <description>TiDB 数据库中 DESC 的使用概况。</description>
    </item>
    
    <item>
      <title>DESCRIBE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/describe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/describe/</guid>
      <description>TiDB 数据库中 DESCRIBE 的使用概况。</description>
    </item>
    
    <item>
      <title>DM 1.0-GA 性能测试报告</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/dm-v1.0-ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/dm-v1.0-ga/</guid>
      <description>DM 1.0-GA 性能测试报告 本报告记录了对 1.0-GA 版本的 DM 进行性能测试的目的、环境、场景和结果。
测试目的 该性能测试用于评估使用 DM 进行全量数据导入和增量数据同步的性能上限，并根据测试结果提供 DM 同步任务的参考配置。
测试环境 测试机器信息 系统信息：
   机器 IP 操作系统 内核版本 文件系统类型     172.16.4.39 CentOS Linux release 7.6.1810 3.10.0-957.1.3.el7.x86_64 ext4   172.16.4.40 CentOS Linux release 7.6.1810 3.10.0-957.1.3.el7.x86_64 ext4   172.16.4.41 CentOS Linux release 7.6.1810 3.10.0-957.1.3.el7.x86_64 ext4   172.16.4.42 CentOS Linux release 7.6.1810 3.10.0-957.1.3.el7.x86_64 ext4   172.16.4.43 CentOS Linux release 7.6.1810 3.</description>
    </item>
    
    <item>
      <title>DM 1.0.2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.2/</guid>
      <description>DM 1.0.2 Release Notes 发版日期：2019 年 10 月 30 日
DM 版本：1.0.2
DM-Ansible 版本：1.0.2
改进提升  支持自动为 DM-worker 生成部分配置项 支持自动为数据迁移任务生成部分配置项 简化 query-status 在无参数时的默认输出 DM 直接管理到下游数据库的连接  问题修复  修复在进程启动过程中以及执行 SQL 失败时可能 panic 的问题 修复 DDL 执行超时后可能造成 sharding DDL 协调异常的问题 修复由于前置检查超时或部分 DM-worker 不可访问而不能启动数据迁移任务的问题 修复 SQL 执行失败后可能错误重试的问题  详细变更及问题修复  支持自动为 DM-worker 生成随机的 server-id 配置项 #337 支持自动为 DM-worker 生成 flavor 配置项 #328 支持自动为 DM-worker 生成 relay-binlog-name 与 relay-binlog-gtid 配置项 #318 支持根据黑白名单生成 mydumper 需要导出的表名配置项 #326 为数据迁移任务增加并发度配置项 (mydumper-thread、loader-thread 与 syncer-thread) #314 简化 query-status 在无参数时的默认输出 #340 修复 DDL 执行超时后可能造成 sharding DDL 协调异常的问题 #338 修复 DM-worker 从本地 meta 数据恢复数据迁移任务时可能 panic 的问题 #311 修复提交事务失败时可能造成 DM-worker panic 的问题 #313 修复监听端口被占用时 DM-worker 或 DM-master 启动过程中可能 panic 的问题 #301 修复对 1105 错误码的部分重试问题 #321, #332 修复对 Duplicate entry 与 Data too long for column 错误的重试问题 #313 修复在上游存在大量需要迁移的表时可能造成启动任务前置检查超时中断的问题 #327 修复部分 DM-worker 不可访问时无法启动数据迁移任务的问题 #319 修复从损坏的 relay log 恢复时可能错误更新 GTID sets 信息的问题 #339 修复 sync 处理单元计算 TPS 错误的问题 #294 DM 直接管理到下游数据库的连接 #325 提升组件内错误信息的传递方式 #320  </description>
    </item>
    
    <item>
      <title>DM 1.0.3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.3/</guid>
      <description>DM 1.0.3 Release Notes 发版日期：2019 年 12 月 13 日
DM 版本：1.0.3
DM-Ansible 版本：1.0.3
改进提升  dmctl 支持命令式使用 支持同步 ALTER DATABASE DDL 语句 优化 DM 错误提示信息  问题修复  修复全量导入模块在暂停或退出时 data race 导致 panic 的问题 修复对下游进行重试操作时，stop-task 和 pause-task 可能不生效的问题  详细变更及问题修复  dmctl 支持命令式使用 #364 优化 DM 错误提示信息 #351 优化 query-status 命令输出内容 #357 优化 DM 不同任务类型的权限检查 #374 支持对重复引用的路由配置和过滤配置进行检查 #385 支持同步 ALTER DATABASE DDL 语句 #389 优化 DM 异常重试机制 #391 修复全量导入模块在暂停或退出时 data race 导致 panic 的问题 #353 修复对下游进行重试操作时，stop-task 和 pause-task 可能不生效的问题 #400 更新 Golang 版本至 1.</description>
    </item>
    
    <item>
      <title>DM 1.0.4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/releases/1.0.4/</guid>
      <description>DM 1.0.4 Release Notes 发版日期：2020 年 03 月 13 日
DM 版本：1.0.4
DM-Ansible 版本：1.0.4
改进提升  DM-portal 新增英文 UI 的支持 query-status 命令增加 --more 参数用于显示完整的同步状态信息  问题修复  修复到下游 TiDB 连接异常导致同步暂停后，resume-task 可能无法正常恢复同步的问题 修复 online DDL 执行失败后错误清理了 online DDL meta 信息而导致重启任务后无法继续正确处理 online DDL 同步的问题 修复 start-task 异常后 query-error 可能导致 DM-worker panic 的问题 修复 relay.meta 写入成功前 DM-worker 进程异常停止后，重启 DM-worker 时可能无法正确 recover relay log 文件与 relay.meta 的问题  详细变更及问题修复  DM-portal 增加支持英文 UI #480 query-status 命令增加 --more 参数用于显示完整的同步状态信息 #533 修复到下游 TiDB 连接异常导致同步暂停后，resume-task 可能无法正常恢复同步的问题 #436 修复 online DDL 执行失败后错误清理了 online DDL meta 信息而导致重启任务后无法继续正确处理 online DDL 同步的问题 #465 修复 start-task 异常后 query-error 可能导致 DM-worker panic 的问题 #519 修复 relay.</description>
    </item>
    
    <item>
      <title>DM Portal 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-portal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-portal/</guid>
      <description>DM Portal 简介 当前版本的 DM 提供了丰富多样的功能特性，包括 Table routing，Black &amp;amp; white table lists，Binlog event filter 等。但这些功能特性同时也增加了用户使用 DM 的复杂度，尤其在编写 DM 任务配置的时候。
针对这个问题，DM 提供了一个精简的网页程序 DM Portal，能够帮助用户以可视化的方式去配置需要的同步任务，并且生成可以直接让 DM 直接执行的 task.yaml 文件。
功能描述 同步模式配置 支持 DM 的三种同步模式：
 全量同步 增量同步 All（全量+增量）  实例信息配置 支持配置库表同步路由方式，能够支持 DM 中分库分表合并的配置方式。
binlog 过滤配置 支持对数据库、数据表配置 binlog event 过滤。
配置文件生成 支持配置文件创建，能够将配置文件下载到本地并且同时会在 dm-portal 服务器的 /tmp/ 目录下自动创建。
使用限制 当前的 DM 配置可视化生成页面能够覆盖绝大部分的 DM 配置场景，但也有一定的使用限制：
 不支持 Binlog event filter 的 SQL pattern 方式 编辑功能不支持解析用户之前写的 task.yaml 文件，页面只能编辑由页面生成的 task.</description>
    </item>
    
    <item>
      <title>DM Relay Log</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/relay-log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/relay-log/</guid>
      <description>了解目录结构、初始同步规则和 DM relay log 的数据清理。</description>
    </item>
    
    <item>
      <title>DM 任务完整配置文件介绍</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/task-configuration-file-full/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/task-configuration-file-full/</guid>
      <description>DM 任务完整配置文件介绍 本文档主要介绍 Data Migration (DM) 的任务完整的配置文件 task_advanced.yaml，包含全局配置 和实例配置 两部分。
关于各配置项的功能和配置，请参阅数据同步功能。
关键概念 关于包括 source-id 和 DM-worker ID 在内的关键概念的介绍，请参阅关键概念。
完整配置文件示例 下面是一个完整的配置文件示例，通过该示例可以完成复杂的数据同步功能。
--- # ----------- 全局配置 ----------- ## ********* 基本信息配置 ********* name: test # 任务名称，需要全局唯一 task-mode: all # 任务模式，可设为 &amp;#34;full&amp;#34;、&amp;#34;incremental&amp;#34;、&amp;#34;all&amp;#34; is-sharding: true # 是否为分库分表合并任务 meta-schema: &amp;#34;dm_meta&amp;#34; # 下游储存 `meta` 信息的数据库 remove-meta: false # 是否在任务同步开始前移除该任务名对应的 `meta`（`checkpoint` 和 `onlineddl` 等）。 enable-heartbeat: false # 是否开启 `heartbeat` 功能 target-database: # 下游数据库实例配置 host: &amp;#34;192.168.0.1&amp;#34; port: 4000 user: &amp;#34;root&amp;#34; password: &amp;#34;&amp;#34; # 如果不为空则需经过 dmctl 加密 ## ******** 功能配置集 ********** routes: # 上游和下游表之间的路由 table routing 规则集 route-rule-1: # 配置名称 schema-pattern: &amp;#34;test_*&amp;#34; # 库名匹配规则，支持通配符 &amp;#34;*&amp;#34; 和 &amp;#34;?</description>
    </item>
    
    <item>
      <title>DM 任务配置文件介绍</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/task-configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/task-configuration-file/</guid>
      <description>DM 任务配置文件介绍 本文档主要介绍 Data Migration (DM) 的任务基础配置文件 task_basic.yaml，包含全局配置和实例配置两部分。
完整的任务配置参见 DM 任务完整配置文件介绍
关于各配置项的功能和配置，请参阅数据同步功能。
关键概念 关于包括 source-id 和 DM-worker ID 在内的关键概念的介绍，请参阅关键概念。
基础配置文件示例 下面是一个基础的配置文件示例，通过该示例可以完成简单的数据同步功能。
--- # ----------- 全局配置 ----------- ## ********* 基本信息配置 ********* name: test # 任务名称，需要全局唯一 task-mode: all # 任务模式，可设为 &amp;#34;full&amp;#34;、&amp;#34;incremental&amp;#34;、&amp;#34;all&amp;#34; target-database: # 下游数据库实例配置 host: &amp;#34;127.0.0.1&amp;#34; port: 4000 user: &amp;#34;root&amp;#34; password: &amp;#34;&amp;#34; # 如果不为空则需经过 dmctl 加密 ## ******** 功能配置集 ********** black-white-list: # 上游数据库实例匹配的表的 black &amp;amp; white list 过滤规则集 bw-rule-1: # 黑白名单配置的名称 do-dbs: [&amp;#34;all_mode&amp;#34;] # 同步哪些库 # ----------- 实例配置 ----------- mysql-instances: - source-id: &amp;#34;mysql-replica-01&amp;#34; # 上游实例或者复制组 ID，参考 `dm-master.</description>
    </item>
    
    <item>
      <title>DM 分库分表合并场景</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/shard-merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/shard-merge/</guid>
      <description>DM 分库分表合并场景 本文介绍如何在分库分表合并场景中使用 Data Migration (DM)。使用场景中，三个上游 MySQL 实例的分库和分表数据需要同步至下游 TiDB 集群。
上游实例 假设上游库结构如下：
  实例 1
   Schema Tables     user information, log_north, log_bak   store_01 sale_01, sale_02   store_02 sale_01, sale_02      实例 2
   Schema Tables     user information, log_east, log_bak   store_01 sale_01, sale_02   store_02 sale_01, sale_02      实例 3</description>
    </item>
    
    <item>
      <title>DM 查询状态</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/query-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/query-status/</guid>
      <description>DM 查询状态 本文介绍 DM（Data Migration）query-status 命令的查询结果、任务状态与子任务状态。
查询结果  » query-status { &amp;#34;result&amp;#34;: true, # 查询是否成功。 &amp;#34;msg&amp;#34;: &amp;#34;&amp;#34;, # 查询失败原因描述。 &amp;#34;tasks&amp;#34;: [ # 迁移 task 列表 { &amp;#34;taskName&amp;#34;: &amp;#34;test-1&amp;#34;, # 任务名称 &amp;#34;taskStatus&amp;#34;: &amp;#34;Running&amp;#34;, # 任务运行状态，包括 “New”，“Running”，“Paused”，“Stopped”，“Finished” 以及 “Error”。 &amp;#34;workers&amp;#34;: [ # 该任务所使用的 DM-workers 列表 &amp;#34;127.0.0.1:8262&amp;#34; ] }, { &amp;#34;taskName&amp;#34;: &amp;#34;test-2&amp;#34;, &amp;#34;taskStatus&amp;#34;: &amp;#34;Error - Some error occurred in subtask&amp;#34;, # 该任务的子任务存在运行错误并暂停的现象 &amp;#34;workers&amp;#34;: [ &amp;#34;127.0.0.1:8262&amp;#34;, &amp;#34;127.0.0.1:8263&amp;#34; ] }, { &amp;#34;taskName&amp;#34;: &amp;#34;test-3&amp;#34;, &amp;#34;taskStatus&amp;#34;: &amp;#34;Error - Relay status is Error&amp;#34;, # 该任务的某个处于 Sync 阶段的子任务对应的 Relay 处理单元出错 &amp;#34;workers&amp;#34;: [ &amp;#34;127.</description>
    </item>
    
    <item>
      <title>DM 版本升级</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-upgrade/</guid>
      <description>DM 版本升级 本文档主要介绍各 DM (Data Migration) 版本间的升级操作步骤。
 注意：
 若无特殊说明，各版本的升级操作均为从前一个有升级指引的版本向当前版本升级。 若无特殊说明，各升级操作示例均假定已经下载了对应版本的 DM 和 DM-Ansible 且 DM binary 存在于 DM-Ansible 的相应目录中（下载 DM binary 可以参考更新组件版本）。 若无特殊说明，各升级操作示例均假定升级前已停止所有同步任务，升级完成后手动重新启动所有同步任务。 以下版本升级指引逆序展示。   升级到 v1.0.3 版本信息 Release Version: v1.0.3 Git Commit Hash: 41426af6cffcff9a325697a3bdebeadc9baa8aa6 Git Branch: release-1.0 UTC Build Time: 2019-12-13 07:04:53 Go Version: go version go1.13 linux/amd64 主要变更  dmctl 支持命令式使用 支持同步 ALTER DATABASE DDL 语句 优化 DM 错误提示信息 修复全量导入模块在暂停或退出时 data race 导致 panic 的问题 修复对下游进行重试操作时，stop-task 和 pause-task 可能不生效的问题  升级操作示例  下载新版本 DM-Ansible，确认 inventory.</description>
    </item>
    
    <item>
      <title>DM 监控指标</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/monitor/</guid>
      <description>介绍 DM 的监控指标</description>
    </item>
    
    <item>
      <title>DM 配置简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/overview/</guid>
      <description>DM 配置简介 本文档简要介绍 DM (Data Migration) 的配置文件和数据同步任务的配置。
配置文件  inventory.ini：使用 DM-Ansible 部署 DM 集群的配置文件。需要根据所选用的集群拓扑来进行编辑。详见编辑 inventory.ini 配置文件。 dm-master.toml：DM-master 进程的配置文件，包括 DM 集群的拓扑信息、MySQL 实例与 DM-worker 之间的关系（必须为一对一的关系）。使用 DM-Ansible 部署 DM 集群时，会自动生成 dm-master.toml 文件，各项配置说明详见 DM-master 配置文件介绍 dm-worker.toml：DM-worker 进程的配置文件，包括上游 MySQL 实例的配置和 relay log 的配置。使用 DM-Ansible 部署 DM 集群时，会自动生成 dm-worker.toml 文件，各项配置说明详见 DM-worker 配置文件介绍  同步任务配置 任务配置文件 使用 DM-Ansible 部署 DM 集群时，&amp;lt;path-to-dm-ansible&amp;gt;/conf 中提供了任务配置文件模板：task.yaml.exmaple 文件。该文件是 DM 同步任务配置的标准文件，每一个具体的任务对应一个 task.yaml 文件。关于该配置文件的详细介绍，参见 任务配置文件。
创建数据同步任务 你可以基于 task.yaml.example 文件来创建数据同步任务，具体步骤如下：
 复制 task.yaml.example 为 your_task.yaml。 参考任务配置文件来修改 your_task.</description>
    </item>
    
    <item>
      <title>DM 集群操作</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/cluster-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/cluster-operations/</guid>
      <description>DM 集群操作 本文介绍 DM 集群操作以及使用 DM-Ansible 管理 DM 集群时需要注意的事项。
启动集群 运行以下命令以启动整个集群的所有组件（包括 DM-master、DM-worker 和监控组件）：
 ansible-playbook start.yml 下线集群 运行以下命令以下线整个集群的所有组件（包括 DM-master、DM-worker 和监控组件）：
 ansible-playbook stop.yml 重启集群组件 在以下情况下，需要更新 DM 集群组件：
 您想要更新组件版本。 发生了严重的错误，您需要重启组件完成临时恢复。 DM 集群所在的机器由于某种原因重启。  重启注意事项 该部分描述重启 DM 各组件时需要了解的事项。
DM-worker 重启事项 全量数据导入过程中：
对于全量数据导入时的 SQL 文件，DM 使用下游数据库记录断点信息，DM-worker 会在本地 meta 文件记录子任务信息。DM-worker 重启时会检查断点信息和本地记录的子任务信息，重启前处于运行中状态的任务会自动恢复数据同步。
增量数据同步过程中：
对于增量数据导入过程中的 binlog，DM 使用下游数据库记录断点信息，并会在同步任务开始或恢复后的第一个五分钟之内开启安全模式。
  未启用 sharding DDL 同步
如果 DM-worker 上运行的任务未启用 sharding DDL 同步功能，DM-worker 重启时会检查断点信息和本地记录的子任务信息，重启前处于运行中状态的任务会自动恢复数据同步。
  已启用 sharding DDL 同步</description>
    </item>
    
    <item>
      <title>DM-master 配置文件介绍</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-master-configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-master-configuration-file/</guid>
      <description>DM-master 配置文件介绍 本文介绍 DM-master 的配置文件，包括配置文件示例与配置项说明。
配置文件示例 DM-master 的示例配置文件如下所示：
# log configuration log-file = &amp;#34;dm-master.log&amp;#34; # DM-master listening address master-addr = &amp;#34;:8261&amp;#34; # DM-worker deployment. It will be refined when the new deployment function is available. [[deploy]] source-id = &amp;#34;mysql-replica-01&amp;#34; dm-worker = &amp;#34;172.16.10.72:8262&amp;#34; [[deploy]] source-id = &amp;#34;mysql-replica-02&amp;#34; dm-worker = &amp;#34;172.16.10.73:8262&amp;#34; 配置项说明 Global 配置    配置项 说明     log-file 日志文件，如果不配置，日志会输出到标准输出中。   master-addr DM-master 服务的地址，可以省略 IP 信息，例如：&amp;quot;:8261&amp;rdquo;。    DM-Worker 的配置 配置在 deploy 中，每一个 DM-worker 都需要设置一个 deploy。</description>
    </item>
    
    <item>
      <title>DM-worker 完整配置说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-worker-configuration-file-full/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-worker-configuration-file-full/</guid>
      <description>DM-worker 完整配置说明 本文完整地介绍 DM-worker 的配置，包括配置文件示例与配置项说明。
配置文件示例 # Worker Configuration. # Log configuration. log-level = &amp;#34;info&amp;#34; log-file = &amp;#34;dm-worker.log&amp;#34; # DM-worker listening address. worker-addr = &amp;#34;:8262&amp;#34; # Represents a MySQL/MariaDB instance or a replication group. source-id = &amp;#34;mysql-replica-01&amp;#34; # Server id of slave for binlog replication. # Each instance (master and slave) in the replication group should have a different server id. server-id = 101 # flavor: mysql/mariadb flavor = &amp;#34;mysql&amp;#34; # The directory used to store relay log.</description>
    </item>
    
    <item>
      <title>DM-worker 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-worker-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/dm-worker-intro/</guid>
      <description>DM-worker 简介 DM-worker 是 DM (Data Migration) 的一个组件，负责执行具体的数据同步任务。
其主要功能如下：
 注册为一台 MySQL 或 MariaDB 服务器的 slave。 读取 MySQL 或 MariaDB 的 binlog event，并将这些 event 持久化保存在本地 (relay log)。 单个 DM-worker 支持同步一个 MySQL 或 MariaDB 实例的数据到下游的多个 TiDB 实例。 多个 DM-Worker 支持同步多个 MySQL 或 MariaDB 实例的数据到下游的一个 TiDB 实例。  DM-worker 处理单元 DM-worker 任务包含如下多个逻辑处理单元。
Relay log Relay log 持久化保存从上游 MySQL 或 MariaDB 读取的 binlog，并对 binlog replication 处理单元提供读取 binlog event 的功能。
其原理和功能与 MySQL slave relay log 类似，详见 Slave Relay Log。</description>
    </item>
    
    <item>
      <title>DM-worker 配置文件介绍</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-worker-configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/configure/dm-worker-configuration-file/</guid>
      <description>DM-worker 配置文件介绍 本文档主要介绍 DM-worker 的基础配置文件。在一般场景中，用户只需要使用基础配置即可完成 DM-worker 的部署。
完整配置项参考 DM-worker 完整配置说明。
配置文件示例 # Worker Configuration. # Log configuration. log-file = &amp;#34;dm-worker.log&amp;#34; # DM-worker listen address. worker-addr = &amp;#34;:8262&amp;#34; # Represents a MySQL/MariaDB instance or a replication group. source-id = &amp;#34;mysql-replica-01&amp;#34; # Server id of slave for binlog replication. # Each instance (master and slave) in replication group should have different server id. server-id = 101 # flavor: mysql/mariadb flavor = &amp;#34;mysql&amp;#34; # The directory that used to store relay log.</description>
    </item>
    
    <item>
      <title>DO | TiDB SQL Statement Reference</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/do/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/do/</guid>
      <description>TiDB 数据库中 DO 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP COLUMN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-column/</guid>
      <description>TiDB 数据库中 DROP COLUMN 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP DATABASE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-database/</guid>
      <description>TiDB 数据库中 DROP DATABASE 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP INDEX</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-index/</guid>
      <description>TiDB 数据库中 DROP INDEX 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-table/</guid>
      <description>TiDB 数据库中 DROP TABLE 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP USER</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-user/</guid>
      <description>TiDB 数据库中 DROP USER 的使用概况。</description>
    </item>
    
    <item>
      <title>DROP VIEW</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/drop-view/</guid>
      <description>TiDB 数据库中 DROP VIEW 的使用概况。</description>
    </item>
    
    <item>
      <title>EXECUTE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/execute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/execute/</guid>
      <description>TiDB 数据库中 EXECUTE 的使用概况。</description>
    </item>
    
    <item>
      <title>EXPLAIN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/explain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/explain/</guid>
      <description>TiDB 数据库中 EXPLAIN 的使用概况。</description>
    </item>
    
    <item>
      <title>EXPLAIN ANALYZE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/explain-analyze/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/explain-analyze/</guid>
      <description>TiDB 数据库中 EXPLAIN ANALYZE 的使用概况。</description>
    </item>
    
    <item>
      <title>Figma 快速上手教程</title>
      <link>https://pingcap.com/docs-cn/v3.1/resources/figma-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/resources/figma-quick-start-guide/</guid>
      <description>本文档介绍如何使用 Figma 绘制图片。</description>
    </item>
    
    <item>
      <title>FLUSH PRIVILEGES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-privileges/</guid>
      <description>TiDB 数据库中 FLUSH PRIVILEGES 的使用概况。</description>
    </item>
    
    <item>
      <title>FLUSH STATUS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-status/</guid>
      <description>TiDB 数据库中 FLUSH STATUS 的使用概况。</description>
    </item>
    
    <item>
      <title>FLUSH TABLES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/flush-tables/</guid>
      <description>TiDB 数据库中 FLUSH TABLES 的使用概况。</description>
    </item>
    
    <item>
      <title>Follower Read</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/follower-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/follower-read/</guid>
      <description>了解 Follower Read 的使用与实现。</description>
    </item>
    
    <item>
      <title>GC 机制简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/garbage-collection/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/garbage-collection/overview/</guid>
      <description>GC 机制简介 TiDB 的事务的实现采用了 MVCC（多版本并发控制）机制，当新写入的数据覆盖旧的数据时，旧的数据不会被替换掉，而是与新写入的数据同时保留，并以时间戳来区分版本。GC 的任务便是清理不再需要的旧数据。
整体流程 一个 TiDB 集群中会有一个 TiDB 实例被选举为 GC leader，GC 的运行由 GC leader 来控制。
GC 会被定期触发，默认情况下每 10 分钟一次。每次 GC 时，首先，TiDB 会计算一个称为 safe point 的时间戳（默认为当前时间减去 10 分钟），接下来 TiDB 会在保证 safe point 之后的快照全部拥有正确数据的前提下，删除更早的过期数据。具体而言，分为以下三个步骤：
 Resolve Locks Delete Ranges Do GC  Resolve Locks TiDB 的事务是基于 Google Percolator 模型实现的，事务的提交是一个两阶段提交的过程。第一阶段完成时，所有涉及的 key 会加上一个锁，其中一个锁会被设定为 Primary，其余的锁（Secondary）则会指向 Primary；第二阶段会将 Primary 锁所在的 key 加上一个 Write 记录，并去除锁。这里的 Write 记录就是历史上对该 key 进行写入或删除，或者该 key 上发生事务回滚的记录。Primary 锁被替换为何种 Write 记录标志着该事务提交成功与否。接下来，所有 Secondary 锁也会被依次替换。如果替换这些 Secondary 锁的线程死掉了，锁就残留了下来。</description>
    </item>
    
    <item>
      <title>GC 配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/garbage-collection/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/garbage-collection/configuration/</guid>
      <description>GC 配置 TiDB 的 GC 相关的配置存储于 mysql.tidb 系统表中，可以通过 SQL 语句对这些参数进行查询和更改：
 select VARIABLE_NAME, VARIABLE_VALUE from mysql.tidb; +--------------------------+----------------------------------------------------------------------------------------------------+ | VARIABLE_NAME | VARIABLE_VALUE | +--------------------------+----------------------------------------------------------------------------------------------------+ | bootstrapped | True | | tidb_server_version | 33 | | system_tz | UTC | | tikv_gc_leader_uuid | 5afd54a0ea40005 | | tikv_gc_leader_desc | host:tidb-cluster-tidb-0, pid:215, start at 2019-07-15 11:09:14.029668932 +0000 UTC m=+0.463731223 | | tikv_gc_leader_lease | 20190715-12:12:14 +0000 | | tikv_gc_enable | true | | tikv_gc_run_interval | 10m0s | | tikv_gc_life_time | 10m0s | | tikv_gc_last_run_time | 20190715-12:09:14 +0000 | | tikv_gc_safe_point | 20190715-11:59:14 +0000 | | tikv_gc_auto_concurrency | true | | tikv_gc_mode | distributed | +--------------------------+----------------------------------------------------------------------------------------------------+ 13 rows in set (0.</description>
    </item>
    
    <item>
      <title>GRANT &lt;privileges&gt;</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/grant-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/grant-privileges/</guid>
      <description>&lt;p&gt;TiDB 数据库中 GRANT &lt;privileges&gt; 的使用概况。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GROUP BY 聚合函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/aggregate-group-by-functions/</guid>
      <description>GROUP BY 聚合函数 本文将详细介绍 TiDB 支持的聚合函数。
TiDB 支持的聚合函数 TiDB 支持的 MySQL GROUP BY 聚合函数如下所示：
   函数名 功能描述     COUNT() 返回检索到的行的数目   COUNT(DISTINCT) 返回不同值的数目   SUM() 返回和   AVG() 返回平均值   MAX() 返回最大值   MIN() 返回最小值   GROUP_CONCAT() 返回连接的字符串     注意：
 除非另有说明，否则聚合函数默认忽略 NULL 值。 如果在不包含 GROUP BY 子句的语句中使用聚合函数，则相当于对所有行进行分组。   GROUP BY 修饰符 TiDB 目前不支持 GROUP BY 修饰符，例如 WITH ROLLUP，将来会提供支持。详情参阅 #4250。</description>
    </item>
    
    <item>
      <title>HAProxy 在 TiDB 中的最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/haproxy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/haproxy/</guid>
      <description>HAProxy 在 TiDB 中的最佳实践 本文介绍 HAProxy 在 TiDB 中的最佳配置和使用方法。HAProxy 提供 TCP 协议下的负载均衡能力，TiDB 客户端通过连接 HAProxy 提供的浮动 IP 即可对数据进行操作，实现 TiDB Server 层的负载均衡。
HAProxy 简介 HAProxy 是由 C 语言编写的自由开放源码的软件，为基于 TCP 和 HTTP 协议的应用程序提供高可用性、负载均衡和代理服务。因为 HAProxy 能够快速、高效使用 CPU 和内存，所以目前使用非常广泛，许多知名网站诸如 GitHub、Bitbucket、Stack Overflow、Reddit、Tumblr、Twitter 和 Tuenti 以及亚马逊网络服务系统都在使用 HAProxy。
HAProxy 由 Linux 内核的核心贡献者 Willy Tarreau 于 2000 年编写，他现在仍然负责该项目的维护，并在开源社区免费提供版本迭代。最新的稳定版本 2.0.0 于 2019 年 8 月 16 日发布，带来更多优秀的特性。
HAProxy 部分核心功能介绍  高可用性：HAProxy 提供优雅关闭服务和无缝切换的高可用功能； 负载均衡：L4 (TCP) 和 L7 (HTTP) 两种负载均衡模式，至少 9 类均衡算法，比如 roundrobin，leastconn，random 等； 健康检查：对 HAProxy 配置的 HTTP 或者 TCP 模式状态进行检查； 会话保持：在应用程序没有提供会话保持功能的情况下，HAProxy 可以提供该项功能； SSL：支持 HTTPS 通信和解析； 监控与统计：通过 web 页面可以实时监控服务状态以及具体的流量信息。  准备环境 在部署 HAProxy 之前，需准备好以下环境。</description>
    </item>
    
    <item>
      <title>Information Schema</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/system-databases/information-schema/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/system-databases/information-schema/</guid>
      <description>Information Schema 为了和 MySQL 保持兼容，TiDB 支持很多 INFORMATION_SCHEMA 表，其中有不少表都支持相应的 SHOW 命令。查询 INFORMATION_SCHEMA 表也为表的连接操作提供了可能。
ANALYZE_STATUS 表 ANALYZE_STATUS 表提供正在执行的收集统计信息的任务以及有限条历史任务记录。
 select * from `ANALYZE_STATUS`; +--------------+------------+----------------+-------------------+----------------+---------------------+----------+ | TABLE_SCHEMA | TABLE_NAME | PARTITION_NAME | JOB_INFO | PROCESSED_ROWS | START_TIME | STATE | +--------------+------------+----------------+-------------------+----------------+---------------------+----------+ | test | t | | analyze index idx | 2 | 2019-06-21 19:51:14 | finished | | test | t | | analyze columns | 2 | 2019-06-21 19:51:14 | finished | | test | t1 | p0 | analyze columns | 0 | 2019-06-21 19:51:15 | finished | | test | t1 | p3 | analyze columns | 0 | 2019-06-21 19:51:15 | finished | | test | t1 | p1 | analyze columns | 0 | 2019-06-21 19:51:15 | finished | | test | t1 | p2 | analyze columns | 1 | 2019-06-21 19:51:15 | finished | +--------------+------------+----------------+-------------------+----------------+---------------------+----------+ 6 rows in set CHARACTER_SETS 表 CHARACTER_SETS 表提供字符集相关的信息。TiDB 目前仅支持部分字符集。</description>
    </item>
    
    <item>
      <title>INSERT</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/insert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/insert/</guid>
      <description>TiDB 数据库中 INSERT 的使用概况。</description>
    </item>
    
    <item>
      <title>JSON 函数及语法糖</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/json-functions/</guid>
      <description>JSON 函数及语法糖 TiDB 支持 MySQL 5.7 GA 版本发布的大多数 JSON 函数。MySQL 5.7 发布后，又增加了更多 JSON 函数，TiDB 并未支持所有这些函数（参见未支持的函数）。
创建 JSON 值的函数    函数及语法糖 功能描述     JSON_ARRAY([val[, val] &amp;hellip;]) 根据一系列元素创建一个 JSON 文档   JSON_OBJECT(key, val[, key, val] &amp;hellip;) 根据一系列 K/V 对创建一个 JSON 文档   JSON_QUOTE(string) 返回一个字符串，该字符串为带引号的 JSON 值    搜索 JSON 值的函数    函数及语法糖 功能描述     JSON_CONTAINS(target, candidate[, path]) 通过返回 1 或 0 来表示目标 JSON 文档中是否包含给定的 candidate JSON 文档   JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] &amp;hellip;) 通过返回 0 或 1 来表示一个 JSON 文档在给定路径是否包含数据   JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) 从 JSON 文档中解出某一路径对应的子文档   -&amp;gt; 返回执行路径后面的 JSON 列的值；JSON_EXTRACT(doc, path_literal) 的语法糖   -&amp;raquo; 返回执行路径后面的 JSON 列的值和转义后的结果； JSON_UNQUOTE(JSON_EXTRACT(doc, path_literal)) 的语法糖   JSON_KEYS(json_doc[, path]) 返回从 JSON 对象的顶级值作为 JSON array 的键，如果给定了路径参数，则从选定路径中获取顶级键    修改 JSON 值的函数    函数及语法糖 功能描述     JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中在某一路径下插入子文档   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) 已废弃的 JSON_MERGE_PRESERVE 别名   JSON_MERGE_PRESERVE(json_doc, json_doc[, json_doc] &amp;hellip;) 将两个或多个 JSON 文档合并成一个文档，并返回合并结果   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) 移除 JSON 文档中某一路径下的子文档   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) 替换 JSON 文档中的某一路径下的子文档   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中为某一路径设置子文档   JSON_UNQUOTE(json_val) 去掉 JSON 值外面的引号，返回结果为字符串    返回 JSON 值属性的函数    函数及语法糖 功能描述     JSON_DEPTH(json_doc) 返回 JSON 文档的最大深度   JSON_LENGTH(json_doc[, path]) 返回 JSON 文档的长度；如果路径参数已定，则返回该路径下值的长度   JSON_TYPE(json_val) 检查某 JSON 文档内部内容的类型    未支持的函数 TiDB 暂未支持以下 JSON 函数。相关进展参见 TiDB #7546:</description>
    </item>
    
    <item>
      <title>JSON 类型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/json/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/json/</guid>
      <description>JSON 类型 JSON 类型可以存储 JSON 这种半结构化的数据，相比于直接将 JSON 存储为字符串，它的好处在于：
 使用 Binary 格式进行序列化，对 JSON 的内部字段的查询、解析加快； 多了 JSON 合法性验证的步骤，只有合法的 JSON 文档才可以放入这个字段中；  JSON 字段本身上，并不能创建索引。相反，可以对 JSON 文档中的某个子字段创建索引。例如：
 CREATE TABLE city ( id INT PRIMARY KEY, detail JSON, population INT AS (JSON_EXTRACT(detail, &amp;#39;$.population&amp;#39;)) ); INSERT INTO city (id,detail) VALUES (1, &amp;#39;{&amp;#34;name&amp;#34;: &amp;#34;Beijing&amp;#34;, &amp;#34;population&amp;#34;: 100}&amp;#39;); SELECT id FROM city WHERE population &amp;gt;= 100; </description>
    </item>
    
    <item>
      <title>KILL [TIDB]</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/kill/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/kill/</guid>
      <description>TiDB 数据库中 KILL [TIDB] 的使用概况。</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB Binlog Drainer 配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/tidb-drainer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/tidb-drainer/</guid>
      <description>了解 Kubernetes 上的 TiDB Binlog Drainer 配置</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 工具指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/tools/in-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/tools/in-kubernetes/</guid>
      <description>Kubernetes 上的 TiDB 工具指南 Kubernetes 上的 TiDB 运维管理需要使用一些开源工具。同时，在 Kubernetes 上使用 TiDB 生态工具时，也有特殊的操作要求。本文档详细描述 Kubernetes 上的 TiDB 相关的工具及其使用方法。
在 Kubernetes 上使用 PD Control PD Control 是 PD 的命令行工具，在使用 PD Control 操作 Kubernetes 上的 TiDB 集群时，需要先使用 kubectl port-forward 打开本地到 PD 服务的连接：
 kubectl port-forward -n &amp;lt;namespace&amp;gt; svc/&amp;lt;cluster-name&amp;gt;-pd 2379:2379 &amp;amp;&amp;gt;/tmp/portforward-pd.log &amp;amp; 执行上述命令后，就可以通过 127.0.0.1:2379 访问到 PD 服务，从而直接使用 pd-ctl 命令的默认参数执行操作，如：
 pd-ctl -d config show 假如你本地的 2379 被占据，则需要选择其它端口：
 kubectl port-forward -n &amp;lt;namespace&amp;gt; svc/&amp;lt;cluster-name&amp;gt;-pd &amp;lt;local-port&amp;gt;:2379 &amp;amp;&amp;gt;/tmp/portforward-pd.log &amp;amp; 此时，需要为 pd-ctl 命令显式指定 PD 端口：</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群备份配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/backup/</guid>
      <description>Kubernetes 上的 TiDB 集群备份配置 tidb-backup 是一个用于 Kubernetes 上 TiDB 集群备份和恢复的 Helm Chart。本文详细介绍了 tidb-backup 的可配置参数。
mode  运行模式 默认：&amp;ldquo;backup&amp;rdquo; 可选值为 backup（备份集群数据）和 restore（恢复集群数据）  clusterName  目标集群名字 默认：&amp;ldquo;demo&amp;rdquo; 指定要从哪个集群进行备份或将数据恢复到哪个集群中  name  备份名 默认值：&amp;ldquo;fullbackup-&amp;rdquo;，&amp;lt;date&amp;gt; 是备份的开始时间，精确到分钟 备份名用于区分不同的备份数据  secretName   访问目标集群时使用的凭据
  默认：&amp;ldquo;backup-secret&amp;rdquo;
  该 Kubernetes Secret 中需要存储目标集群的登录用户名和密码，你可以通过以下命令来创建这个 Secret：
 kubectl create secret generic backup-secret -n &amp;lt;namespace&amp;gt; --from-literal=user=root --from-literal=password=&amp;lt;password&amp;gt;   storage.className  Kubernetes StorageClass 默认：&amp;ldquo;local-storage&amp;rdquo; 备份任务需要绑定一个持久卷 (Persistent Volume, PV) 来永久或临时存储备份数据，StorageClass 用于声明持久卷使用的存储类型，需要确保该 StorageClass 在 Kubernetes 集群中存在。  storage.</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群常见问题</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/faq/</guid>
      <description>Kubernetes 上的 TiDB 集群常见问题 本文介绍 Kubernetes 上的 TiDB 集群常见问题以及解决方案。
如何修改时区设置？ 默认情况下，在 Kubernetes 集群上部署的 TiDB 集群各组件容器中的时区为 UTC，如果要修改时区配置，有下面两种情况：
  第一次部署集群
在 TiDB 集群的 values.yaml 文件中，修改 timezone 配置，例如：timezone: Asia/Shanghai，然后部署 TiDB 集群。
  集群已经在运行
如果 TiDB 集群已经在运行，需要做如下修改：
 在 TiDB 集群的 values.yaml 文件中，修改 timezone 配置，例如：timezone: Asia/Shanghai，然后升级 TiDB 集群。 参考时区支持，修改 TiDB 服务时区配置。    TiDB 相关组件可以配置 HPA 或 VPA 么？ TiDB 集群目前还不支持 HPA（Horizontal Pod Autoscaling，自动水平扩缩容）和 VPA（Vertical Pod Autoscaling，自动垂直扩缩容），因为对于数据库这种有状态应用而言，实现自动扩缩容难度较大，无法仅通过 CPU 和 memory 监控数据来简单地实现。</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群扩缩容</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/scale-in-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/scale-in-kubernetes/</guid>
      <description>Kubernetes 上的 TiDB 集群扩缩容 本文介绍 TiDB 在 Kubernetes 中如何进行水平扩缩容和垂直扩缩容。
水平扩缩容 TiDB 水平扩缩容操作指的是通过增加或减少节点的数量，来达到集群扩缩容的目的。扩缩容 TiDB 集群时，会按照填入的 replicas 值，对 PD、TiKV、TiDB 进行顺序扩缩容操作。扩容操作按照节点编号由小到大增加节点，缩容操作按照节点编号由大到小删除节点。
水平扩缩容操作   修改集群的 value.yaml 文件中的 pd.replicas、tidb.replicas、tikv.replicas 至期望值。
  执行 helm upgrade 命令进行扩缩容：
 helm upgrade &amp;lt;release-name&amp;gt; pingcap/tidb-cluster -f values.yaml --version=&amp;lt;chart-version&amp;gt;   查看集群水平扩缩容状态：
 watch kubectl -n &amp;lt;namespace&amp;gt; get pod -o wide 当所有组件的 Pod 数量都达到了预设值，并且都进入 Running 状态后，水平扩缩容完成。
   注意：
 PD、TiKV 组件在滚动升级的过程中不会触发扩缩容操作。 TiKV 组件在缩容过程中会调用 PD 接口将对应 TiKV 标记为下线，然后将其上数据迁移到其它 TiKV 节点，在数据迁移期间 TiKV Pod 依然是 Running 状态，数据迁移完成后对应 Pod 才会被删除，缩容时间与待缩容的 TiKV 上的数据量有关，可以通过 kubectl get tidbcluster -n &amp;lt;namespace&amp;gt; &amp;lt;release-name&amp;gt; -o json | jq &#39;.</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群故障自动转移</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/auto-failover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/auto-failover/</guid>
      <description>Kubernetes 上的 TiDB 集群故障自动转移 故障自动转移是指在 TiDB 集群的某些节点出现故障时，TiDB Operator 会自动添加一个节点，保证 TiDB 集群的高可用，类似于 K8s 的 Deployment 行为。
由于 TiDB Operator 基于 StatefulSet 来管理 Pod，但 StatefulSet 在某些 Pod 发生故障时不会自动创建新节点来替换旧节点，所以，TiDB Operator 扩展了 StatefulSet 的这种行为，添加了 Auto Failover 功能。
Auto Failover 功能在 TiDB Operator 中默认关闭。部署 TiDB Operator 时，可通过设置 charts/tidb-operator/values.yaml 文件的 controllerManager.autoFailover 为 true 开启该功能：
controllerManager: serviceAccount: tidb-controller-manager logLevel: 2 replicas: 1 resources: limits: cpu: 250m memory: 150Mi requests: cpu: 80m memory: 50Mi # autoFailover is whether tidb-operator should auto failover when failure occurs autoFailover: true # pd failover period default(5m) pdFailoverPeriod: 5m # tikv failover period default(5m) tikvFailoverPeriod: 5m # tidb failover period default(5m) tidbFailoverPeriod: 5m pdFailoverPeriod、tikvFailoverPeriod 和 tidbFailoverPeriod 默认均为 5 分钟，它们的含义是在确认实例故障后的等待超时时间，超过这个时间后，TiDB Operator 就开始做自动的故障转移。</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/troubleshoot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/troubleshoot/</guid>
      <description>Kubernetes 上的 TiDB 集群故障诊断 本文介绍了 Kubernetes 上 TiDB 集群的一些常见故障以及诊断解决方案。
诊断模式 当 Pod 处于 CrashLoopBackoff 状态时，Pod 内会容器不断退出，导致无法正常使用 kubectl exec 或 tkctl debug，给诊断带来不便。为了解决这个问题，TiDB in Kubernetes 提供了 PD/TiKV/TiDB Pod 诊断模式。在诊断模式下，Pod 内的容器启动后会直接挂起，不会再进入重复 Crash 的状态，此时，便可以通过 kubectl exec 或 tkctl debug 连接 Pod 内的容器进行诊断。
操作方式：
首先，为待诊断的 Pod 添加 Annotation：
 kubectl annotate pod &amp;lt;pod-name&amp;gt; -n &amp;lt;namespace&amp;gt; runmode=debug 在 Pod 内的容器下次重启时，会检测到该 Annotation，进入诊断模式。等待 Pod 进入 Running 状态即可开始诊断：
 watch kubectl get pod &amp;lt;pod-name&amp;gt; -n &amp;lt;namespace&amp;gt; 下面是使用 kubectl exec 进入容器进行诊断工作的例子：</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群环境需求</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/prerequisites/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/prerequisites/</guid>
      <description>Kubernetes 上的 TiDB 集群环境需求 本文介绍在 Kubernetes 上部署 TiDB 集群的软硬件环境需求。
软件版本要求    软件名称 版本     Docker Docker CE 18.09.6   Kubernetes v1.12.5+   CentOS CentOS 7.6，内核要求为 3.10.0-957 或之后版本    内核参数设置    配置项 设置值     net.core.somaxconn 32768   vm.swappiness 0   net.ipv4.tcp_syncookies 0   net.ipv4.ip_forward 1   fs.file-max 1000000   fs.inotify.max_user_watches 1048576   fs.</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群监控</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/monitor/tidb-in-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/monitor/tidb-in-kubernetes/</guid>
      <description>Kubernetes 上的 TiDB 集群监控 基于 Kubernetes 环境部署的 TiDB 集群监控可以大体分为两个部分：对 TiDB 集群本身的监控、对 Kubernetes 集群及 TiDB Operator 的监控。本文将对两者进行简要说明。
TiDB 集群的监控 TiDB 通过 Prometheus 和 Grafana 监控 TiDB 集群。在通过 TiDB Operator 创建新的 TiDB 集群时，对于每个 TiDB 集群，会同时创建、配置一套独立的监控系统，与 TiDB 集群运行在同一 Namespace，包括 Prometheus 和 Grafana 两个组件。
监控数据默认没有持久化，如果由于某些原因监控容器重启，已有的监控数据会丢失。可以在 values.yaml 中设置 monitor.persistent 为 true 来持久化监控数据。开启此选项时应将 storageClass 设置为一个当前集群中已有的存储，并且此存储应当支持将数据持久化，否则仍然会存在数据丢失的风险。
在 TiDB 集群监控中有一些监控系统配置的细节可供参考。
查看监控面板 可以通过 kubectl port-forward 查看监控面板：
 kubectl port-forward -n &amp;lt;namespace&amp;gt; svc/&amp;lt;release-name&amp;gt;-grafana 3000:3000 &amp;amp;&amp;gt;/tmp/portforward-grafana.log 然后在浏览器中打开 http://localhost:3000，默认用户名和密码都为 admin。
Grafana 服务默认通过 NodePort 暴露，如果 Kubernetes 集群支持负载均衡器，你可以在 values.</description>
    </item>
    
    <item>
      <title>Kubernetes 上的 TiDB 集群配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/tidb-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/tidb-cluster/</guid>
      <description>Kubernetes 上的 TiDB 集群配置 本文介绍 Kubernetes 上 TiDB 集群的配置参数、资源配置，以及容灾配置。
配置参数 TiDB Operator 使用 Helm 部署和管理 TiDB 集群。通过 Helm 获取的配置文件默认提供了基本的配置，通过这个基本配置，可以快速启动一个 TiDB 集群。但是如果用户需要特殊配置或是用于生产环境，则需要根据以下配置参数列表手动配置对应的配置项。
 注意：
下文用 values.yaml 指代要修改的 TiDB 集群配置文件。
    参数名 说明 默认值     rbac.create 是否启用 Kubernetes 的 RBAC true   clusterName TiDB 集群名，默认不设置该变量，tidb-cluster 会直接用执行安装时的 ReleaseName 代替 nil   extraLabels 添加额外的 labels 到 TidbCluster 对象 (CRD) 上，参考：labels {}   schedulerName TiDB 集群使用的调度器 tidb-scheduler   timezone TiDB 集群默认时区 UTC   pvReclaimPolicy TiDB 集群使用的 PV (Persistent Volume)的 reclaim policy Retain   services[0].</description>
    </item>
    
    <item>
      <title>Kubernetes 上的持久化存储类型配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/storage-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/configuration/storage-class/</guid>
      <description>Kubernetes 上的持久化存储类型配置 TiDB 集群中 PD、TiKV、监控等组件以及 TiDB Binlog 和备份等工具都需要使用将数据持久化的存储。Kubernetes 上的数据持久化需要使用 PersistentVolume (PV)。Kubernetes 提供多种存储类型，主要分为两大类：
  网络存储
存储介质不在当前节点，而是通过网络方式挂载到当前节点。一般有多副本冗余提供高可用保证，在节点出现故障时，对应网络存储可以再挂载到其它节点继续使用。
  本地存储
存储介质在当前节点，通常能提供比网络存储更低的延迟，但没有多副本冗余，一旦节点出故障，数据就有可能丢失。如果是 IDC 服务器，节点故障可以一定程度上对数据进行恢复，但公有云上使用本地盘的虚拟机在节点故障后，数据是无法找回的。
  PV 一般由系统管理员或 volume provisioner 自动创建，PV 与 Pod 是通过 PersistentVolumeClaim (PVC) 进行关联的。普通用户在使用 PV 时并不需要直接创建 PV，而是通过 PVC 来申请使用 PV，对应的 volume provisioner 根据 PVC 创建符合要求的 PV，并将 PVC 与该 PV 进行绑定。
 警告：
为了数据安全，任何情况下都不要直接删除 PV，除非对 volume provisioner 原理非常清楚。
 TiDB 集群推荐存储类型 TiKV 自身借助 Raft 实现了数据复制，出现节点故障后，PD 会自动进行数据调度补齐缺失的数据副本，同时 TiKV 要求存储有较低的读写延迟，所以生产环境强烈推荐使用本地 SSD 存储。</description>
    </item>
    
    <item>
      <title>Kubernetes 上的集群初始化配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/initialize-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/initialize-cluster/</guid>
      <description>Kubernetes 上的集群初始化配置 本文介绍如何对 Kubernetes 上的集群进行初始化配置完成初始化账号和密码设置，以及批量自动执行 SQL 语句对数据库进行初始化。
 注意：
以下功能只在第一次创建集群时有作用，集群创建之后再设置或修改不会生效。
 设置初始化账号和密码 集群创建时默认会创建 root 账号，但是密码为空，这会带来一些安全性问题。可以通过如下步骤为 root 账号设置初始密码：
  创建 Namespace
在部署集群前通过下面命令创建 Namespace：
 kubectl create namespace &amp;lt;namespace&amp;gt;   创建 Secret
在部署集群前通过下面命令创建 Secret 指定 root 账号密码：
 kubectl create secret generic tidb-secret --from-literal=root=&amp;lt;root-password&amp;gt; --namespace=&amp;lt;namespace&amp;gt; 如果希望能自动创建其它用户，可以在上面命令里面再加上其他用户的 username 和 password，例如：
 kubectl create secret generic tidb-secret --from-literal=root=&amp;lt;root-password&amp;gt; --from-literal=developer=&amp;lt;developer-passowrd&amp;gt; --namespace=&amp;lt;namespace&amp;gt; 该命令会创建 root 和 developer 两个用户的密码，存到 tidb-secret 的 Secret 里面。并且创建的普通用户 developer 默认只有 USAGE 权限，其他权限请在 tidb.</description>
    </item>
    
    <item>
      <title>LOAD DATA</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/load-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/load-data/</guid>
      <description>TiDB 数据库中 LOAD DATA 的使用概况。</description>
    </item>
    
    <item>
      <title>Loader 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/loader/</guid>
      <description>Loader 使用文档 Loader 简介 Loader 是由 PingCAP 开发的数据导入工具，用于向 TiDB 中导入数据。
Loader 包含在 tidb-enterprise-tools 安装包中，可在此下载。
为什么我们要做这个工具 当数据量比较大的时候，如果用 mysqldump 这样的工具迁移数据会比较慢。我们尝试了 Mydumper/myloader 套件，能够多线程导出和导入数据。在使用过程中，Mydumper 问题不大，但是 myloader 由于缺乏出错重试、断点续传这样的功能，使用起来很不方便。所以我们开发了 loader，能够读取 Mydumper 的输出数据文件，通过 MySQL protocol 向 TiDB/MySQL 中导入数据。
Loader 有哪些优点  多线程导入 支持表级别的并发导入，分散写入热点 支持对单个大表并发导入，分散写入热点 支持 Mydumper 数据格式 出错重试 断点续导 通过 system variable 优化 TiDB 导入数据速度  使用方法 注意事项 请勿使用 loader 导入 MySQL 实例中 mysql 系统数据库到下游 TiDB。
如果 Mydumper 使用 -m 参数，会导出不带表结构的数据，这时 loader 无法导入数据。
如果使用默认的 checkpoint-schema 参数，在导完一个 database 数据库后，请 drop database tidb_loader 后再开始导入下一个 database。</description>
    </item>
    
    <item>
      <title>MODIFY COLUMN</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/modify-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/modify-column/</guid>
      <description>TiDB 数据库中 MODIFY COLUMN 的使用概况。</description>
    </item>
    
    <item>
      <title>Mydumper 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/mydumper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/mydumper/</guid>
      <description>使用 Mydumper 从 TiDB 导出数据。</description>
    </item>
    
    <item>
      <title>Optimizer Hints</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/optimizer-hints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/optimizer-hints/</guid>
      <description>Optimizer Hints TiDB 支持 Optimizer Hints 语法，它基于 MySQL 5.7 中介绍的类似 comment 的语法，例如 /*+ HINT_NAME(t1, t2) */。当 TiDB 优化器选择的不是最优查询计划时，建议使用 Optimizer Hints。
 注意：
MySQL 命令行客户端在 5.7.7 版本之前默认清除了 Optimizer Hints。如果需要在这些早期版本的客户端中使用 Hint 语法，需要在启动客户端时加上 --comments 选项，例如 mysql -h 127.0.0.1 -P 4000 -uroot --comments。
 语法 Optimizer Hints 通过 /*+ ... */ 注释的形式跟在 SELECT、UPDATE 或 DELETE 关键字的后面，常见形式如 /*+ HINT_NAME([t1_name [, t2_name] ...]) */。Hint 名称不区分大小写，多个不同的 Hint 之间需用逗号隔开。例如：
 select /*+ USE_INDEX(t1, idx1), HASH_AGG(), HASH_JOIN(t1) */ count(*) from t t1, t t2 where t1.</description>
    </item>
    
    <item>
      <title>Overview 面板重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/overview-dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/overview-dashboard/</guid>
      <description>Overview 面板重要监控指标详解 使用 Ansible 部署 TiDB 集群时，一键部署监控系统 (Prometheus/Grafana)，监控架构请看 TiDB 监控框架概述。
目前 Grafana Dashboard 整体分为 PD、TiDB、TiKV、Node_exporter、Overview 等。
对于日常运维，我们单独挑选出重要的 Metrics 放在 Overview 页面，方便日常运维人员观察集群组件 (PD, TiDB, TiKV) 使用状态以及集群使用状态。
以下为 Overview Dashboard 监控说明：
Services Port Status  Services Online：各服务在线节点数量 Services Offline：各服务 Down 掉节点数量  PD  Storage Capacity：TiDB 集群总可用数据库空间大小 Current Storage Size：TiDB 集群目前已用数据库空间大小 Number of Regions：当前集群的 Region 总量 Leader Balance Ratio：Leader 数量最多和最少节点相差的百分比，一般小于 5%，节点重启时会有比较大的波动 Region Balance Ratio：Region 数量最多和最少节点相差的百分比，一般小于 5%，新增/下线节点时相差比较大 Store Status：集群 TiKV 节点的状态  Up Stores：正常运行的 TiKV 节点数量 Disconnect Stores：短时间内通信异常的 TiKV 节点数量 LowSpace Stores：剩余可用空间小于 20% 的 TiKV 节点数量 Down Stores：停止工作的 TiKV 节点数量，如果大于 0，说明有节点不正常 Offline Stores：正在下线的 TiKV 节点数量（正在下线的 TiKV 节点还在提供服务） Tombstone Stores：下线成功的 TiKV 节点数量   99% completed_cmds_duration_seconds：单位时间内，99% 的 pd-server 请求执行时间小于监控曲线的值，一般 &amp;lt;= 5ms handle_requests_duration_seconds：PD 发送请求的网络耗时  TiDB  Statement OPS：SQL 执行数量统计（包含 select、insert、update 等） Duration：SQL 执行的时间 QPS By Instance：每个 TiDB 上的 QPS Failed Query OPM：失败 SQL 的统计，例如语法错误、主键冲突等 Connection count：每个 TiDB 的连接数 Heap Memory Usage：每个 TiDB 使用的堆内存大小 Transaction OPS：事务执行数量统计 Transaction Duration：事务执行的时间 KV Cmd OPS：KV 命令执行数量统计 KV Cmd Duration 99：KV 命令执行的时间 PD TSO OPS：TiDB 从 PD 获取 TSO 的数量 PD TSO Wait Duration：TiDB 从 PD 获取 TS 的时间 TiClient Region Error OPS：TiKV 返回 Region 相关错误信息的数量 Lock Resolve OPS：事务冲突相关的数量 Load Schema Duration：TiDB 从 TiKV 获取 Schema 的时间 KV Backoff OPS：TiKV 返回错误信息的数量（事务冲突等）  TiKV  leader：各个 TiKV 节点上 Leader 的数量分布 region：各个 TiKV 节点上 Region 的数量分布 CPU：各个 TiKV 节点的 CPU 使用率 Memory：各个 TiKV 节点的内存使用量 store size：各个 TiKV 节点存储的数据量 cf size：集群不同 CF 存储的数据量 channel full：正常情况显示 No data，如果有了监控值，说明对应 TiKV 节点的消息处理不过来了 server report failures：正常情况显示 No data，如果出现了 Unreachable，说明 TiKV 之间通信有问题 scheduler pending commands：写入堆积的数量，偶尔出现峰值属于正常现象 coprocessor pending requests：正常情况监控为 0 或者数量很少 coprocessor executor count：不同类型的查询操作数量 coprocessor request duration：TiKV 中查询消耗的时间 raft store CPU：raftstore 线程的 CPU 使用率，线程数量默认为 2 (通过 raftstore.</description>
    </item>
    
    <item>
      <title>PD Control 使用说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/pd-control/</guid>
      <description>PD Control 使用说明 PD Control 是 PD 的命令行工具，用于获取集群状态信息和调整集群。
源码编译  Go Version 1.9 以上 在 PD 项目根目录使用 make 命令进行编译，生成 bin/pd-ctl  下载安装包 如需下载最新版本的 pd-ctl，直接下载 TiDB 安装包即可，因为 pd-ctl 包含在 TiDB 安装包中。
   安装包 操作系统 架构 SHA256 校验和     https://download.pingcap.org/tidb-{version}-linux-amd64.tar.gz (pd-ctl) Linux amd64 https://download.pingcap.org/tidb-{version}-linux-amd64.sha256     注意：
下载链接中的 {version} 为 TiDB 的版本号。例如 latest 版本的下载链接为 https://download.pingcap.org/tidb-latest-linux-amd64.tar.gz。也可以使用 latest 替代 {version} 来下载最新的未发布版本。
 简单例子 单命令模式：
 ./pd-ctl store -u http://127.</description>
    </item>
    
    <item>
      <title>PD Recover 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/pd-recover/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/pd-recover/</guid>
      <description>PD Recover 使用文档 PD Recover 是对 PD 进行灾难性恢复的工具，用于恢复无法正常启动或服务的 PD 集群。
源码编译  Go Version 1.9 以上 在 PD 项目根目录使用 make 命令进行编译，生成 bin/pd-recover  使用方法 参数说明 -alloc-id uint指定比原集群已分配过的 ID 更大的数-cacert string指定 PEM 格式的受信任 CA 的证书文件路径-cert string指定 PEM 格式的 SSL 证书文件路径-key string指定 PEM 格式的 SSL 证书密钥文件路径，即 `--cert` 所指定的证书的私钥-cluster-id uint指定原集群的 cluster ID-endpoints string指定 PD 的地址 (default &amp;#34;http://127.0.0.1:2379&amp;#34;)恢复流程  从当前集群中找到集群的 Cluster ID 和 Alloc ID。一般在 PD，TiKV 或 TiDB 的日志中都可以获取 Cluster ID。已经分配过的 Alloc ID 可以从 PD 日志获得。另外也可以从 PD 的监控面板的 Metadata Information 监控项中获得。在指定 alloc-id 时需指定一个比当前最大的 Alloc ID 更大的值。如果没有途径获取 Alloc ID，可以根据集群中的 Region，Store 数预估一个较大的数，一般可取高几个数量级的数。 停止整个集群，清空 PD 数据目录，重启 PD 集群。 使用 PD recover 进行恢复，注意指定正确的 cluster-id 和合适的 alloc-id。 提示恢复成功后，重启整个集群。  </description>
    </item>
    
    <item>
      <title>PD 调度策略最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/pd-scheduling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/pd-scheduling/</guid>
      <description>了解 PD 调度策略的最佳实践和调优方式</description>
    </item>
    
    <item>
      <title>PD 配置参数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/pd-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/pd-server/configuration/</guid>
      <description>PD 配置参数 PD 可以通过命令行参数或环境变量配置。
--advertise-client-urls  对外客户端访问 URL 列表。 默认：${client-urls} 在某些情况下，譬如 docker，或者 NAT 网络环境，客户端并不能通过 PD 自己监听的 client URLs 来访问到 PD，这时候，你就可以设置 advertise urls 来让客户端访问 例如，docker 内部 IP 地址为 172.17.0.1，而宿主机的 IP 地址为 192.168.100.113 并且设置了端口映射 -p 2379:2379，那么可以设置为 --advertise-client-urls=&amp;quot;http://192.168.100.113:2379&amp;quot;，客户端可以通过 http://192.168.100.113:2379 来找到这个服务。  --advertise-peer-urls  对外其他 PD 节点访问 URL 列表。 默认：${peer-urls} 在某些情况下，譬如 docker，或者 NAT 网络环境，其他节点并不能通过 PD 自己监听的 peer URLs 来访问到 PD，这时候，你就可以设置 advertise urls 来让其他节点访问 例如，docker 内部 IP 地址为 172.17.0.1，而宿主机的 IP 地址为 192.168.100.113 并且设置了端口映射 -p 2380:2380，那么可以设置为 --advertise-peer-urls=&amp;quot;http://192.</description>
    </item>
    
    <item>
      <title>PD 配置文件描述</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/pd-server/configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/pd-server/configuration-file/</guid>
      <description>PD 配置文件描述 PD 配置文件比命令行参数支持更多的选项。你可以在 conf/config.toml 找到默认的配置文件。
本文档只阐述未包含在命令行参数中的参数，命令行参数参见 PD 配置参数。
lease  PD Leader Key 租约超时时间，超时系统重新选举 Leader。 默认：3 单位：秒  tso-save-interval  TSO 分配的时间窗口,实时持久存储。 默认：3s  initial-cluster-state  集群初始状态 默认：new  enable-prevote  开启 raft prevote 的开关。 默认：true  quota-backend-bytes  元信息数据库存储空间的大小，默认 2GB。 默认：2147483648  auto-compaction-mod  元信息数据库自动压缩的模式，可选项为 periodic（按周期），revision（按版本数）。 默认：periodic  auto-compaction-retention  compaction-mode 为 periodic 时为元信息数据库自动压缩的间隔时间；compaction-mode 设置为 revision 时为自动压缩的版本数。 默认：1h  force-new-cluster  强制让该 PD 以一个新集群启动，且修改 raft 成员数为 1。 默认：false  tick-interval  etcd raft 的 tick 周期。 默认：100ms  election-interval  etcd leader 选举的超时时间。 默认：3s  use-region-storage  开启独立的 region 存储。 默认：false  security 安全相关配置项。</description>
    </item>
    
    <item>
      <title>PD 重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/pd-dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/pd-dashboard/</guid>
      <description>PD 重要监控指标详解 使用 Ansible 部署 TiDB 集群时，一键部署监控系统 (Prometheus/Grafana)，监控架构请看 TiDB 监控框架概述。
目前 Grafana Dashboard 整体分为 PD、TiDB、TiKV、Node_exporter、Overview 等。
对于日常运维，我们通过观察 PD 面板上的 Metrics，可以了解 PD 当前的状态。
以下为 PD Dashboard 监控说明：
Cluster  PD role：当前 PD 的角色 Storage capacity：TiDB 集群总可用数据库空间大小 Current storage size：TiDB 集群目前已用数据库空间大小 Current storage usage：TiDB 集群存储空间的使用率 Normal stores：处于正常状态的节点数目 Number of Regions：当前集群的 Region 总量 PD scheduler config：PD 调度配置列表 Region label isolation level：不同 label 所在的 level 的 Region 数量 Label distribution：集群中 TiKV 节点的 label 分布情况 Abnormal stores：处于异常状态的节点数目，正常情况应当为 0 pd_cluster_metadata：记录集群 ID，时间戳和生成的 ID Current peer count：当前集群 peer 的总量 Region health：每个 Region 的状态，通常情况下，pending 的 peer 应该少于 100，miss 的 peer 不能一直大于 0  Operator  Schedule operator create：新创建的不同 operator 的数量 Schedule operator check：已检查的 operator 的数量，主要检查是否当前步骤已经执行完成，如果是，则执行下一个步骤 Schedule operator finish：已完成调度的 operator 的数量 Schedule operator timeout：已超时的 operator 的数量 Schedule operator replaced or canceled：已取消或者被替换的 operator 的数量 Schedule operators count by state：不同状态的 operator 的数量 99% Operator finish duration：99% 已完成 operator 所花费的最长时间 50% Operator finish duration：50% 已完成 operator 所花费的最长时间 99% Operator step duration：99% 已完成的 operator 步骤所花费的最长时间 50% Operator step duration：50% 已完成的 operator 步骤所花费的最长时间  Statistics - Balance  Store capacity：每个 TiKV 实例的总的空间大小 Store available：每个 TiKV 实例的可用空间大小 Store used：每个 TiKV 实例的已使用空间大小 Size amplification：每个 TiKV 实例的空间放大比率 Size available ratio：每个 TiKV 实例的可用空间比率 Store leader score：每个 TiKV 实例的 leader 分数 Store Region score：每个 TiKV 实例的 Region 分数 Store leader size：每个 TiKV 实例上所有 leader 的大小 Store Region size：每个 TiKV 实例上所有 Region 的大小 Store leader count：每个 TiKV 实例上所有 leader 的数量 Store Region count：每个 TiKV 实例上所有 Region 的数量  Statistics - hotspot  Hot write Region&#39;s leader distribution：每个 TiKV 实例上是写入热点的 leader 的数量 Hot write Region&#39;s peer distribution：每个 TiKV 实例上是写入热点的 peer 的数量 Hot write Region&#39;s leader written bytes：每个 TiKV 实例上热点的 leader 的写入大小 Hot write Region&#39;s peer written bytes：每个 TiKV 实例上热点的 peer 的写入大小 Hot read Region&#39;s leader distribution：每个 TiKV 实例上是读取热点的 leader 的数量 Hot read Region&#39;s peer distribution：每个 TiKV 实例上是读取热点的 peer 的数量 Hot read Region&#39;s leader read bytes：每个 TiKV 实例上热点的 leader 的读取大小 Hot read Region&#39;s peer read bytes：每个 TiKV 实例上热点的 peer 的读取字节数  Scheduler  Scheduler is running：所有正在运行的 scheduler Balance leader movement：leader 移动的详细情况 Balance Region movement：Region 移动的详细情况 Balance leader event：balance leader 的事件数量 Balance Region event：balance Region 的事件数量 Balance leader scheduler：balance-leader scheduler 的状态 Balance Region scheduler：balance-region scheduler 的状态 Namespace checker：namespace checker 的状态 Replica checker：replica checker 的状态 Region merge checker：merge checker 的状态 Filter target：尝试选择 Store 作为调度 taget 时没有通过 Filter 的计数 Filter source：尝试选择 Store 作为调度 source 时没有通过 Filter 的计数 Balance Direction：Store 被选作调度 target 或 source 的次数 Store Limit：Store 的调度限流状态  gRPC  Completed commands rate：gRPC 命令的完成速率 99% Completed commands duration：99% 命令的最长消耗时间  etcd  Handle transactions count：etcd 的事务个数 99% Handle transactions duration：99% 的情况下，处理 etcd 事务所需花费的时间 99% WAL fsync duration：99% 的情况下，持久化 WAL 所需花费的时间，这个值通常应该小于 1s 99% Peer round trip time seconds：99% 的情况下，etcd 的网络延时，这个值通常应该小于 1s etcd disk WAL fsync rate：etcd 持久化 WAL 的速率 Raft term：当前 Raft 的 term Raft committed index：最后一次 commit 的 Raft index Raft applied index：最后一次 apply 的 Raft index  TiDB  Handle requests count：TiDB 的请求数量 Handle requests duration：每个请求所花费的时间，99% 的情况下，应该小于 100ms  Heartbeat  Region heartbeat report：TiKV 向 PD 发送的心跳个数 Region heartbeat report error：TiKV 向 PD 发送的异常的心跳个数 Region heartbeat report active：TiKV 向 PD 发送的正常的心跳个数 Region schedule push：PD 向 TiKV 发送的调度命令的个数 99% Region heartbeat latency：99% 的情况下，心跳的延迟  Region storage  Syncer Index：Leader 记录 Region 变更历史的最大 index history last index：Follower 成功同步的 Region 变更历史的 index  </description>
    </item>
    
    <item>
      <title>PREPARE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/prepare/</guid>
      <description>TiDB 数据库中 PREPARE 的使用概况。</description>
    </item>
    
    <item>
      <title>RECOVER TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/recover-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/recover-table/</guid>
      <description>RECOVER TABLE RECOVER TABLE 的功能是恢复被删除的表及其数据。在 DROP TABLE 后，在 GC life time 时间内，可以用 RECOVER TABLE 语句恢复被删除的表以及其数据。
语法  RECOVER TABLE table_name  RECOVER TABLE BY JOB ddl_job_id 注意事项 如果删除表后并过了 GC lifetime，就不能再用 RECOVER TABLE 来恢复被删除的表了，执行 RECOVER TABLE 语句会返回类似错误：snapshot is older than GC safe point 2019-07-10 13:45:57 +0800 CST。
对于 3.0.0 及之后的 TiDB 版本，不推荐在使用 TiDB Binlog 的情况下使用 RECOVER TABLE 功能。
TiDB Binlog 在 3.0.1 支持 RECOVER TABLE 后，可在下面的情况下使用 RECOVER TABLE：
 3.0.1+ 版本的 TiDB Binlog 主从集群都使用 TiDB 3.</description>
    </item>
    
    <item>
      <title>RENAME INDEX</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rename-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rename-index/</guid>
      <description>TiDB 数据库中 RENAME INDEX 的使用概况。</description>
    </item>
    
    <item>
      <title>RENAME TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rename-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rename-table/</guid>
      <description>TiDB 数据库中 RENAME TABLE 的使用概况。</description>
    </item>
    
    <item>
      <title>Reparo 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/reparo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/reparo/</guid>
      <description>Reparo 使用文档 Reparo 是 TiDB Binlog 的一个配套工具，用于增量的恢复。使用 TiDB Binlog 中的 Drainer 将 binlog 按照 protobuf 格式输出到文件，通过这种方式来备份增量数据。当需要恢复增量数据时，使用 Reparo 解析文件中的 binlog，并将其应用到 TiDB／MySQL 中。
下载链接：tidb-binlog-cluster-latest-linux-amd64.tar.gz
Reparo 使用 命令行参数说明 Usage of Reparo: -L string 日志输出信息等级设置：debug, info, warn, error, fatal（默认值：info）。 -V 打印版本信息。 -c int 同步下游的并发数，该值设置越高同步的吞吐性能越好（默认 16）。 -config string 配置文件路径，如果指定了配置文件，Reparo 会首先读取配置文件的配置；如果对应的配置在命令行参数里面也存在，Reparo 就会使用命令行参数的配置来覆盖配置文件里面的。 -data-dir string Drainer 输出的 protobuf 格式 binlog 文件的存储路径 (默认值： data.drainer)。 -dest-type string 下游服务类型。 取值为 print, mysql（默认值：print）。当值为 print 时，只做解析打印到标准输出，不执行 SQL；如果为 mysql，则需要在配置文件内配置 host、port、user、password 等信息。 -log-file string log 文件路径。 -log-rotate string log 文件切换频率，取值为 hour、day。 -start-datetime string 用于指定开始恢复的时间点，格式为 “2006-01-02 15:04:05”。如果不设置该参数则从最早的 binlog 文件开始恢复。 -stop-datetime string 用于指定结束恢复的时间点，格式同上。如果不设置该参数则恢复到最后一个 binlog 文件。 -safe-mode bool 指定是否开启安全模式，开启后可支持反复同步。 -txn-batch int 输出到下游数据库一个事务的 SQL 语句数量（默认 20）。 配置文件说明 # Drainer 输出的 protobuf 格式 binlog 文件的存储路径。 data-dir = &amp;#34;.</description>
    </item>
    
    <item>
      <title>REPLACE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/replace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/replace/</guid>
      <description>TiDB 数据库中 REPLACE 的使用概况。</description>
    </item>
    
    <item>
      <title>REVOKE &lt;privileges&gt;</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/revoke-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/revoke-privileges/</guid>
      <description>&lt;p&gt;TiDB 数据库中 REVOKE &lt;privileges&gt; 的使用概况。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ROLLBACK</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rollback/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/rollback/</guid>
      <description>TiDB 数据库中 ROLLBACK 的使用概况。</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/schema-object-names/</guid>
      <description>Schema Object Names 在 TiDB 中，包括 database，table，index，column，alias 等等都被认为是 identifier (标识符，之后阐述用英文).
在 TiDB 中，identifier可以被反引号 (`) 包裹，为了阐述方便，我们叫这种情况为 被引用。identifier 也可以不被 ` 包裹。但是如果一个 identifier 存在一个特殊符号或者是一个保留关键字，那么你必须要 引用 它。
 SELECT * FROM `table` WHERE `table`.id = 20; 如果ANSI_QUOTES sql mode 被设置了，那么我们认为被双引号 &amp;quot; 包裹的字符串为 identifier。
 CREATE TABLE &amp;#34;test&amp;#34; (a varchar(10)); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a varchar(10))&amp;#34; (total length 35)  SET SESSION sql_mode=&amp;#39;ANSI_QUOTES&amp;#39;; Query OK, 0 rows affected (0.00 sec)  CREATE TABLE &amp;#34;test&amp;#34; (a varchar(10)); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>SELECT</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/select/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/select/</guid>
      <description>TiDB 数据库中 SELECT 的使用概况。</description>
    </item>
    
    <item>
      <title>SET [GLOBAL|SESSION] &lt;variable&gt;</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-variable/</guid>
      <description>TiDB 数据库中 SET [GLOBAL|SESSION] &lt;variable&gt; 的使用概况。</description>
    </item>
    
    <item>
      <title>SET [NAMES|CHARACTER SET]</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-names/</guid>
      <description>TiDB 数据库中 SET [NAMES|CHARACTER SET] 的使用概况。</description>
    </item>
    
    <item>
      <title>SET PASSWORD</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-password/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-password/</guid>
      <description>TiDB 数据库中 SET PASSWORD 的使用概况。</description>
    </item>
    
    <item>
      <title>SET TRANSACTION</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/set-transaction/</guid>
      <description>TiDB 数据库中 SET TRANSACTION 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [FULL] COLUMNS FROM</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-columns-from/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-columns-from/</guid>
      <description>TiDB 数据库中 SHOW [FULL] COLUMNS FROM 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [FULL] FIELDS FROM</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-fields-from/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-fields-from/</guid>
      <description>TiDB 数据库中 SHOW [FULL] FIELDS FROM 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [FULL] PROCESSLIST</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-processlist/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-processlist/</guid>
      <description>TiDB 数据库中 SHOW [FULL] PROCESSLIST 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [FULL] TABLES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-tables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-tables/</guid>
      <description>TiDB 数据库中 SHOW [FULL] TABLES 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [GLOBAL|SESSION] STATUS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-status/</guid>
      <description>TiDB 数据库中 SHOW [GLOBAL|SESSION] STATUS 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW [GLOBAL|SESSION] VARIABLES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-variables/</guid>
      <description>TiDB 数据库中 SHOW [GLOBAL|SESSION] VARIABLES 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW CHARACTER SET</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-character-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-character-set/</guid>
      <description>TiDB 数据库中 SHOW CHARACTER SET 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW COLLATION</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-collation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-collation/</guid>
      <description>TiDB 数据库中 SHOW COLLATION 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW CREATE TABLE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-create-table/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-create-table/</guid>
      <description>TiDB 数据库中 SHOW CREATE TABLE 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW CREATE USER</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-create-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-create-user/</guid>
      <description>TiDB 数据库中 SHOW CREATE USER 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW DATABASES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-databases/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-databases/</guid>
      <description>TiDB 数据库中 SHOW DATABASES 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW ENGINES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-engines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-engines/</guid>
      <description>TiDB 数据库中 SHOW ENGINES 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW ERRORS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-errors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-errors/</guid>
      <description>TiDB 数据库中 SHOW ERRORS 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW GRANTS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-grants/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-grants/</guid>
      <description>TiDB 数据库中 SHOW GRANTS 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW INDEX [FROM|IN]</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-index/</guid>
      <description>TiDB 数据库中 SHOW INDEX [FROM|IN] 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW INDEXES [FROM|IN]</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-indexes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-indexes/</guid>
      <description>TiDB 数据库中 SHOW INDEXES [FROM|IN] 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW KEYS [FROM|IN]</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-keys/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-keys/</guid>
      <description>TiDB 数据库中 SHOW KEYS [FROM|IN] 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW PRIVILEGES</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-privileges/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-privileges/</guid>
      <description>TiDB 数据库中 SHOW PRIVILEGES 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW SCHEMAS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-schemas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-schemas/</guid>
      <description>TiDB 数据库中 SHOW SCHEMAS 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW TABLE REGIONS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-table-regions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-table-regions/</guid>
      <description>了解如何使用 TiDB 数据库中的 SHOW TABLE REGIONS。</description>
    </item>
    
    <item>
      <title>SHOW TABLE STATUS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-table-status/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-table-status/</guid>
      <description>TiDB 数据库中 SHOW TABLE STATUS 的使用概况。</description>
    </item>
    
    <item>
      <title>SHOW WARNINGS</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-warnings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/show-warnings/</guid>
      <description>TiDB 数据库中 SHOW WARNINGS 的使用概况。</description>
    </item>
    
    <item>
      <title>Split Region 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/split-region/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/split-region/</guid>
      <description>Split Region 使用文档 在 TiDB 中新建一个表后，默认会单独切分出 1 个 Region 来存储这个表的数据，这个默认行为由配置文件中的 split-table 控制。当这个 Region 中的数据超过默认 Region 大小限制后，这个 Region 会开始分裂成 2 个 Region。
上述情况中，如果在新建的表上发生大批量写入，则会造成热点，因为开始只有一个 Region，所有的写请求都发生在该 Region 所在的那台 TiKV 上。
为解决上述场景中的热点问题，TiDB 引入了预切分 Region 的功能，即可以根据指定的参数，预先为某个表切分出多个 Region，并打散到各个 TiKV 上去。
Split Region 的使用 Split Region 有 2 种不同的语法，具体如下：
SPLIT TABLE table_name [INDEX index_name] BETWEEN (lower_value) AND (upper_value) REGIONS region_num BETWEEN lower_value AND upper_value REGIONS region_num 语法是通过指定上、下边界和 Region 数量，然后在上、下边界之间均匀切分出 region_num 个 Region。
SPLIT TABLE table_name [INDEX index_name] BY (value_list) [, (value_list)] .</description>
    </item>
    
    <item>
      <title>SQL Mode</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/sql-mode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/sql-mode/</guid>
      <description>SQL 模式 TiDB 服务器采用不同 SQL 模式来操作，且不同客户端可以应用不同模式。SQL 模式定义 TiDB 支持哪些 SQL 语法及执行哪种数据验证检查.
TiDB 启动之前采用修改 --sql-mode=&amp;quot;modes&amp;quot; 配项设置 SQL 模式。
TiDB 启动之后采用 SET [ SESSION | GLOBAL ] sql_mode=&#39;modes&#39;设置 SQL 模式。设置 GLOBAL 级别的 SQL 模式时用户需要有 SUPER 权限，并且只会影响到从设置 SQL 模式开始后续新建立的连接（注：老连接不受影响)。 SESSION 级别的 SQL 模式的变化只会影响当前的客户端。
Modes 是用逗号 (&#39;,&#39;) 间隔开的一系列不同的模式。使用 SELECT @@sql_mode 语句查询当前 SQL 模式，SQL 模式默认值：ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION。
重要的 sql_mode 值  ANSI: 符合标准 SQL ，对数据进行校验，如果不符合定义类型或长度，对数据类型调整或截断保存，且返回warning警告。 STRICT_TRANS_TABLES: 严格模式，对数据进严格校验，但数据出现错误时，插入到表中，并且返回错误。 TRADITIONAL: 采用此模式使 TiDB 的行为象 &amp;ldquo;传统&amp;rdquo; SQL 数据库系统，当在列中插入不正确的值时“给出错误而不是警告”，一旦发现错误立即放弃INSERT/UPDATE。  SQL mode 列表    名称 含义     PIPES_AS_CONCAT 将 &amp;ldquo;||&amp;rdquo; 视为字符串连接操作符（＋）(同CONCAT())，而不视为OR（支持)   ANSI_QUOTES 将 &amp;quot; 视为识别符，如果启用 ANSI_QUOTES，只单引号内的会被认为是 String Literals，双引号被解释为识别符，因此不能用双引号来引用字符串（支持）   IGNORE_SPACE 若开启该模式，系统忽略空格。例如：“user” 和 “user “ 是相同的（支持）   ONLY_FULL_GROUP_BY 如果 GROUP BY 出现的列并没有在 SELECT，HAVING，ORDER BY 中出现，此 SQL 不合法，因为不在 GROUP BY 中的列被查询展示出来不符合正常现象 （支持)   NO_UNSIGNED_SUBTRACTION 在减运算中，如果某个操作数没有符号，不要将结果标记为UNSIGNED （支持）   NO_DIR_IN_CREATE 创建表时，忽视所有 INDEX DIRECTORY 和 DATA DIRECTORY 指令，该选项仅对从复制服务器有用 （仅语法支持）   NO_KEY_OPTIONS 使用 SHOW CREATE TABLE 时不会输出 MySQL 特有的语法部分，如 ENGINE ，使用 mysqldump 跨DB种类迁移的时需要考虑此选项（仅语法支持）   NO_FIELD_OPTIONS 使用 SHOW CREATE TABLE 时不会输出 MySQL 特有的语法部分，如 ENGINE ，使用 mysqldump 跨DB种类迁移的时需要考虑此选项（仅语法支持）   NO_TABLE_OPTIONS 使用 SHOW CREATE TABLE 时不会输出 MySQL 特有的语法部分，如 ENGINE ，使用 mysqldump 跨DB种类迁移的时需要考虑此选项（仅语法支持）   NO_AUTO_VALUE_ON_ZERO 若启用该模式，在AUTO_INCREMENT列的处理传入的值是 0 或者具体数值时系统直接将该值写入此列，传入 NULL 时系统自动生成下一个序列号（支持）   NO_BACKSLASH_ESCAPES 若启用该模式，\ 反斜杠符号仅代表它自己（支持）   STRICT_TRANS_TABLES 对于事务存储引擎启用严格模式，insert非法值之后，回滚整条语句（支持）   STRICT_ALL_TABLES 对于事务型表，写入非法值之后，回滚整个事务语句（支持）   NO_ZERO_IN_DATE 在严格模式，不接受月或日部分为0的日期。如果使用IGNORE选项，我们为类似的日期插入&#39;0000-00-00&amp;rsquo;。在非严格模式，可以接受该日期，但会生成警告 （支持）   NO_ZERO_DATE 在严格模式，不要将 &amp;lsquo;0000-00-00&#39;做为合法日期。你仍然可以用IGNORE选项插入零日期。在非严格模式，可以接受该日期，但会生成警告 （支持）   ALLOW_INVALID_DATES 不检查全部日期的合法性，仅检查月份值在 1 到 12 及 日期值在 1 到31 之间，仅适用于 DATE 和 DATATIME 列，TIMESTAMP 列需要全部检查其合法性 （支持）   ERROR_FOR_DIVISION_BY_ZERO 若启用该模式，在 INSERT 或 UPDATE 过程中，被除数为 0 值时，系统产生错误 若未启用该模式，被除数为 0 值时，系统产生警告，并用 NULL 代替 （支持）   NO_AUTO_CREATE_USER 防止GRANT自动创建新用户，但指定密码除外 （支持）   HIGH_NOT_PRECEDENCE NOT 操作符的优先级是表达式。例如： NOT a BETWEEN b AND c 被解释为 NOT (a BETWEEN b AND c)。在部份旧版本MySQL中， 表达式被解释为(NOT a) BETWEEN b AND c (支持)   NO_ENGINE_SUBSTITUTION 如果需要的存储引擎被禁用或未编译，可以防止自动替换存储引擎 （仅语法支持）   PAD_CHAR_TO_FULL_LENGTH 若启用该模式，系统对于 CHAR 类型不会截断尾部空格（支持）   REAL_AS_FLOAT 将REAL视为FLOAT的同义词，而不是DOUBLE的同义词 （支持）   POSTGRESQL 等同于 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS （支持）   MSSQL 等同于 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、 NO_FIELD_OPTIONS （支持）   DB2 等同于 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS （支持）   MAXDB 等同于 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS、NO_AUTO_CREATE_USER （支持）   MySQL323 等同于 NO_FIELD_OPTIONS、HIGH_NOT_PRECEDENCE (支持)   MYSQL40 等同于 NO_FIELD_OPTIONS、HIGH_NOT_PRECEDENCE （支持）   ANSI 等同于 REAL_AS_FLOAT、PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE （支持）   TRADITIONAL 等同于 STRICT_TRANS_TABLES、STRICT_ALL_TABLES、NO_ZERO_IN_DATE、NO_ZERO_DATE、ERROR_FOR_DIVISION_BY_ZERO、NO_AUTO_CREATE_USER(支持)   ORACLE 等同于 PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、NO_FIELD_OPTIONS、NO_AUTO_CREATE_USER （支持）    </description>
    </item>
    
    <item>
      <title>SQL 优化流程简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/sql-optimizer-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/sql-optimizer-overview/</guid>
      <description>SQL 优化流程简介 在 TiDB 中，SQL 优化过程分为逻辑优化和物理优化两个阶段。
逻辑优化简介 逻辑优化是基于规则的优化，对输入的逻辑执行计划按顺序应用一些优化规则，从而使整个逻辑执行计划变得更好。这些优化规则包括：
 列裁剪 投影消除 关联子查询去关联 Max/Min 消除 谓词下推 分区裁剪 TopN 和 Limit 下推  物理优化简介 物理优化是基于代价的优化，为上一阶段产生的逻辑执行计划制定物理执行计划。这一阶段中，优化器会为逻辑执行计划中的每个算子选择具体的物理实现。逻辑算子的不同物理实现有着不同的时间复杂度、资源消耗和物理属性等。在这个过程中，优化器会根据数据的统计信息来确定不同物理实现的代价，并选择整体代价最小的物理执行计划。
逻辑执行计划是一个树形结构，每个节点对应 SQL 中的一个逻辑算子。同样的，物理执行计划也是一个树形结构，每个节点对应 SQL 中的一个物理算子。逻辑算子只描述这个算子的功能，而物理算子则描述了完成这个功能的具体算法。对于同一个逻辑算子，可能有多个物理算子实现，比如 LogicalAggregate，它的实现可以是采用哈希算法的 HashAggregate，也可以是流式的 StreamAggregate。不同的物理算子具有不同的物理属性，也对其子节点有着不同的物理属性的要求。物理属性包括数据的顺序和分布等。TiDB 中现在只考虑了数据的顺序。</description>
    </item>
    
    <item>
      <title>START TRANSACTION</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/start-transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/start-transaction/</guid>
      <description>TiDB 数据库中 START TRANSACTION 的使用概况。</description>
    </item>
    
    <item>
      <title>Statement Summary Tables</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/statement-summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/statement-summary/</guid>
      <description>Statement Summary Tables 针对 SQL 性能相关的问题，MySQL 在 performance_schema 提供了 statement summary tables，用来监控和统计 SQL。例如其中的一张表 events_statements_summary_by_digest，提供了丰富的字段，包括延迟、执行次数、扫描行数、全表扫描次数等，有助于用户定位 SQL 问题。
为此，从 3.1.0-beta 版本开始，TiDB 也提供系统表 events_statements_summary_by_digest，从 3.1.0-beta.1 开始提供系统表 events_statements_summary_by_digest_history。本文将详细介绍这两张表，以及如何利用它们来排查 SQL 性能问题。
events_statements_summary_by_digest events_statements_summary_by_digest 是 performance_schema 里的一张系统表，它把 SQL 按 SQL digest 和 plan digest 分组，统计每一组的 SQL 信息。
此处的 SQL digest 与 slow log 里的 SQL digest 一样，是把 SQL 规一化后算出的唯一标识符。SQL 的规一化会忽略常量、空白符、大小写的差别。即语法一致的 SQL 语句，其 digest 也相同。
例如：
SELECT * FROM employee WHERE id IN (1, 2, 3) AND salary BETWEEN 1000 AND 2000; select * from EMPLOYEE where ID in (4, 5) and SALARY between 3000 and 4000; 规一化后都是：</description>
    </item>
    
    <item>
      <title>sync-diff-inspector 用户文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/overview/</guid>
      <description>sync-diff-inspector 用户文档 sync-diff-inspector 是一个用于校验 MySQL／TiDB 中两份数据是否一致的工具。该工具提供了修复数据的功能（适用于修复少量不一致的数据）。
主要功能：
 对比表结构和数据 如果数据不一致，则生成用于修复数据的 SQL 语句 支持不同库名或表名的数据校验 支持分库分表场景下的数据校验 支持 TiDB 主从集群的数据校验  GitHub 地址：sync-diff-inspector
下载地址：tidb-enterprise-tools-latest-linux-amd64
sync-diff-inspector 的使用 使用限制   目前不支持在线校验，需要保证上下游校验的表中没有数据写入，或者保证某个范围内的数据不再变更，通过配置 range 来校验这个范围内的数据。
  不支持 JSON、BIT、BINARY、BLOB 等类型的数据，在校验时需要设置 ignore-columns 忽略检查这些类型的数据。
  FLOAT、DOUBLE 等浮点数类型在 TiDB 和 MySQL 中的实现方式不同，在计算 checksum 时可能存在差异，如果发现因为这些类型的数据导致的数据校验不一致，需要设置 ignore-columns 忽略这些列的检查。
  数据库权限 sync-diff-inspector 需要获取表结构信息、查询数据、建 checkpoint 库保存断点信息，需要的数据库权限如下：
  上游数据库
  SELECT（查数据进行对比）
  SHOW_DATABASES (查看库名)
  RELOAD (查看表结构)
    下游数据库</description>
    </item>
    
    <item>
      <title>Syncer 使用文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/syncer/</guid>
      <description>Syncer 使用文档 Syncer 简介 Syncer 是一个数据导入工具，能方便地将 MySQL 的数据增量导入到 TiDB。
Syncer 包含在 tidb-enterprise-tools 安装包中，可在此下载。
Syncer 架构 Syncer 部署位置 Syncer 可以部署在任一台可以连通对应的 MySQL 和 TiDB 集群的机器上，推荐部署在 TiDB 集群。
Syncer 增量导入数据示例 使用前请详细阅读 Syncer 同步前预检查。
设置同步开始的 position 设置 Syncer 的 meta 文件, 这里假设 meta 文件是 syncer.meta:
 cat syncer.meta binlog-name = &amp;#34;mysql-bin.000003&amp;#34; binlog-pos = 930143241 binlog-gtid = &amp;#34;2bfabd22-fff7-11e6-97f7-f02fa73bcb01:1-23,61ccbb5d-c82d-11e6-ac2e-487b6bd31bf7:1-4&amp;#34;  注意：
 syncer.meta 只需要第一次使用的时候配置，后续 Syncer 同步新的 binlog 之后会自动将其更新到最新的 position。 如果使用 binlog position 同步则只需要配置 binlog-name 和 binlog-pos；如果使用 binlog-gtid 同步则需要设置 binlog-gtid，且启动 Syncer 时带有 --enable-gtid。   启动 Syncer Syncer 的命令行参数说明：</description>
    </item>
    
    <item>
      <title>Table Selector</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/table-selector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/table-selector/</guid>
      <description>介绍 DM 的 Table Selector</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes 2017 年 10 月 16 日，TiDB 发布 GA 版（TiDB 1.0）。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB   SQL 查询优化器
 调整代价模型 Analyze 下推 函数签名下推    优化内部数据格式，减小中间结果大小
  提升 MySQL 兼容性
  支持 NO_SQL_CACHE 语法，控制存储引擎对缓存的使用
  重构 Hash Aggregator 算子，降低内存使用
  支持 Stream Aggragator 算子
  PD  支持基于读流量的热点调度 支持设置 Store 权重，以及基于权重的调度  TiKV  Coprocessor 支持更多下推函数 支持取样操作下推 支持手动触发数据 Compact，用于快速回收空间 提升性能和稳定性 增加 Debug API，方便调试  TiSpark Beta Release  支持可配置框架 支持 ThriftSever/JDBC 和 Spark SQL 脚本入口  源码地址 源码地址</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/11alpha/</guid>
      <description>TiDB 1.1 Alpha Release Notes 2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL parser  兼容更多语法   SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确地估算点查的代价 支持更复杂的条件，更充分使用索引   SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT IGNORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计   Server  支持 PROXY protocol    PD  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 Region size Fix 了一些调度的 bug  TiKV  支持 Raft learner 优化 Raft Snapshot，减少 I/O 开销 支持 TLS 优化 RocksDB 配置，提升性能 优化 Coprocessor count (*) 和点查 unique index 的性能 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 tikv-ctl 的功能 Region 支持按 table 进行分裂 支持 Delete Range 功能 支持设置 snapshot 导致的 I/O 上限 完善流控机制  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/11beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/11beta/</guid>
      <description>TiDB 1.1 Beta Release Notes 2018 年 2 月 24 日，TiDB 发布 1.1 Beta 版。该版本在 1.1 Alpha 版的基础上，对 MySQL 兼容性、系统稳定性做了很多改进。
TiDB  添加更多监控项, 优化日志 兼容更多 MySQL 语法 在 information_schema 中支持显示建表时间 提速包含 MaxOneRow 算子的查询 控制 Join 产生的中间结果集大小，进一步减少 Join 的内存使用 增加 tidb_config session 变量，输出当前 TiDB 配置 修复 Union 和 Index Join 算子中遇到的 panic 问题 修复 Sort Merge Join 算子在部分场景下结果错误的问题 修复 Show Index 语句显示正在添加过程中的索引的问题 修复 Drop Stats 语句失败的问题 优化 SQL 引擎查询性能，Sysbench 的 Select/OLTP 测试结果提升 10% 使用新的执行引擎提升优化器中的子查询计算速度；相比 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2rc1/</guid>
      <description>TiDB 2.0 RC1 Release Notes 2018 年 3 月 9 日，TiDB 发布 2.0 RC1 版。该版本在上一版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  支持限制单条 SQL 语句使用内存的大小，减少程序 OOM 风险 支持下推流式聚合算子到 TiKV 支持配置文件的合法性检测 支持 HTTP API 获取 TiDB 参数信息 Parser 兼容更多 MySQL 语法 提升对 Navicat 的兼容性 优化器提升，提取多个 OR 条件的公共表达式，选取更优执行计划 优化器提升，在更多场景下将子查询转换成 Join 算子，选取更优查询计划 使用 Batch 方式 Resolve Lock，提升垃圾回收速度 修复 Boolean 类型的字段长度，提升兼容性 优化 Add Index 操作，所有的读写操作采用低优先级，减小对在线业务的影响  PD  优化检查 Region 状态的代码逻辑，提升程序性能 优化异常情况下日志信息输出，便于调试 修复监控中关于 TiKV 节点磁盘空间不足情况的统计 修复开启 TLS 时健康检查接口误报的问题 修复同时添加副本数量可能超过配置阈值的问题，提升程序稳定性  TiKV  修复 PD leader 切换，gRPC call 没被 cancel 的问题 对重要配置进行保护，第一次设置之后不允许变更 增加获取 metrics 的 gRPC API 启动时候，检查是否使用 SSD 使用 ReadPool 优化读性能，raw get 测试性能提升 30% 完善 metrics，优化 metrics 的使用  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2rc3/</guid>
      <description>TiDB 2.0 RC3 Release Notes 2018 年 3 月 23 日，TiDB 发布 2.0 RC3 版。该版本在 2.0 RC2 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  修复部分场景下 MAX/MIN 结果不正确的问题 修复部分场景下 Sort Merge Join 结果未按照 Join Key 有序的问题 修复边界条件下 uint 和 int 比较的错误 完善浮点数类型的长度和精度检查，提升 MySQL 兼容性 完善时间类型解析报错日志，添加更多错误信息 完善内存控制，新增对 IndexLookupExecutor 的内存统计 优化 ADD INDEX 的执行速度，部分场景下速度大幅度提升 GROUP BY 子句为空时使用 Stream Aggregation 算子，提升速度 支持通过 STRAIGHT_JOIN 来关闭优化器的 Join Reorder 优化 ADMIN SHOW DDL JOBS 输出更详细的 DDL 任务状态信息 支持 ADMIN SHOW DDL JOB QUERIES 查询当前正在运行的 DDL 任务的原始语句 支持 ADMIN RECOVER INDEX 命令，用于灾难恢复情况下修复索引数据 ADD INDEX 操作变更为低优先级，降低对线上业务影响 支持参数为 JSON 类型的 SUM/AVG 等聚合函数 支持配置文件修改 lower_case_table_names 系统变量，用于支持 OGG 数据同步工具 提升对 Navicat 管理工具的兼容性 支持在 CRUD 操作中使用隐式的行 ID  PD  支持 Region Merge，合并数据删除后产生的空 Region 或小 Region 添加副本时忽略有大量 pending peer 的节点，提升恢复副本及下线的速度 优化有大量空 Region 时产生的频繁调度问题 优化不同 label 中资源不均衡的场景中 leader balance 调度的速度 添加更多异常 Region 的统计  TiKV  支持 Region Merge Raft snapshot 流程完成之后立刻通知 PD，加速调度 增加 Raw DeleteRange API 增加 GetMetric API 减缓 RocksDB sync 文件造成的 I/O 波动 优化了对 delete 掉数据的空间回收机制 完善数据恢复工具 tikv-ctl 解决了由于 snapshot 导致下线节点慢的问题 Coprocessor 支持 streaming 支持 Readpool，raw_get/get/batch_get 性能提升 30% 支持配置 Coprocessor 请求超时时间 Coprocessor 支持 streaming aggregation 上报 Region heartbeat 时携带时间信息 限制 snapshot 文件的空间使用，防止占用过多磁盘空间 对长时间不能选出 leader 的 Region 进行记录上报 加速启动阶段的垃圾清理工作 根据 compaction 事件及时更新对应 Region 的 size 信息 对 scan lock 的大小进行限制，防止请求超时 使用 DeleteRange 加速 Region 删除 支持在线修改 RocksDB 的参数  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2rc4/</guid>
      <description>TiDB 2.0 RC4 Release Notes 2018 年 3 月 30 日，TiDB 发布 2.0 RC4 版。该版本在 2.0 RC3 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  支持 SHOW GRANTS FOR CURRENT_USER(); 修复 UnionScan 里的 Expression 没有 Clone 的问题 支持 SET TRANSACTION 语法 修复 copIterator 中潜在的 goroutine 泄露问题 修复 admin check table 对包含 null 的 unique index 误判的问题 支持用科学计数法显示浮点数 修复 binary literal 计算时的类型推导 修复解析 CREATE VIEW 语句的问题 修复语句中同时包含 ORDER BY 和 LIMIT 0 时 panic 的问题 提升 DecodeBytes 执行性能 优化 LIMIT 0 为 TableDual，避免无用的执行计划构建  PD  支持手动 split Region，可用于处理单 Region 热点的问题 修复 pdctl 运行 config show all 不显示 label property 的问题 metrics 及代码结构相关的优化  TiKV  限制接收 snapshot 时的内存使用，解决极端情况下的 OOM 可以配置 Coprocessor 在遇到 warnings 时的行为 TiKV 支持导数据模式 支持 Region 从正中间分裂 提升 CI test 的速度 使用 crossbeam channel 改善 TiKV 在被隔离的情况下由于 leader missing 输出太多日志的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 RC5 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2rc5/</guid>
      <description>TiDB 2.0 RC5 Release Notes 2018 年 4 月 17 日，TiDB 发布 2.0 RC5 版。该版本在 RC4 版的基础上，对 MySQL 兼容性、系统稳定性和优化器做了很多改进。
TiDB  修复应用 Top-N 下推规则的问题 修复对包含 NULL 值的列的行数估算 修复 Binary 类型的 0 值 修复事务内的 BatchGet 问题 回滚 Add Index 操作的时候，清除清除已写入的数据，减少空间占用 优化 insert on duplicate key update 语句性能，提升 10 倍以上 修复 UNIX_TIMESTAMP 函数返回结果类型问题返回结果类型问题 修复在添加 NOT NULL 列的过程中，插入 NULL 值的问题 Show Process List 语句支持显示执行语句的内存占用 修复极端情况下 Alter Table Modify Column 出错问题 支持通过 Alter 语句设置 table comment  PD  添加 Raft Learner 支持 优化 Balance Region Scheduler，减少调度开销 调整默认 schedule-limit 配置 修复频繁分配 ID 问题 修复添加调度兼容性问题  TiKV  tikv-ctl 支持 compact 指定的 Region Raw KV 支持 Batch Put、Batch Get、Batch Delete 和 Batch Scan 解决太多 snapshot 导致的 OOM 问题 Coprocessor 返回更详细的错误信息 支持通过 tikv-ctl 动态修改 TiKV 的 block-cache-size 进一步完善 importer 功能 简化 ImportSST::Upload 接口 设置 gRPC 的 keepalive 属性 tikv-importer 作为独立的 binary 从 TiKV 中分离出来 统计 Coprocessor 每个 scan range 命令扫描了多少行数据 解决在 macOS 系统上的编译问题 优化 metric 相关的内容 解决 snapshot 相关的一个潜在 bug 解决误用了一个 RocksDB metric 的问题 Coprocessor 支持 overflow as warning 选项  </description>
    </item>
    
    <item>
      <title>TiDB 2.0 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.0ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.0ga/</guid>
      <description>TiDB 2.0 Release Notes 2018 年 4 月 27 日，TiDB 发布 2.0 GA 版。相比 1.0 版本，该版本对 MySQL 兼容性、系统稳定性、优化器和执行器做了很多改进。
TiDB  SQL 优化器  精简统计信息数据结构，减小内存占用 加快进程启动时加载统计信息速度 支持统计信息动态更新 [experimental] 优化代价模型，对代价估算更精准 使用 Count-Min Sketch 更精确地估算点查的代价 支持分析更复杂的条件，尽可能充分的使用索引 支持通过 STRAIGHT_JOIN 语法手动指定 Join 顺序 GROUP BY子句为空时使用 Stream Aggregation 算子，提升性能 支持使用索引计算 Max/Min 函数 优化关联子查询处理算法，支持将更多类型的关联子查询解关联并转化成 Left Outer Join 扩大 IndexLookupJoin 的使用范围，索引前缀匹配的场景也可以使用该算法   SQL 执行引擎  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用，显著提升 TPC-H 结果 支持 Streaming Aggregation 算子下推 优化 Insert Into Ignore 语句性能，提升 10 倍以上 优化 Insert On Duplicate Key Update 语句性能，提升 10 倍以上 下推更多的数据类型和函数到 TiKV 计算 优化 Load Data 性能，提升 10 倍以上 支持对物理算子内存使用进行统计，通过配置文件以及系统变量指定超过阈值后的处理行为 支持限制单条 SQL 语句使用内存的大小，减少程序 OOM 风险 支持在 CRUD 操作中使用隐式的行 ID 提升点查性能   Server  支持 Proxy Protocol 添加大量监控项, 优化日志 支持配置文件的合法性检测 支持 HTTP API 获取 TiDB 参数信息 使用 Batch 方式 Resolve Lock，提升垃圾回收速度 支持多线程垃圾回收 支持 TLS   兼容性  支持更多 MySQL 语法 支持配置文件修改 lower_case_table_names 系统变量，用于支持 OGG 数据同步工具 提升对 Navicat 的兼容性 在 Information_Schema 中支持显示建表时间 修复部分函数/表达式返回类型和 MySQL 不同的问题 提升对 JDBC 兼容性 支持更多的 SQL_MODE   DDL  优化 Add Index 的执行速度，部分场景下速度大幅度提升 Add Index 操作变更为低优先级，降低对线上业务影响 Admin Show DDL Jobs 输出更详细的 DDL 任务状态信息 支持 Admin Show DDL Job Queries JobID 查询当前正在运行的 DDL 任务的原始语句 支持 Admin Recover Index 命令，用于灾难恢复情况下修复索引数据 支持通过 Alter 语句修改 Table Options    PD  增加 Region Merge 支持，合并数据删除后产生的空 Region [experimental] 增加 Raft Learner 支持 [experimental] 调度器优化  调度器适应不同的 Region size 提升 TiKV 宕机时数据恢复的优先级和恢复速度 提升下线 TiKV 节点搬迁数据的速度 优化 TiKV 节点空间不足时的调度策略，尽可能防止空间不足时磁盘被写满 提升 balance-leader scheduler 的调度效率 减少 balance-region scheduler 调度开销 优化 hot-region scheduler 的执行效率   运维接口及配置  增加 TLS 支持 支持设置 PD leader 优先级 支持基于 label 配置属性 支持配置特定 label 的节点不调度 Region leader 支持手动 Split Region，可用于处理单 Region 热点的问题 支持打散指定 Region，用于某些情况下手动调整热点 Region 分布 增加配置参数检查规则，完善配置项的合法性较验   调试接口  增加 Drop Region 调试接口 增加枚举各个 PD health 状态的接口   统计相关  添加异常 Region 的统计 添加 Region 隔离级别的统计 添加调度相关 metrics   性能优化  PD leader 尽量与 etcd leader 保持同步，提升写入性能 优化 Region heartbeat 性能，现可支持超过 100 万 Region    TiKV  功能  保护关键配置，防止错误修改 支持 Region Merge [experimental] 添加 Raw DeleteRange API 添加 GetMetric API 添加 Raw Batch Put，Raw Batch Get，Raw Batch Delete 和 Raw Batch Scan 给 Raw KV API 增加 Column Family 参数，能对特定 Column Family 进行操作 Coprocessor 支持 streaming 模式，支持 streaming 聚合 支持配置 Coprocessor 请求的超时时间 心跳包携带时间戳 支持在线修改 RocksDB 的一些参数，包括 block-cache-size 大小等 支持配置 Coprocessor 遇到某些错误时的行为 支持以导数据模式启动，减少导数据过程中的写放大 支持手动对 region 进行对半 split 完善数据修复工具 tikv-ctl Coprocessor 返回更多的统计信息，以便指导 TiDB 的行为 支持 ImportSST API，可以用于 SST 文件导入 [experimental] 新增 TiKV Importer 二进制，与 TiDB Lightning 集成用于快速导入数据 [experimental]   性能  使用 ReadPool 优化读性能，raw_get/get/batch_get 提升 30% 提升 metrics 的性能 Raft snapshot 处理完之后立即通知 PD，加快调度速度 解决 RocksDB 刷盘导致性能抖动问题 提升在数据删除之后的空间回收 加速启动过程中的垃圾清理过程 使用 DeleteFilesInRanges 减少副本迁移时 I/O 开销   稳定性  解决在 PD leader 发送切换的情况下 gRPC call 不返回问题 解决由于 snapshot 导致下线节点慢的问题 限制搬移副本临时占用的空间大小 如果有 Region 长时间没有 Leader，进行上报 根据 compaction 事件及时更新统计的 Region size 限制单次 scan lock 请求的扫描的数据量，防止超时 限制接收 snapshot 过程中的内存占用，防止 OOM 提升 CI test 的速度 解决由于 snapshot 太多导致的 OOM 问题 配置 gRPC 的 keepalive 参数 修复 Region 增多容易 OOM 的问题    TiSpark TiSpark 使用独立的版本号，现为 1.</description>
    </item>
    
    <item>
      <title>TiDB 2.0.1 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/201/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/201/</guid>
      <description>TiDB 2.0.1 Release Notes 2018 年 5 月 16 日，TiDB 发布 2.0.1 版。该版本在 2.0.0 (GA) 版的基础上，对 MySQL 兼容性、系统稳定性做出了改进。
TiDB  实时更新 Add Index 的进度到 DDL 任务信息中 添加 Session 变量 tidb_auto_analyze_ratio 控制统计信息自动更新阈值 修复当事务提交失败时可能未清理所有的残留状态的问题 修复加索引在部分情况下的 Bug 修复 DDL 修改表面操作在某些并发场景下的正确性问题 修复某些情况下 LIMIT 结果不正确的问题 修复 ADMIN CHECK INDEX 语句索引名字区分大小写问题 修复 UNION 语句的兼容性问题 修复插入 TIME 类型数据的兼容性问题 修复某些情况下 copIteratorTaskSender 导致的 goroutine 泄漏问题 增加一个选项，用于设置 TiDB 在写 Binlog 失败的情况下的行为 优化 Coprocessor 慢请求日志格式，区分处理时间长与排队时间长的任务 MySQL 协议握手阶段发生错误不打印日志，避免 KeepAlive 造成大量日志 优化 Out of range value for column 的错误信息 修复 Update 语句中遇到子查询导致结果错误的问题 调整 TiDB 进程处理 SIGTERM 的行为，不等待正在执行的 Query 完成  PD  添加 Scatter Range 调度，调度指定 Key Range 包含的 Region 优化 Merge Region 调度，使新分裂不久的 Region 不能被合并 添加 learner 相关的 metrics 修复重启误删 scheduler 的问题 修复解析配置文件出错问题 修复 etcd leader 和 PD leader 不同步的问题 修复关闭 learner 情况下还有 learner 出现的问题 修复读取包过大造成 load Regions 失败的问题  TiKV  修复 SELECT FOR UPDATE 阻止其他人读的问题 优化慢查询的日志 减少 thread_yield 的调用次数 修复生成 snapshot 会意外阻塞 raftstore 的 bug 修复特殊情况下开启 learner 无法选举成功的问题 修复极端情况下分裂可能导致的脏读问题 修正读线程池的配置默认值 修正删大数据表会影响写性能的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.10 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.0.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.0.10/</guid>
      <description>TiDB 2.0.10 Release Notes 2018 年 12 月 18 日，TiDB 发布 2.0.10 版，TiDB Ansible 相应发布 2.0.10 版本。该版本在 2.0.9 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  修复取消 DDL 任务的时候可能导致的问题 #8513 修复 ORDER BY，UNION 语句无法引用带表名的列的问题 #8514 修复 UNCOMPRESS 函数没有判断错误输入长度的问题 #8607 修复 ANSI_QUOTES SQL_MODE 在 TiDB 升级的时候遇到的问题 #8575 修复某些情况下 select 返回结果错误的问题 #8570 修复 TiDB 在收到退出信号的时候可能无法退出的问题 #8501 修复某些情况下 IndexLookUpJoin 返回错误结果的问题 #8508 避免下推有 GetVar 或 SetVar 的 filter #8454 修复某些情况下 UNION 语句结果长度错误的问题 #8491 修复 PREPARE FROM @var_name 的问题 #8488 修复某些情况下导出统计信息 panic 的问题 #8464 修复统计信息某些情况下对点查估算的问题 #8493 修复某些情况下返回 Enum 默认值为字符串导致的 panic #8476 修复在宽表场景下，占用太多内存的问题 #8467 修复 Parser 对取模操作错误格式化导致的问题 #8431 修复某些情况下添加外键约束导致的 panic 问题 #8421，#8410 修复 YEAR 类型错误转换零值的问题 #8396 修复 VALUES 函数在参数不为列的时候 panic 的问题 #8404 存在子查询的语句禁用 Plan Cache #8395  PD  修复 RaftCluster 在退出时可能的死锁问题 #1370  TiKV  修复迁移 Leader 到新节点时造成请求延时问题 #3929 修复多余的 Region 心跳 #3930  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.11 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.0.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.0.11/</guid>
      <description>TiDB 2.0.11 Release Notes 2019 年 1 月 3 日，TiDB 发布 2.0.11 版，TiDB Ansible 相应发布 2.0.11 版本。该版本在 2.0.10 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  修复 PD 发生异常的情况下，Error 没有被正确处理的问题 #8764 修复 Rename 相同表的行为，跟 MySQL 保持一致 #8809 修复 ADMIN CHECK TABLE 在 ADD INDEX 过程中误报的问题 #8750 修复前缀索引在某些情况下，开闭范围区间错误的问题 #8877 修复在某些添加列的情况下，UPDATE 语句 panic 的问题 #8904  TiKV  修复了两个 Region merge 相关的问题 #4003，#4004  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.2 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/202/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/202/</guid>
      <description>TiDB 2.0.2 Release Notes 2018 年 5 月 21 日，TiDB 发布 2.0.2 版。该版本在 2.0.1 版的基础上，对系统稳定性做出了改进。
TiDB  修复 Decimal 除法内置函数下推的问题 支持 Delete 语句中使用 USE INDEX 的语法 禁止在带有 Auto-Increment 的列中使用 shard_row_id_bits 特性 增加写入 Binlog 的超时机制  PD  使 balance leader scheduler 过滤失连节点 更改 transfer leader operator 的超时时间为 10 秒 修复 label scheduler 在集群 Regions 不健康状态下不调度的问题 修复 evict leader scheduler 调度不当的问题  TiKV  修复 Raft 日志没有打出来的问题 支持配置更多 gRPC 相关参数 支持配置选举超时的取值范围 修复过期 learner 没有删掉的问题 修复 snapshot 中间文件被误删的问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.3 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/203/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/203/</guid>
      <description>TiDB 2.0.3 Release Notes 2018 年 6 月 1 日，TiDB 发布 2.0.3 版。该版本在 2.0.2 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  支持在线更改日志级别 支持 COM_CHANGE_USER 命令 支持二进制协议情况下使用时间类型参数 优化带 BETWEEN 表达式的查询条件代价估算 在 SHOW CREATE TABLE 里不显示 FOREIGN KEY 信息 优化带 LIMIT 子句的查询代价估算 修复 YEAR 类型作为唯一索引的问题 修复在没有唯一索引的情况下 ON DUPLICATE KEY UPDATE 的问题 修复 CEIL 函数的兼容性问题 修复 DECIMAL 类型计算 DIV 的精度问题 修复 ADMIN CHECK TABLE 误报的问题 修复 MAX/MIN 在特定表达式参数下 panic 的问题 修复特殊情况下 JOIN 结果为空的问题 修复 IN 表达式构造查询 Range 的问题 修复使用 Prepare 方式进行查询且启用 Plan Cache 情况下的 Range 计算问题 修复异常情况下频繁加载 Schema 信息的问题  PD  修复在特定条件下收集 hot-cache metrics 会 panic 的问题 修复对旧的 Region 产生调度的问题  TiKV  修复 learner flag 错误上报给 PD 的 bug 在 do_div_mod 中 divisor/dividend 为 0 时返回错误  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.4 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/204/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/204/</guid>
      <description>TiDB 2.0.4 Release Notes 2018 年 6 月 15 日，TiDB 发布 2.0.4 版。该版本在 2.0.3 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  支持 ALTER TABLE t DROP COLUMN a CASCADE 语法 支持设置 tidb_snapshot 变量的值为 TSO 优化监控项中语句类型展示 优化查询代价估计精度 设置 gRPC 的 backoff max delay 参数 支持通过配置文件设置单条语句的内存使用阈值 重构 Optimizer 的 error 解决 Cast Decimal 数据的副作用问题 解决特定场景下 Merge Join 算子结果错误的问题 解决转换 Null 对象到 String 的问题 解决 Cast JSON 数据为 JSON 类型的问题 解决 Union + OrderBy 情况下结果顺序和 MySQL 不一致的问题 解决 Union 语句中对 Limit/OrderBy 子句的合法性检查规则问题 解决 Union All 的结果兼容性问题 解决谓词下推中的一个 Bug 解决 Union 语句对 For Update 子句的兼容性问题 解决 concat_ws 函数对结果错误截断的问题  PD  改进 max-pending-peer-count 调度参数未设置时的行为，调整为不限制最大 PendingPeer 的数量  TiKV  新增 RocksDB PerfContext 接口用于调试 移除 import-mode 参数 为 tikv-ctl 添加 region-properties 命令 优化有大量 RocksDB tombstone 时 reverse-seek 过慢的问题 修复 do_sub 导致的崩溃问题 当 GC 遇到有太多版本的数据时记录日志  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.5 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/205/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/205/</guid>
      <description>TiDB 2.0.5 Release Notes 2018 年 7 月 6 日，TiDB 发布 2.0.5 版。该版本在 2.0.4 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  New Features  增加一个系统变量 tidb_disable_txn_auto_retry，用于关闭事务自动重试 #6877   Improvements  调整计算 Selection 代价的方式，结果更准确 #6989 查询条件能够完全匹配唯一索引或者主键时，直接选择作为查询路径 #6966 启动服务失败时，做必要的清理工作 #6964 在 Load Data 语句中，将 \N 处理为 NULL #6962 优化 CBO 代码结构 #6953 启动服务时，尽早上报监控数据 #6931 对慢查询日志格式进行优化：去除 SQL 语句中的换行符，增加用户信息 #6920 支持注释中存在多个星号的情况 #6858   Bug Fixes  修复 KILL QUERY 语句权限检查问题 #7003 修复用户数量超过 1024 时可能造成无法登录的问题 #6986 修复一个写入无符号类型 float/double 数据的问题 #6940 修复 COM_FIELD_LIST 命令的兼容性，解决部分 MariaDB 客户端遇到 Panic 的问题 #6929 修复 CREATE TABLE IF NOT EXISTS LIKE 行为 #6928 修复一个 TopN 下推过程中的问题 #6923 修复 Add Index 过程中遇到错误时当前处理的行 ID 记录问题 #6903    PD  修复某些场景下副本迁移导致 TiKV 磁盘空间耗尽的问题 修复 AdjacentRegionScheduler 导致的崩溃问题  TiKV  修复 decimal 运算中潜在的溢出问题 修复 merge 过程中可能发生的脏读问题  </description>
    </item>
    
    <item>
      <title>TiDB 2.0.6 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/206/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/206/</guid>
      <description>TiDB 2.0.6 Release Notes 2018 年 8 月 6 日，TiDB 发布 2.0.6 版。该版本在 2.0.5 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  Improvements  精简 &amp;ldquo;set system variable&amp;rdquo; 日志的长度，减少日志文件体积 #7031 在日志中记录 ADD INDEX 执行过程中的慢操作，便于定位问题 #7083 减少更新统计信息操作中的事务冲突 #7138 当待估算的值超过统计信息范围时，提高行数估计的准确度 #7185 当使用 Index Join 时，选择行数估计较小的表作为驱动表，提高 Index Join 的执行效率 #7227 为 ANALYZE TABLE 语句执行过程中发生的 panic 添加 recover 机制，避免收集统计信息过程中的异常行为导致 tidb-server 不可用 #7228 当 RPAD/LPAD 的结果超过设置系统变量 max_allowed_packet 时，返回 NULL 和对应的 warning，兼容 MySQL #7244 设置 PREPARE 语句中占位符数量上限为 65535，兼容 MySQL #7250   Bug Fixes  修复某些情况下，DROP USER 语句和 MySQL 行为不兼容的问题 #7014 修复当 tidb_batch_insert 打开后，INSERT/LOAD DATA 等语句在某些场景下 OOM 的问题 #7092 修复某个表的数据持续更新时，其统计信息自动更新失效的问题 #7093 修复防火墙断掉不活跃的 gRPC 连接的问题 #7099 修复某些场景下使用前缀索引结果不正确的问题 #7126 修复某些场景下统计信息过时导致 panic 的问题 #7155 修复某些场景下 ADD INDEX 后索引数据少一条的问题 #7156 修复某些场景下查询唯一索引上的 NULL 值结果不正确的问题 #7172 修复某些场景下 DECIMAL 的乘法结果出现乱码的问题 #7212 修复某些场景下 DECIMAL 的取模运算结果不正确的问题 #7245 修复某些特殊语句序列下在事务中执行 UPDATE/DELETE 语句后结果不正确的问题 #7219 修复某些场景下 UNION ALL/UPDATE 语句在构造执行计划过程中 panic 的问题 #7225 修复某些场景下前缀索引的索引范围计算错误的问题 #7231 修复某些场景下 LOAD DATA 语句不写 binlog 的问题 #7242 修复某些场景下在 ADD INDEX 过程中 SHOW CREATE TABLE 结果不正确的问题 #7243 修复某些场景下 Index Join 因为没有初始化事务时间戳而 panic 的问题 #7246 修复 ADMIN CHECK TABLE 因为误用 session 中的时区而导致误报的问题 #7258 修复 ADMIN CLEANUP INDEX 在某些场景下索引没有清除干净的问题 #7265 禁用 Read Committed 事务隔离级别 #7282    TiKV  Improvements  扩大默认 scheduler slots 值以减少假冲突现象 减少回滚事务的连续标记以提升冲突极端严重下的读性能 限制 RocksDB log 文件的大小和个数以减少长时间运行下不必要的磁盘占用   Bug Fixes  修复字符串转 Decimal 时出现的 crash    </description>
    </item>
    
    <item>
      <title>TiDB 2.0.7 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/207/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/207/</guid>
      <description>TiDB 2.0.7 Release Notes 2018 年 9 月 7 日，TiDB 发布 2.0.7 版。该版本在 2.0.6 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  New Feature  在 information_schema 里添加 PROCESSLIST 表 #7286   Improvements  收集更多语句执行细节，并输出在 SLOW QUERY 日志里 #7364 SHOW CREATE TABLE 不再输出分区信息 #7388 通过设置 RC 隔离级别和低优先级优化 ANALYZE 语句执行效率 #7500 加速 ADD UNIQUE INDEX #7562 增加控制 DDL 并发度的选项 #7563   Bug Fixes  修复 PRIMARY KEY 为整数的表，无法使用 USE INDEX(PRIMARY) 的问题 #7298 修复 Merge Join 和 Index Join 在 inner row 为 NULL 时输出多余结果的问题 #7301 修复 chunk size 设置过小时，Join 输出多余结果的问题 #7315 修复建表语句中包含 range column 语法导致 panic 的问题 #7379 修复 admin check table 对时间类型的列误报的问题 #7457 修复以默认值 current_timestamp 插入的数据无法用 = 条件查询到的问题 #7467 修复以 ComStmtSendLongData 命令插入空字符串参数被误解析为 NULL 的问题 #7508 修复特定场景下 auto analyze 不断重复执行的问题 #7556 修复 parser 无法解析以换行符结尾的单行注释的问题 #7635    TiKV  Improvement  空集群默认打开 dynamic-level-bytes 参数减少空间放大   Bug Fix  在 Region merge 之后更新 Region 的 approximate size 和 keys    </description>
    </item>
    
    <item>
      <title>TiDB 2.0.8 release notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/208/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/208/</guid>
      <description>TiDB 2.0.8 Release Notes 2018 年 10 月 16 日，TiDB 发布 2.0.8 版。该版本在 2.0.7 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  功能改进  在 Update 没有更改相应 AUTO-INCREMENT 列情况下，防止 AUTO-ID 被消耗过快 #7846   Bug 修复  在 PD Leader 异常宕机的情况下，TiDB 快速创建 etcd Session 恢复服务 #7810 修复 DateTime 类型使用默认值时候没有考虑时区的问题 #7672 修复 duplicate key update 在某些情况下没有正确插入值的问题 #7685 修复 UnionScan 中谓词条件没有下推的问题 #7726 修复增加 TIMESTAMP 索引没有正确处理时区的问题 #7812 修复某些情况下统计信息模块导致的内存泄露问题 #7864 修复在某些异常情况下，无法获得 ANALYZE 结果的问题 #7871 令 SYSDATE 不做表达式展开，以返回正确的结果 #7894 修复某些情况下，substring_index panic 的问题 #7896 修复某些情况下，错误将 OUTER JOIN 转为 INNER JOIN 的问题 #7899    TiKV  Bug 修复  修复节点宕机时 Raftstore EntryCache 占用内存持续上升的问题 #3529    </description>
    </item>
    
    <item>
      <title>TiDB 2.0.9 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/209/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/209/</guid>
      <description>TiDB 2.0.9 Release Notes 2018 年 11 月 19 日，TiDB 发布 2.0.9 版。该版本在 2.0.8 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  修复统计信息直方图为空的时候导致的问题 #7927 修复 UNION ALL 语句在某些情况下 panic 的问题 #7942 修复错误的 DDL JOB 情况下导致的递归溢出问题 #7959 为 Commit 操作加上慢操作日志 #7983 修复 Limit 值太大的情况下导致的 panic 问题 #8004 支持 USING 子句指定 utf8mb4 字符集 #8048 内建函数 TRUNCATE 支持类型为 unsigned int 的参数 #8069 修复统计信息模块在某些情况下主键选择率估算的问题 #8150 增加 Session 变量来控制是否允许写入 _tidb_rowid #8126 修复 PhysicalProjection 在某些情况下 panic 的问题 #8154 修复 Union 语句在某些情况下结果不稳定的问题 #8168 修复在非插入语句下 values 没有返回 NULL 的问题 #8179 修复某些情况下统计信息模块无法清除过期统计数据的问题 #8184 让事务允许的最长运行时间变成一个可配置项 #8209 修复 expression rewriter 某些情况下错误的比较逻辑 #8288 消除 UNION ORDER BY 语句生成的多余列的问题 #8307 支持 admin show next_row_id 语句 #8274 修复 Show Create Table 语句中特殊字符转义的问题 #8321 修复 UNION 语句在某些情况下遇到非预期错误的问题 #8318 修复某些情况下取消 DDL 任务导致的 Schema 没有回滚的问题 #8312 把变量 tidb_max_chunk_size 变成全局环境变量 #8333 ticlient Scan 命令增加边界，解决数据扫出边界的问题 #8309 #8310  PD  修复 etcd 启动失败导致的服务挂起问题 #1267 修复 pd-ctl 读取 Region key 的相关问题 #1298 #1299 #1308 修复 regions/check API 输出错误的问题 #1311 修复 PD join 失败后无法重新 join 的问题 1279  TiKV  增加 kv_scan 接口扫描上界的限制 #3749 废弃配置 max-tasks-xxx 并新增 max-tasks-per-worker-xxx #3093 修复 RocksDB CompactFiles 的问题 #3789  </description>
    </item>
    
    <item>
      <title>TiDB 2.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21beta/</guid>
      <description>TiDB 2.1 Beta Release Notes 2018 年 6 月 29 日，TiDB 发布 2.1 Beta 版。相比 2.0 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  优化 Index Join 选择范围，提升执行性能 优化关联子查询，下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升 在 UPDATE、DELETE 语句中支持 Index Hint 和 Join Hint 优化器 Hint TIDM_SMJ 在没有索引可用的情况下可生效 支持更多函数下推：ABS/CEIL/FLOOR/IS TRUE/IS FALSE 在常量折叠过程中特殊处理函数 IF 和 IFNULL 优化 EXPLAIN 语句输出格式   SQL 执行引擎  实现并行 Hash Aggregate 算子，部分场景下能提高 Hash Aggregate 计算性能 350% 实现并行 Project 算子，部分场景下性能提升达 74% 并发地读取 Hash Join 的 Inner 表和 Outer 表的数据，提升执行性能 修复部分场景下 INSERT … ON DUPLICATE KEY UPDATE … 结果不正确的问题 修复 CONCAT_WS/FLOOR/CEIL/DIV 内建函数的结果不正确的问题   Server  添加 HTTP API 打散 table 的 Regions 在 TiKV 集群中的分布 添加 auto_analyze_ratio 系统变量控制自动 analyze 的阈值 添加 HTTP API 控制是否打开 general log 添加 HTTP API 在线修改日志级别 在 general log 和 slow query log 中添加 user 信息 支持 Server side cursor   兼容性  支持更多 MySQL 语法 BIT 聚合函数支持 ALL 参数 支持 SHOW PRIVILEGES 语句   DML  减少 INSERT INTO SELECT 语句的内存占用 修复 Plan Cache 的性能问题 添加 tidb_retry_limit 系统变量控制事务自动重试的次数 添加 tidb_disable_txn_auto_retry 系统变量控制事务是否自动重试 修复写入 time 类型的数据精度问题 支持本地冲突事务排队，优化冲突事务性能 修复 UPDATE 语句的 Affected Rows 优化 insert ignore on duplicate key update 语句性能 优化 Create Table 语句的执行速度 优化 Add index 的速度，在某些场景下速度大幅提升 修复 Alter table add column 增加列超过表的列数限制的问题 修复在某些异常情况下 DDL 任务重试导致 TiKV 压力增加的问题 修复在某些异常情况下 TiDB 不断重载 Schema 信息的问题   DDL  Show Create Table 不再输出外键相关的内容 支持 select tidb_is_ddl_owner() 语句，方便判断 TiDB 是否为 DDL Owner 修复某些场景下 YEAR 类型删除索引的问题 修复并发执行场景下的 Rename table 的问题 支持 ALTER TABLE FORCE 语法 支持 ALTER TABLE RENAME KEY TO 语法 admin show ddl jobs 输出信息中添加表名、库名等信息    PD  PD 节点间开启 Raft PreVote，避免网络隔离后恢复时产生的重新选举 优化 Balance Scheduler 频繁调度小 Region 的问题 优化热点调度器，在流量统计信息抖动时适应性更好 region merge 调度时跳过数据行数较多的 Region 默认开启 raft learner 功能，降低调度时出现宕机导致数据不可用的风险 pd-recover 移除 max-replica 参数 增加 Filter 相关的 metrics 修复 tikv-ctl unsafe recovery 之后 Region 信息没更新的问题 修复某些场景下副本迁移导致 TiKV 磁盘空间耗尽的问题 兼容性提示  由于新版本存储引擎更新，不支持在升级后回退至 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 GA Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1ga/</guid>
      <description>TiDB 2.1 GA Release Notes 2018 年 11 月 30 日，TiDB 发布 2.1 GA 版。相比 2.0 版本，该版本对系统稳定性、性能、兼容性、易用性做了大量改进。
TiDB   SQL 优化器
 优化 Index Join 选择范围，提升执行性能 优化 Index Join 外表选择，使用估算的行数较少的表作为外表 扩大 Join Hint TIDB_SMJ 的作用范围，在没有合适索引可用的情况下也可使用 Merge Join 加强 Join Hint TIDB_INLJ 的能力，可以指定 Join 中的内表 优化关联子查询，包括下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升 支持在 UPDATE 和 DELETE 语句中使用 Index Hint 和 Join Hint 支持更多函数下推：ABS/CEIL/FLOOR/IS TRUE/IS FALSE 优化内建函数 IF 和 IFNULL 的常量折叠算法 优化 EXPLAIN 语句输出格式, 使用层级结构表示算子之间的上下游关系    SQL 执行引擎</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21rc1/</guid>
      <description>TiDB 2.1 RC1 Release Notes 2018 年 8 月 24 日，TiDB 发布 2.1 RC1 版。相比 2.1 Beta 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复某些情况下关联子查询去关联后结果不正确的问题 #6972 优化 Explain 输出结果 #7011#7041 优化 IndexJoin 驱动表选择策略#7019 去掉非 PREPARE 语句的 Plan Cache #7040 修复某些情况下 INSERT 语句无法正常解析执行的问题 #7068 修复某些情况下 IndexJoin 结果不正确的问题 #7150 修复某些情况下使用唯一索引不能查询到 NULL 值的问题 #7163 修复 UTF-8 编码情况下前缀索引的范围计算不正确的问题 #7194 修复某些情况下 Project 算子消除导致的结果不正确的问题 #7257 修复主键为整数类型时无法使用 USE INDEX(PRIMARY) 的问题 #7316 修复某些情况下使用关联列无法计算索引范围的问题 #7357   SQL 执行引擎  修复某些情况下夏令时时间计算结果不正确的问题 #6823 重构聚合函数框架，提升 Stream 和 Hash 聚合算子的执行效率 #6852 修复某些情况下 Hash 聚合算子不能正常退出的问题 #6982 修复 BIT_AND/BIT_OR/BIT_XOR 没有正确处理非整型数据的问题 #6994 优化 REPLACE INTO 语句的执行速度，性能提升近 10 倍 #7027 优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半 #7043 修复 UNION 语句整合有符号和无符号型整数结果时与 MySQL 不兼容的问题 #7112 修复 LPAD/RPAD/TO_BASE64/FROM_BASE64/REPEAT 因为申请过多内存导致 TiDB panic 的问题 #7171 #7266 #7409 #7431 修复 MergeJoin/IndexJoin 在处理 NULL 值时结果不正确的问题 #7255 修复某些情况下 Outer Join 结果不正确的问题 #7288 增强 Data Truncated 的报错信息，便于定位出错的数据和表中对应的字段 #7401 修复某些情况下 Decimal 计算结果不正确的问题 #7001 #7113 #7202 #7208 优化点查的查询性能 #6937 禁用 Read Committed 隔离级别，避免潜在的问题 #7211 修复某些情况下 LTRIM/RTRIM/TRIM 结果不正确的问题 #7291 修复 MaxOneRow 算子无法保证返回结果不超过 1 行的问题 #7375 拆分 range 个数过多的 Coprocessor 请求 #7454   统计信息  优化统计信息动态收集机制 #6796 解决数据频繁更新场景下 Auto Analyze 不工作的问题 #7022 减少统计信息动态更新过程中的写入冲突 #7124 优化统计信息不准确情况下的代价估算 #7175 优化 AccessPath 的代价估算策略 #7233   Server  修复加载权限信息时的 bug #6976 修复 Kill 命令对权限的检查过严问题 #6954 解决 Binary 协议中某些数值类型移除的问题 #6922 精简日志输出 #7029 处理 mismatchClusterID 问题 #7053 增加 advertise-address 配置项 #7078 增加 GrpcKeepAlive 选项 #7100 增加连接或者 Token 时间监控 #7110 优化数据解码性能 #7149 INFORMMATION_SCHEMA 中增加 PROCESSLIST 表 #7236 解决权限验证时多条规则可以命中情况下的顺序问题 #7211 将部分编码相关的系统变量默认值改为 UTF-8 #7198 慢查询日志显示更详细的信息 #7302 支持在 PD 注册 tidb-server 的相关信息并通过 HTTP API 获取 #7082   兼容性  支持 Session 变量 warning_count 和 error_count #6945 读取系统变量时增加 Scope 检查 #6958 支持 MAX_EXECUTION_TIME 语法 #7012 支持更多的 SET 语法 #7020 Set 系统变量值过程中增加合法性校验 #7117 增加 Prepare 语句中 PlaceHolder 数量的校验 #7162 支持 set character_set_results = null #7353 支持 flush status 语法 #7369 修复 SET 和 ENUM 类型在 information_schema 里的 column size #7347 支持建表语句里的 NATIONAL CHARACTER 语法 #7378 支持 LOAD DATA 语句的 CHARACTER SET 语法 #7391 修复 SET 和 ENUM 类型的 column info #7417 支持 CREATE USER 语句的 IDENTIFIED WITH 语法 #7402 修复 TIMESTAMP 类型计算过程中丢失精度的问题 #7418 支持更多 SYSTEM 变量的合法性验证 #7196 修复 CHAR_LENGTH 函数在计算 binary string 时结果不正确的问题 #7410 修复在包含 GROUP BY 的语句里 CONCAT 结果不正确的问题 #7448 修复 DECIMAL 类型 CAST 到 STRING 类型时，类型长度不准确的问题 #7451   DML  解决 Load Data 语句的稳定性 #6927 解决一些 Batch 操作情况下的内存使用问题 #7086 提升 Replace Into 语句的性能 #7027 修复写入 CURRENT_TIMESTAMP 时，精度不一致的问题 #7355   DDL  改进 DDL 判断 Schema 是否已经同步的方法, 避免某些情况下的误判 #7319 修复在 ADD INDEX 过程中的 SHOW CREATE TABLE 结果 #6993 非严格 sql-mode 模式下, text/blob/json 的默认值可以为空 #7230 修复某些特定场景下 ADD INDEX 的问题 #7142 大幅度提升添加 UNIQUE-KEY 索引操作的速度 #7132 修复 Prefix-index 在 UTF-8 字符集的场景下的截断问题 #7109 增加环境变量 tidb_ddl_reorg_priority 来控制 add-index 操作的优先级 #7116 修复 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21rc2/</guid>
      <description>TiDB 2.1 RC2 Release Notes 2018 年 9 月 14 日，TiDB 发布 2.1 RC2 版。相比 2.1 RC1 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  新版 Planner 设计方案 #7543 提升常量传播优化规则 #7276 增强 Range 的计算逻辑使其能够同时处理多个 IN 或者等值条件 #7577 修复当 Range 为空时，TableScan 的估算结果不正确的问题 #7583 为 UPDATE 语句支持 PointGet 算子 #7586 修复 FirstRow 聚合函数某些情况下在执行过程中 panic 的问题 #7624   SQL 执行引擎  解决 HashJoin 算子在遇到错误的情况下潜在的 DataRace 问题 #7554 HashJoin 算子同时读取内表数据和构建 Hash 表 #7544 优化 Hash 聚合算子性能 #7541 优化 Join 算子性能 #7493、#7433 修复 UPDATE JOIN 在 Join 顺序改变后结果不正确的问题 #7571 提升 Chunk 迭代器的性能 #7585   统计信息  解决重复自动 Analyze 统计信息的问题 #7550 解决统计信息无变化时更新统计信息遇到错误的问题 #7530 Analyze 执行时使用低优先级以及 RC 隔离级别 #7496 支持只在一天中的某个时间段开启统计信息自动更新的功能 #7570 修复统计信息写日志时发生的 panic #7588 支持通过 ANALYZE TABLE WITH BUCKETS 语句配置直方图中桶的个数 #7619 修复更新空的直方图时 panic 的问题 #7640 使用统计信息更新 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21rc3/</guid>
      <description>TiDB 2.1 RC3 Release Notes 2018 年 9 月 29 日，TiDB 发布 2.1 RC3 版。相比 2.1 RC2 版本，该版本对系统稳定性、兼容性、优化器以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复语句内包含内嵌的 LEFT OUTER JOIN 时，结果不正确的问题 #7689 增强 JOIN 语句上的 predicate pushdown 优化规则 #7645 修复 UnionScan 算子的 predicate pushdown 优化规则 #7695 修复 Union 算子的 unique key 属性设置不正确的问题 #7680 增强常量折叠的优化规则 #7696 把常量传播后的 filter 是 null 的 data source 优化成 table dual #7756   SQL 执行引擎  优化事务内读请求的性能 #7717 优化部分执行器 Chunk 内存分配的开销 #7540 修复点查全部为 NULL 的列导致数组越界的问题 #7790   Server  修复配置文件里内存配额选项不生效的问题 #7729 添加 tidb_force_priority 系统变量用来整体设置语句执行的优先级 #7694 支持使用 admin show slow 语句来获取 SLOW QUERY LOG #7785   兼容性  修复 information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21rc4/</guid>
      <description>TiDB 2.1 RC4 Release Notes 2018 年 10 月 23 日，TiDB 发布 2.1 RC4 版。相比 2.1 RC3 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复某些情况下 UnionAll 的列裁剪不正确的问题 #7941 修复某些情况下 UnionAll 算子结果不正确的问题 #8007   SQL 执行引擎  修复 AVG 函数的精度问题 #7874 支持通过 EXPLAIN ANALYZE 语句查看 Query 执行过程中各个算子的运行时间，返回结果行数等运行时统计信息 #7925 修复多次引用同一列时 PointGet 算子 panic 的问题 #7943 修复当 Limit 子句中的值太大时 panic 的问题 #8002 修复某些情况下 AddDate/SubDate 执行过程中 panic 的问题 #8009   统计信息  修复将组合索引的直方图下边界前缀判断为越界的问题 #7856 修复统计信息收集引发的内存泄漏问题 #7873 修复直方图为空时 panic 的问题 #7928 修复加载统计信息时直方图边界越界的问题 #7944 限制统计信息采样过程中数值的最大长度 #7982   Server  重构 Latch，避免事务冲突误判，提升并发事务的执行性能 #7711 修复某些情况下收集 Slow Query 导致的 panic 问题 #7874 修复 LOAD DATA 语句中，ESCAPED BY 为空字符串时 panic 的问题 #8005 完善 “coprocessor error” 日志信息 #8006   兼容性  当 Query 为空时，将 SHOW PROCESSLIST 结果中的 Command 字段设置为 “Sleep” #7839   表达式  修复 SYSDATE 函数被常量折叠的问题 #7895 修复 SUBSTRING_INDEX 在某些情况下 panic 的问题 #7897   DDL  修复抛出 “invalid ddl job type” 的错误时导致栈溢出的问题 #7958 修复某些情况下 ADMIN CHECK TABLE 结果不正确的问题 #7975    PD  修复下线后的 TiKV 没有从 Grafana 面板中移除的问题 #1261 修复 grpc-go 设置 status 时的 data race 问题#1265 修复 etcd 启动失败导致的服务挂起问题 #1267 修复 leader 切换过程中可能产生的 data race #1273 修复下线 TiKV 时可能输出多余 warning 日志的问题 #1280  TiKV  优化 apply snapshot 导致的 RocksDB Write stall 的问题 #3606 增加 raftstore tick 相关 metrics #3657 升级 RocksDB，修复写入卡死及 IngestExternalFile 时可能写坏源文件的问题 #3661 升级 grpcio，修复 “too many pings” 误报的问题 #3650  </description>
    </item>
    
    <item>
      <title>TiDB 2.1 RC5 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/21rc5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/21rc5/</guid>
      <description>TiDB 2.1 RC5 Release Notes 2018 年 11 月 12 日，TiDB 发布 2.1 RC5 版。相比 2.1 RC4 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  修复 IndexReader 在某些情况下读取的 handle 不正确的问题 #8132 修复 IndexScan Prepared 语句在使用 Plan Cache 的时候的问题 #8055 修复 Union 语句结果不稳定的问题 #8165   执行器  提升 TiDB 插入和更新宽表的性能 #8024 内建函数 Truncate 支持 unsigned int 参数 #8068 修复转换 JSON 数据到 decimal 类型出错的问题 #8109 修复 float 类型在 Update 时出错的问题 #8170   统计信息  修复点查在某些情况下，统计信息出现错误的问题 #8035 修复统计信息某些情况下在 primary key 的选择率的问题 #8149 修复被删除的表的统计信息长时间没有清理的问题 #8182   Server  提升日志的可读性，完善日志信息  #8063 #8053 #8224     修复获取 infoschema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.1/</guid>
      <description>TiDB 2.1.1 Release Notes 2018 年 12 月 12 日，TiDB 发布 2.1.1 版。相比 2.1.0 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  优化器/执行器  修复时间为负值时的四舍五入错误 #8574 修复 uncompress 函数未检查数据长度的问题 #8606 在执行 execute 命令后重置 prepare 语句绑定的变量 #8652 支持对分区表自动收集统计信息 #8649 修复在下推 abs 函数时设置错误的整数类型 #8628 修复 JSON 列的数据竞争问题 #8660   Server  修复在 PD 故障时获取错误 TSO 的问题 #8567 修复不规范的语句导致启动失败的问题 #8576 修复在事务重试时使用了错误的参数 #8638   DDL  将表的默认字符集和排序规则改为 utf8mb4 和 utf8mb4_bin #8590 增加变量 ddl_reorg_batch_size 来控制添加索引的速度 #8614 DDL 中的 character set 和 collation 选项内容不再大小写敏感 #8611 修复对于生成列添加索引的问题 #8655    PD  修复一些配置项无法在配置文件中设置为 0 的问题 #1334 启动时检查未定义的配置 #1362 避免 transfer leader 至新创建的 Peer，优化可能产生的延迟增加问题 #1339 修复 RaftCluster 在退出时可能的死锁问题 #1370  TiKV  避免 transfer leader 至新创建的 Peer，优化可能产生的延迟增加问题 #3878  Tools  Lightning  优化对导入表的 analyze 机制，提升了导入速度 支持 checkpoint 信息储存在本地文件   TiDB Binlog  修复 pb files 输出 bug，表只有主键列则无法产生 pb event    </description>
    </item>
    
    <item>
      <title>TiDB 2.1.10 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.10/</guid>
      <description>TiDB 2.1.10 Release Notes 发版日期：2019 年 5 月 22 日
TiDB 版本：2.1.10
TiDB Ansible 版本：2.1.10
TiDB  修复在使用 tidb_snapshot 读取历史数据的时候，某些异常情况导致的表结构不正确 #10359 修复 NOT 函数在某些情况下导致的读取结果错误的问题 #10363 修复 Generated Column 在 Replace 或者 Insert on duplicate update 语句中的错误行为 #10385 修复 BETWEEN 函数在 DATE/DATETIME 类型比较的一个 bug #10407 修复使用 SLOW_QUERY 表查询慢日志时，单行慢日志长度过长导致的报错 #10412 修复某些情况下 DATETIME 和 INTERVAL 相加的结果跟 MySQL 不一致的问题 #10416，#10418 增加闰年二月的非法时间的检查 #10417 内部的初始化操作限制只在 DDL Owner 中执行，避免了初始化集群的时候出现的大量冲突报错 #10426 修复 DESC 在输出时间戳列的默认值为 default current_timestamp on update current_timestamp 时跟 MySQL 不兼容的问题 #10337 修复 Update 语句中权限检查出错的问题 #10439 修复 CHAR 类型的列在某些情况下 RANGE 计算错误导致的错误结果的问题 #10455 避免 ALTER SHARD_ROW_ID_BITS 缩小 shard bits 位数在极低概率下，可能导致的数据错误 #9868 修复 ORDER BY RAND() 不返回随机数字的问题 #10064 禁止 ALTER 语句修改 DECIMAL 的精度 #10458 修复 TIME_FORMAT 函数与 MySQL 的兼容问题 #10474 检查 PERIOD_ADD 中参数的合法性 #10430 修复非法的 YEAR 字符串在 TiDB 中的表现跟 MySQL 不兼容的问题 #10493 支持 ALTER DATABASE 语法 #10503 修复 SLOW_QUERY 内存表在慢语句没有 ; 的情况下报错的问题 #10536 修复某些情况下 Partitioned Table 的表 Add index 操作没有办法取消的问题 #10533 修复在某些情况下无法抓住内存使用太多导致 OOM 的问题 #10545 增强 DDL 操作改写表元信息的安全性 #10547  PD  修复 Leader 优先级不生效的问题 #1533  TiKV  拒绝在最近发生过成员变更的 Region 上执行 transfer leader，防止迁移失败 #4684 Coprocessor metrics 上添加 priority 标签 #4643 修复 transfer leader 中可能发生的脏读问题 #4724 修复某些情况下 CommitMerge 导致 TiKV 不能重启的问题 #4615 修复 unknown 的日志 #4730  Tools  TiDB Lightning  新增 TiDB Lightning 发送数据到 importer 失败时进行重试 #176   TiDB Binlog  优化 Pump storage 组件 log，以利于排查问题 #607    TiDB Ansible  更新 TiDB Lightning 配置文件，新增 tidb_lightning_ctl 脚本 #d3a4a368  </description>
    </item>
    
    <item>
      <title>TiDB 2.1.11 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.11/</guid>
      <description>TiDB 2.1.11 Release Notes 发版日期：2019 年 6 月 03 日
TiDB 版本：2.1.11
TiDB Ansible 版本：2.1.11
TiDB  修复 delete 多表 join 的结果时使用错误 schema 的问题 #10595 修复 CONVERT() 函数返回错误的字段类型的问题 #10263 更新统计信息时合并不重叠的反馈信息 #10569 修复 unix_timestamp()-unix_timestamp(now()) 计算错误的问题 #10491 修复 period_diff 与 MySQL 8.0 不兼容的问题 #10501 收集统计信息的时候，忽略 Virtual Column，避免异常报错 #10628 支持 SHOW OPEN TABLES 语句 #10374 修复某些情况下导致的 goroutine 泄露问题 #10656 修复某些情况下设置 tidb_snapshot 变量时间格式解析出错的问题 #10637  PD  修复因为 balance-region 可能会导致热点 Region 没有机会调度的问题 #1551 将热点相关调度的优先级改为高优先级 #1551 新增配置项 hot-region-schedule-limit 控制同时进行热点调度任务的数量及新增 hot-region-cache-hits-threshold 控制判断是否为热点 Region #1551  TiKV  修复在仅有一个 leader，learner 时，learner 读到空 index 的问题 #4751 将 ScanLock 和 ResolveLock 放在高优先级线程池中处理，减少对普通优先级命令的影响 #4791 同步所有收到的 snapshot 的文件 #4811  Tools  TiDB Binlog  新增 GC 删数据限速功能，避免因为删除数据导致 QPS 降低的问题 #620    TiDB Ansible  新增 Drainer 参数 #760  </description>
    </item>
    
    <item>
      <title>TiDB 2.1.12 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.12/</guid>
      <description>TiDB 2.1.12 Release Notes 发版日期：2019 年 6 月 13 日
TiDB 版本：2.1.12
TiDB Ansible 版本：2.1.12
TiDB  修复在使用 feedback 时由于类型不匹配导致进程 panic 的问题 #10755 修复某些情况下改变字符集导致 BLOB 类型变成 TEXT 类型的问题 #10745 修复某些情况下在事务中的 GRANT 操作误报 &amp;ldquo;Duplicate Entry&amp;rdquo; 错误的问题 #10739 提升以下功能跟 MySQL 的兼容性  DAYNAME 函数 #10732 MONTHNAME 函数 #10733 EXTRACT 函数在处理 MONTH 的时候支持零值 #10702 DECIMAL 类型转换成 TIMESTAMP 或者 DATETIME 类型 #10734   修改表的字符集时，同步修改列的字符集 #10714 修复某些情况下 DECIMAL 转换成浮点数的溢出问题 #10730 修复 TiDB 跟 TiKV 在 gRPC 最大封包设置不一致导致的某些超大封包报 &amp;ldquo;grpc: received message larger than max&amp;rdquo; 错误的问题 #10710 修复某些情况下 ORDER BY 没有过滤 NULL 值导致的 panic 问题 #10488 修复 UUID 函数的返回值，在多机器情况可能出现重复的问题 #10711 CAST(-num as datetime) 的返回值由错误变更为 NULL 值 #10703 修复某些情况下 unsigned 列直方图遇到 signed 越界的问题 #10695 修复统计信息的 feedback 遇到 bigint unsigned 主键时处理不正确导致读数据时报错的问题 #10307 修复分区表某些情况下 Show Create Table 结果显示不正确的问题 #10690 修复在某些关联子查询上聚合函数 GROUP_CONCAT 计算不正确的问题 #10670 修复某些情况下 slow query 内存表在解析慢日志的时候导致的显示结果错乱的问题 #10776  PD  修复极端情况下 etcd Leader 选举阻塞的问题 #1576  TiKV  修复极端条件下 Leader 迁移过程中 Region 不可用的问题 #4799 修复在机器异常掉电时由于接收 snapshot 未及时将数据刷新到磁盘导致丢数据的问题 #4850  </description>
    </item>
    
    <item>
      <title>TiDB 2.1.13 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.13/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.13/</guid>
      <description>TiDB 2.1.13 Release Notes 发版日期：2019 年 6 月 21 日
TiDB 版本：2.1.13
TiDB Ansible 版本：2.1.13
TiDB  新增列属性包含 AUTO_INCREMENT 时利用 SHARD_ROW_ID_BITS 打散行 ID 功能，缓解热点问题 #10788 优化无效 DDL 元信息存活时间，缩短集群升级后恢复 DDL 操作正常执行所需的时间 #10789 修复因持有 execdetails.ExecDetails 指针时 Coprocessor 的资源无法快速释放导致的在大并发场景下 OOM 的问题 #10833 新增 update-stats配置项，控制是否更新统计信息 #10772 新增 3 个 TiDB 特有语法，支持预先切分 Region，解决热点问题：  新增 Table Option PRE_SPLIT_REGIONS 选项 #10863 新增 SPLIT TABLE table_name INDEX index_name 语法 #10865 新增 SPLIT TABLE [table_name] BETWEEN (min_value...) AND (max_value.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.14 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.14/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.14/</guid>
      <description>TiDB 2.1.14 Release Notes 发版日期：2019 年 7 月 4 日
TiDB 版本：2.1.14
TiDB Ansible 版本：2.1.14
TiDB  修复某些情况下列裁剪导致查询结果不正确的问题 #11019 修复 show processlist 中 db 和 info 列信息显示有误的问题 #11000 修复 MAX_EXECUTION_TIME 作为 SQL hint 和全局变量在某些情况下不生效的问题 #10999 支持根据负载情况自动调整 Auto ID 分配的步长 #10997 修复 SQL 查询结束时 MemTracker 统计的 DistSQL 内存信息未正确清理的问题 #10971 information_schema.processlist 表中新增 MEM 列用于描述 Query 的内存使用情况 #10896 新增全局系统变量 max_execution_time，用于控制查询的最大执行时间 10940 修复使用未支持的聚合函数导致 TiDB panic 的问题 #10911 新增 load data 语句失败后自动回滚最后一个事务功能 #10862 修复 TiDB 超过内存配额的行为配置为 CANCEL 时，某些情况下 TiDB 返回结果不正确的问题 #11016 禁用 TRACE 语句，避免 TiDB panic 问题 #11039 新增 mysql.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.15 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.15/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.15/</guid>
      <description>TiDB 2.1.15 Release Notes 发版日期：2019 年 7 月 18 日
TiDB 版本：2.1.15
TiDB Ansible 版本：2.1.15
TiDB  修复 DATE_ADD 函数处理微秒时由于没有对齐导致结果不正确的问题 #11289 修复 DELETE 语句中，字符串列中的空值与 FLOAT/INT 做比较时会报错的问题 #11279 修复 INSERT 函数参数有 NULL 值时，未正确返回 NULL 值的问题 #11249 修复在非字符串类型且长度为 0 的列建立索引时出错的问题 #11215 新增 SHOW TABLE REGIONS 的语句，支持通过 SQL 查询表的 Region 分布情况 #11238 修复 UPDATE … SELECT 语句因 SELECT 子查询中使用投影消除来优化规则所导致的报错 #11254 新增 ADMIN PLUGINS ENABLE/DISABLE SQL 语句，支持通过 SQL 动态开启/关闭 Plugin #11189 Audit Plugin 新增审记连接功能 #11189 修复点查时，某列被查询多次而且结果为 NULL 时会 Panic 的问题 #11227 新增 tidb_scatter_region 配置项，控制创建表时是否开启自己打散 Record Region #11213 修复 RAND 函数由于非线程安全的 rand.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.16 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.16/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.16/</guid>
      <description>TiDB 2.1.16 Release Notes 发版日期：2019 年 8 月 15 日
TiDB 版本：2.1.16
TiDB Ansible 版本：2.1.16
TiDB  SQL 优化器  修复时间列上的等值条件 Row Count 估算不准确的问题 #11526 修复 TIDB_INLJ Hint 不生效或者对非指定的表生效的问题 #11361 将查询中的 NOT EXISTS 由 OUTER JOIN 实现方式改为 ANTI JOIN ，便于找到更优执行计划 #11291 支持在 SHOW 语句中使用子查询，现在可以支持诸如 SHOW COLUMNS FROM tbl WHERE FIELDS IN (SELECT &#39;a&#39;) 的写法 #11461 修复常量折叠优化导致 SELECT … CASE WHEN … ELSE NULL ... 查询结果不正确的问题 #11441   SQL 执行引擎  修复函数 DATE_ADD 在 INTERVAL 为负的情况下结果错误的问题 #11616 修复 DATE_ADD 函数接受 FLOAT、DOUBLE 和 DECIMAL 类型的参数时，没有正确地进行类型转换而导致结果可能不正确的问题 #11628 修复 CAST(JSON AS SIGNED) 出现 OVERFLOW 时错误信息不准确的问题 #11562 修复在关闭 Executor 的过程中，子节点关闭返回错误时其他子节点未关闭的问题 #11598 支持 SPLIT TABLE 语句返回切分成功的 REGION 数量，并且当部分 REGION SCATTER 在超时未完成调度时，不再返回错误，而是返回完成调度的比例 #11487 修复 REGEXP BINARY 函数对大小写敏感，与 MySQL 不兼容的问题 #11505 修复 DATE_ADD / DATE_SUB 结果中 YEAR 小于 0 或 大于 65535 时溢出导致结果没有正确返回 NULL 值的问题 #11477 慢查询表中添加用于表示是否执行成功的 Succ 字段 #11412 修复一条 SQL 语句在涉及当前时间计算时（例如 CURRENT_TIMESTAMP 或者 NOW），多次取当前时间值，结果与 MySQL不兼容的问题：现在同一条SQL语句中取当前时间时，均使用相同值 #11392 修复 AUTO INCREMENT 列未处理 FLOAT / DOUBLE 的问题 #11389 修复 CONVERT_TZ 函数在参数不合法时，没有正确返回 NULL 的问题 #11357 修复 PARTITION BY LIST 报错的问题（仅添加语法支持，TiDB 执行时候会作为普通表创建并提供提示信息） #11236 修复 Mod(%)、Multiple(*) 和 Minus(-) 返回结果为 0 时，在小数位数较多（例如 select 0.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.17 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.17/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.17/</guid>
      <description>TiDB 2.1.17 Release Notes 发版日期：2019 年 9 月 11 日
TiDB 版本：2.1.17
TiDB Ansible 版本：2.1.17
  新特性
 TiDB 的 SHOW TABLE REGIONS 语法新增 WHERE 条件子句 TiKV、PD 新增 config-check 功能，用于配置项检查 pd-ctl 新增 remove-tomestone 命令，支持清理 tombstone store 记录 Reparo 新增 worker-count 和 txn-batch 配置项，用于控制恢复速率    改进提升
 PD 优化调度流程，支持主动下发调度 TiKV 优化启动流程，减少重启节点带来的抖动    行为变更
 TiDB 慢日志中的 start ts 由最后一次重试的时间改为第一次执行的时间 TiDB 慢日志中的 Index_ids 字段替换为 Index_names 字段，提升慢日志易用性 TiDB 配置文件中添加 split-region-max-num 参数，用于调整 SPLIT TABLE 语法允许的最大 Region 数量，默认配置下，允许的数量由 1,000 增加至 10,000    TiDB  SQL 优化器  修复 EvalSubquery 在构建 Executor 出现错误时，错误信息没有被正确返回的问题 #11811 修复 Index Lookup Join 中，外表的行数大于一个 batch 时，查询的结果可能不正确的问题；扩大 Index Lookup Join 的作用范围：可以使用 UnionScan 作为 IndexJoin 的子节点 #11843 针对统计信息的反馈过程可能产生失效 Key 的情况，SHOW STAT_BUCKETS 语句现在增加了失效 Key 的显示，例如：invalid encoded key flag 252 #12098   SQL 执行引擎  修复 CAST 函数在进行数值类型转换时，首先将数值转换为 UINT 导致一些结果不正确的问题（例如，select cast(13835058000000000000 as double)）#11712 修复 DIV 运算的被除数为 DECIMAL 类型且运算含有负数时，运算结果可能不正确的问题 #11812 添加 ConvertStrToIntStrict 函数，修复执行 SELECT/EXPLAIN 语句时，一些字符串转换 INT 类型结果与 MySQL 不兼容的问题 #11892 修复使用 EXPLAIN .</description>
    </item>
    
    <item>
      <title>TiDB 2.1.18 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.18/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.18/</guid>
      <description>TiDB 2.1.18 Release Notes 发版日期：2019 年 11 月 4 日
TiDB 版本：2.1.18
TiDB Ansible 版本：2.1.18
TiDB  SQL 优化器  修复 Feedback 切分查询范围出错的问题 #12172 修复点查中权限检查不正确的问题 #12341 将 Limit 算子下推到 IndexLookUpReader 执行逻辑中，优化 select ... limit ... offset ... 的执行性能 #12380 支持在 ORDER BY、GROUP BY 和 LIMIT OFFSET 中使用参数 #12514 修复 partition 表上的 IndexJoin 返回错误结果的问题 #12713 修复 TiDB 中 str_to_date 函数在日期字符串和格式化字符串不匹配的情况下，返回结果与 MySQL 不一致的问题 #12757 修复当查询条件中包含 cast 函数时 outer join 被错误转化为 inner join 的问题 #12791 修复 AntiSemiJoin 的 join 条件中错误的表达式传递 #12800   SQL 执行引擎  修复时间取整不正确的问题 (如 2019-09-11 11:17:47.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.19 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.19/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.19/</guid>
      <description>TiDB 2.1.19 Release Notes 发版日期：2019 年 12 月 27 日
TiDB 版本：2.1.19
TiDB Ansible 版本：2.1.19
TiDB  SQL 优化器  优化 select max(_tidb_rowid) from t 的场景，避免全表扫 #13294 修复当查询语句中赋予用户变量错误的值且将谓词下推后导致错误的输出结果 #13230 修复更新统计信息时可能存在数据竞争，导致统计信息不准确的问题 #13690 修复 UPDATE 语句中同时包含子查询和 stored generated column 时结果错误的问题；修复 UPDATE 语句中包含不同数据库的两个表名相同时，UPDATE 执行报错的问题 #13357 修复 PhysicalUnionScan 算子没有正确设置统计信息，导致查询计划可能选错的问题 #14134 移除 minAutoAnalyzeRatio 约束使自动 ANALYZE 更及时 #14013 当 WHERE 子句上有 UNIQUE KEY 的等值条件时，估算行数应该不大于 1 #13385   SQL 执行引擎  修复 ConvertJSONToInt 中使用 int64 作为 uint64 的中间解析结果，导致精度溢出的问题 #13036 修复查询中包含 SLEEP 函数时（例如 select 1 from (select sleep(1)) t;)），由于列裁剪导致查询中的 sleep(1) 失效的问题 #13039 通过实现在 INSERT ON DUPLICATE UPDATE 语句中复用 Chunk 来降低内存开销 #12999 给 slow_query 表添加事务相关的信息段 #13129，如下：  Prewrite_time Commit_time Get_commit_ts_time Commit_backoff_time Backoff_types Resolve_lock_time Local_latch_wait_time Write_key Write_size Prewrite_region Txn_retry   修复 UPDATE 语句中包含子查询时转换子查询出现的错误和当 UPDATE 的 WHERE 条件中包含子查询时更新失败的问题 #13120 支持在分区表上执行 ADMIN CHECK TABLE #13143 修复 ON UPDATE CURRENT_TIMESTAMP 作为列的属性且指定浮点精度时，SHOW CREATE TABLE 等语句显示精度不完整的问题 #12462 修复在 DROP/MODIFY/CHANGE COLUMN 时没有检查外键导致执行 SELECT * FROM information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.2/</guid>
      <description>TiDB 2.1.2 Release Notes 2018 年 12 月 22 日，TiDB 发布 2.1.2 版，TiDB Ansible 相应发布 2.1.2 版本。该版本在 2.1.1 版的基础上，对系统兼容性、稳定性做出了改进。
TiDB  兼容 Kafka 版本的 TiDB Binlog #8747 完善滚动升级下 TiDB 的退出机制 #8707 修复在某些情况下为 generated column 增加索引 panic 的问题 #8676 修复在某些情况下语句有 TIDB_SMJ Hint 的时候优化器无法找到正确执行计划的问题 #8729 修复在某些情况下 AntiSemiJoin 返回错误结果的问题 #8730 增强 utf8 字符集的有效字符检查 #8754 修复事务中先写后读的情况下时间类型字段可能返回错误结果的问题 #8746  PD  修复 Region Merge 相关的 Region 信息更新问题 #1377  TiKV  支持以日 (d) 为时间单位的配置格式，并解决配置兼容性问题 #3931 修复 Approximate Size Split 可能会 panic 的问题 #3942 修复两个 Region merge 相关问题 #3822，#3873  Tools  TiDB Lightning  支持最小 TiDB 集群版本为 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.3/</guid>
      <description>TiDB 2.1.3 Release Notes 2019 年 01 月 28 日，TiDB 发布 2.1.3 版，TiDB Ansible 相应发布 2.1.3 版本。相比 2.1.2 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  优化器/执行器  修复某些情况下 Prepared Plan Cache panic 的问题 #8826 修复在有前缀索引的某些情况下，Range 计算错误的问题 #8851 当 SQL_MODE 不为 STRICT 时, CAST(str AS TIME(N)) 在 str 为非法的 TIME 格式的字符串时返回 NULL #8966 修复某些情况下 Generated Column 在 Update 中 Panic 的问题 #8980 修复统计信息直方图某些情况下上界溢出的问题 #8989 支持对 _tidb_rowid 构造查询的 Range，避免全表扫，减轻集群压力 #9059 CAST(AS TIME) 在精度太大的情况下返回一个错误 #9058 允许把 Sort Merge Join 用于笛卡尔积 #9037 修复统计信息的 worker 在某些情况下 panic 之后无法恢复的问题 #9085 修复某些情况下 Sort Merge Join 结果不正确的问题 #9046 支持在 CASE 子句返回 JSON 类型 #8355   Server  当语句中有非 TiDB hint 的注释时返回警告，而不是错误 #8766 验证设置的 TIMEZONE 的合法性 #8879 优化 Metrics 项 QueryDurationHistogram，展示更多语句的类型 #8875 修复 bigint 某些情况下下界溢出的问题 #8544 支持 ALLOW_INVALID_DATES SQL mode #9110   DDL  修复一个 RENAME TABLE 的兼容性问题，保持行为跟 MySQL 一致 #8808 支持 ADD INDEX 的并发修改即时生效 #8786 修复在 ADD COLUMN 的过程中，某些情况 Update 语句 panic 的问题 #8906 修复某些情况下并发创建 Table Partition 的问题 #8902 支持把 utf8 字符集转换为 utf8mb4 字符集 #8951 #9152 处理 Shard Bits 溢出的问题 #8976 支持 SHOW CREATE TABLE 输出列的字符集 #9053 修复 varchar 最大支持字符数在 utf8mb4 下限制的问题 #8818 支持 ALTER TABLE TRUNCATE TABLE PARTITION #9093 修复创建表的时候缺省字符集推算的问题 #9147    PD  修复 Leader 选举相关的 Watch 问题 #1396  TiKV  支持了使用 HTTP 方式获取监控信息 #3855 修复 data_format 遇到 NULL 时的问题 #4075 添加验证 Scan 请求的边界合法性 #4124  Tools  TiDB Binlog  修复在启动或者重启时 no available pump 的问题 #157 开启 Pump client log 输出 #165 修复表只有 unique key 没有 primary key 的情况下，unique key 包含 NULL 值导致数据更新不一致的问题    </description>
    </item>
    
    <item>
      <title>TiDB 2.1.4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.4/</guid>
      <description>TiDB 2.1.4 Release Notes 2019 年 2 月 15 日，TiDB 发布 2.1.4 版，TiDB Ansible 相应发布 2.1.4 版本。相比 2.1.3 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  优化器/执行器  修复 VALUES 函数未正确处理 FLOAT 类型的问题 #9223 修复某些情况下 CAST 浮点数成字符串结果不正确的问题 #9227 修复 FORMAT 函数在某些情况下结果不正确的问题 #9235 修复某些情况下处理 Join 查询时 panic 的问题 #9264 修复 VALUES 函数未正确处理 ENUM 类型的问题 #9280 修复 DATE_ADD/DATE_SUB 在某些情况下结果不正确的问题 #9284   Server  优化 reload privilege success 日志，将其调整为 DEBUG 级别 #9274   DDL  tidb_ddl_reorg_worker_cnt 和 tidb_ddl_reorg_batch_size 变成 GLOBAL 变量 #9134 修复某些异常情况下，在 Generated column 增加索引导致的 Bug #9289    TiKV  修复在 TiKV 关闭时可能发生重复写的问题 #4146 修复某些情况下 event listener 结果处理异常的问题 #4132  Tools  Lightning  优化内存使用 #107，#108 去掉 dump files 的 chunk 划分，减少对 dump files 的一次额外解析 #109 限制读取 dump files 的 I/O 并发，避免过多的 cache miss 导致性能下降 #110 对单个表实现 batch 导入，提高导入的稳定性 #110 TiKV 在 import 模式下开启 auto compactions #4199 增加禁用 TiKV periodic Level-1 compaction 参数，因为当 TiKV 集群为 2.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.5 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.5/</guid>
      <description>TiDB 2.1.5 Release Notes 2019 年 2 月 28 日，TiDB 发布 2.1.5 版，TiDB Ansible 相应发布 2.1.5 版本。相比 2.1.4 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  优化器/执行器  当列的字符集信息和表的字符集信息相同时，SHOW CREATE TABLE 不再打印列的字符集信息，使其结果更加兼容 MySQL #9306 将 Sort 算子中的表达计算抽取出来用一个 Project 算子完成，简化 Sort 算子的计算逻辑，修复某些情况下 Sort 算子结果不正确或者 panic 的问题 #9319 移除 Sort 算子中的数值为常量的排序字段 #9335，#9440 修复向无符号整数列插入数据时数据溢出的问题 #9339 目标 binary 的长度超过 max_allowed_packet 时，将 cast_as_binary 设置为 NULL #9349 优化 IF 和 IFNULL 的常量折叠过程 #9351 使用 skyline pruning 优化 TiDB 的索引选择，增加简单查询的稳定性 #9356 支持对析取范式计算选择率 #9405 修复 !</description>
    </item>
    
    <item>
      <title>TiDB 2.1.6 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.6/</guid>
      <description>TiDB 2.1.6 Release Notes 2019 年 3 月 15 日，TiDB 发布 2.1.6 版，TiDB Ansible 相应发布 2.1.6 版本。相比 2.1.5 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  优化器/执行器  当两个表在 TIDB_INLJ 的 Hint 中时，基于代价来选择外表 #9615 修复在某些情况下，没有正确选择 IndexScan 的问题 #9587 修复聚合函数在子查询里面的检查跟 MySQL 不兼容的行为 #9551 使 show stats_histograms 语句只输出合法的列，避免 Panic #9502   Server  支持变量 log_bin，用于开启/关闭 Binlog #9634 在事务中添加一个防御性检查，避免错误的事务提交 #9559 修复设置变量导致的 Panic 的问题 #9539   DDL  修复 Create Table Like 语句在某些情况导致 Panic 的问题 #9652 打开 etcd client 的 AutoSync 特性，防止某些情况下 TiDB 无法连接上 etcd 的问题 #9600    TiKV  修复在某些情况下解析 protobuf 失败导致 StoreNotMatch 错误的问题 #4303  Tools  Lightning  importer 的默认的 region-split-size 变更为 512 MiB #4369 保存原先在内存中的中间状态的 SST 到磁盘，减少内存使用 #4369 限制 RocksDB 的内存使用 #4369 修复 Region 还没有调度完成时进行 scatter 的问题 #4369 将大表的数据和索引分离导入，在分批导入时能有效降低耗时 #132 支援 CSV #111 修复库名中含非英数字符时导入失败的错误 #9547    </description>
    </item>
    
    <item>
      <title>TiDB 2.1.7 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.7/</guid>
      <description>TiDB 2.1.7 Release Notes 发版日期：2019 年 3 月 28 日
TiDB 版本：2.1.7
TiDB Ansible 版本：2.1.7
TiDB  修复因 DDL 被取消导致升级程序时启动时间变长问题 #9768 修复配置项 check-mb4-value-in-utf8 在 config.example.toml 中位置错误的问题 #9852 提升内置函数 str_to_date 跟 MySQL 的兼容性 #9817 修复内置函数 last_day 的兼容性问题 #9750 infoschema.tables 添加 tidb_table_id 列，方便通过 SQL 语句获取 table_id，新增 tidb_indexes 系统表管理 Table 与 Index 之间的关系 #9862 增加 Table Partition 定义为空的检查 #9663 将 Truncate Table 需要的权限由删除权限变为删表权限，与 MySQL 保持一致 #9876 支持在 DO 语句中使用子查询 #9877 修复变量 default_week_format 在 week 函数中不生效的问题 #9753 支持插件机制 #9880，#9888 支持使用系统变量 log_bin 查看 binlog 开启状况 #9634 支持使用 SQL 语句查看 Pump/Drainer 状态 #9896 修复升级时对 utf8 检查 mb4 字符的兼容性 #9887 修复某些情况下对 JSON 数据的聚合函数在计算过程中 Panic 的问题 #9927  PD  修改副本数为 1 时 balance-region 无法迁移 leader 问题 #1462  Tools  支持 binlog 同步 generated column #491  TiDB Ansible  Prometheus 监控数据默认保留时间改成 30d  </description>
    </item>
    
    <item>
      <title>TiDB 2.1.8 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.8/</guid>
      <description>TiDB 2.1.8 Release Notes 发版日期：2019 年 4 月 12 日
TiDB 版本：2.1.8
TiDB Ansible 版本：2.1.8
TiDB  修复 GROUP_CONCAT 函数在参数存在 NULL 值情况下与 MySQL 处理逻辑不兼容的问题 #9930 修复在 Distinct 模式下 decimal 类型值之间相等比较的问题 #9931 修复 SHOW FULL COLUMNS 语句在 date，datetime，timestamp 类型的 Collation 的兼容性问题  #9938 #10114   修复过滤条件存在关联列的时候统计信息估算行数不准确的问题 #9937 修复 DATE_ADD 跟 DATE_SUB 函数的兼容性问题  #9963 #9966   STR_TO_DATE 函数支持格式 %H，提升兼容性 #9964 修复 GROUP_CONCAT 函数在 group by 唯一索引的情况下结果错误的问题 #9969 当 Optimizer Hints 存在不匹配的表名的时候返回 warning #9970 统一日志格式规范，利于工具收集分析 日志规范 修复大量 NULL 值导致统计信息估算不准确的问题 #9979 修复 TIMESTAMP 类型默认值为边界值的时候报错的问题 #9987 检查设置 time_zone 值的合法性 #10000 支持时间格式 2019.</description>
    </item>
    
    <item>
      <title>TiDB 2.1.9 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/2.1.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/2.1.9/</guid>
      <description>TiDB 2.1.9 Release Notes 发版日期：2019 年 5 月 6 日
TiDB 版本：2.1.9
TiDB Ansible 版本：2.1.9
TiDB  修复 MAKETIME 函数在 unsigned 类型溢出时的兼容性 #10089 修复常量折叠在某些情况下导致的栈溢出 #10189 修复 Update 在某些有别名的情况下权限检查的问题 #10157 #10326 追踪以及控制 DistSQL 中的内存使用 #10197 支持指定 collation 为 utf8mb4_0900_ai_ci #10201 修复主键为 Unsigned 类型的时候，MAX 函数结果错误的问题 #10209 修复在非 Strict SQL Mode 下可以插入 NULL 值到 NOT NULL 列的问题 #10254 修复 COUNT 函数在 DISTINCT 有多列的情况下结果错误的问题 #10270 修复 LOAD DATA 解析不规则的 CSV 文件时候 Panic 的问题 #10269 忽略 Index Lookup Join 中内外 join key 类型不一致的时候出现的 overflow 错误 #10244 修复某些情况下错误判定语句为 point-get 的问题 #10299 修复某些情况下时间类型未转换时区导致的结果错误问题 #10345 修复 TiDB 字符集在某些情况下大小写比较不一致的问题 #10354 支持控制算子返回的行数 #9166  Selection &amp;amp; Projection #10110 StreamAgg &amp;amp; HashAgg #10133 TableReader &amp;amp; IndexReader &amp;amp; IndexLookup #10169   慢日志改进  增加 SQL Digest 用于区分同类 SQL #10093 增加慢语句使用的统计信息的版本信息 #10220 输出语句内存使用量 #10246 调整 Coprocessor 相关信息的输出格式，让其能被 pt-query-digest 解析 #10300 修复慢语句中带有 # 字符的问题 #10275 增加一些信息的列到慢查询的内存表 #10317 将事务提交时间算入慢语句执行时间 #10310 修复某些时间格式无法被 pt-query-digest 解析的问题 #10323    PD  支持 GetOperator 服务 #1514  TiKV  修复在 transfer leader 时非预期的 quorum 变化 #4604  Tools  TiDB Binlog  修复 unsigned int 类型的主键列的 binlog 数据为负数，造成同步出错中断的问题 #574 删除下游是 pb 时的压缩选项，修改下游名字 pb 成 file #597 修复 2.</description>
    </item>
    
    <item>
      <title>TiDB 3.0 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0beta/</guid>
      <description>TiDB 3.0 Beta Release Notes 2019 年 1 月 19 日，TiDB 发布 3.0 Beta 版，TiDB Ansible 相应发布 3.0 Beta 版本。相比 2.1 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。
TiDB  新特性  支持 View 支持窗口函数 支持 Range 分区 支持 Hash 分区   SQL 优化器  重新支持聚合消除的优化规则 #7676 优化 NOT EXISTS 子查询，将其转化为 Anti Semi Join #7842 添加 tidb_enable_cascades_planner 变量以支持新的 Cascades 优化器。目前 Cascades 优化器尚未实现完全，默认关闭 #7879 支持在事务中使用 Index Join #7877 优化 Outer Join 上的常量传播，使得对 Join 结果里和 Outer 表相关的过滤条件能够下推过 Outer Join 到 Outer 表上，减少 Outer Join 的无用计算量，提升执行性能 #7794 调整投影消除的优化规则到聚合消除之后，消除掉冗余的 Project 算子 #7909 优化 IFNULL 函数，当输入参数具有非 NULL 的属性的时候，消除该函数 #7924 支持对 _tidb_rowid 构造查询的 Range，避免全表扫，减轻集群压力 #8047 优化 IN 子查询为先聚合后做 Inner Join 并，添加变量 tidb_opt_insubq_to_join_and_agg 以控制是否开启该优化规则并默认打开 #7531 支持在 DO 语句中使用子查询 #8343 添加 Outer Join 消除的优化规则，减少不必要的扫表和 Join 操作，提升执行性能 #8021 修改 TIDB_INLJ 优化器 Hint 的行为，优化器将使用 Hint 中指定的表当做 Index Join 的 Inner 表 #8243 更大范围的启用 PointGet，使得当 Prepare 语句的执行计划缓存生效时也能利用上它 #8108 引入贪心的 Join Reorder 算法，优化多表 Join 时 Join 顺序选择的问题 #8394 支持 View #8757 支持 Window Function #8630 当 TIDB_INLJ 未生效时，返回 warning 给客户端，增强易用性 #9037 支持根据过滤条件和表的统计信息推导过滤后数据的统计信息的功能 #7921 增强 Range Partition 的 Partition Pruning 优化规则 #8885   SQL 执行引擎  优化 Merge Join 算子，使其支持空的 ON 条件 #9037 优化日志，打印执行 EXECUTE 语句时使用的用户变量 #7684 优化日志，为 COMMIT 语句打印慢查询信息 #7951 支持 EXPLAIN ANALYZE 功能，使得 SQL 调优过程更加简单 #7827 优化列很多的宽表的写入性能 #7935 支持 admin show next_row_id #8242 添加变量 tidb_init_chunk_size 以控制执行引擎使用的初始 Chunk 大小 #8480 完善 shard_row_id_bits，对自增 ID 做越界检查 #8936   Prepare 语句  对包含子查询的 Prepare 语句，禁止其添加到 Prepare 语句的执行计划缓存中，确保输入不同的用户变量时执行计划的正确性 #8064 优化 Prepare 语句的执行计划缓存，使得当语句中包含非确定性函数的时候，该语句的执行计划也能被缓存 #8105 优化 Prepare 语句的执行计划缓存，使得 DELETE/UPDATE/INSERT 的执行计划也能被缓存 #8107 优化 Prepare 语句的执行计划缓存，当执行 DEALLOCATE 语句时从缓存中剔除对应的执行计划 #8332 优化 Prepare 语句的执行计划缓存，通过控制其内存使用以避免缓存过多执行计划导致 TiDB OOM 的问题 #8339 优化 Prepare 语句，使得 ORDER BY/GROUP BY/LIMIT 子句中可以使用 “?</description>
    </item>
    
    <item>
      <title>TiDB 3.0 GA Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0-ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0-ga/</guid>
      <description>TiDB 3.0 GA Release Notes 发版日期：2019 年 6 月 28 日
TiDB 版本：3.0.0
TiDB Ansible 版本：3.0.0
Overview 2019 年 6 月 28 日，TiDB 发布 3.0 GA 版本，对应的 TiDB Ansible 版本为 3.0.0。 相比于 V2.1，V3.0.0 版本在以下方面有重要改进：
 稳定性方面，显著提升了大规模集群的稳定性，集群支持 150+ 存储节点，300+ TB 存储容量长期稳定运行。 易用性方面有显著的提升，降低用户运维成本，例如：标准化慢查询日志，制定日志文件输出规范，新增 EXPLAIN ANALYZE，SQL Trace 功能方便排查问题等。 性能方面，与 2.1 相比，TPC-C 性能提升约 4.5 倍，Sysbench 性能提升约 1.5 倍。因支持 View，TPC-H 50G Q15 可正常运行。 新功能方面增加了窗口函数、视图（实验特性）、分区表、插件系统、悲观锁（实验特性）、SQL Plan Management 等特性。  TiDB  新功能  新增 Window Function，支持所有 MySQL 8.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0 Beta.1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-beta.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-beta.1/</guid>
      <description>TiDB 3.0.0 Beta.1 Release Notes 发版日期：2019 年 3 月 26 日
TiDB 版本：3.0.0-beta.1
TiDB Ansible 版本：3.0.0-beta.1
Overview 2019 年 03 月 26 日，TiDB 发布 3.0.0 Beta.1 版，对应的 TiDB Ansible 版本为 3.0.0 Beta.1。相比 3.0.0 Beta 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。
TiDB  SQL 优化器  支持使用 Sort Merge Join 计算笛卡尔积 #9032 支持 Skyline Pruning，用一些规则来防止执行计划过于依赖统计信息 #9337   支持 Window Functions  NTILE #9682 LEAD 和 LAG #9672 PERCENT_RANK #9671 NTH_VALUE #9596 CUME_DIST #9619 FIRST_VALUE 和 LAST_VALUE #9560 RANK 和 DENSE_RANK #9500 RANGE FRAMED #9450 ROW FRAMED #9358 ROW NUMBER #9098     增加了一类统计信息，表示列和 handle 列之间顺序的相关性 #9315   SQL 执行引擎  增加内建函数  JSON_QUOTE #7832 JSON_ARRAY_APPEND #9609 JSON_MERGE_PRESERVE #8931 BENCHMARK #9252 COALESCE #9087 NAME_CONST #9261     根据查询上下文优化 Chunk 大小，降低 SQL 执行时间和集群的资源消耗 #6489   权限管理  支持 SET ROLE 和 CURRENT_ROLE #9581 支持 DROP ROLE #9616 支持 CREATE ROLE #9461   Server  新增 /debug/zip HTTP 接口，获取当前 TiDB 实例的信息 #9651 支持使用 show pump status/show drainer status 语句查看 Pump/Drainer 状态 #9456 支持使用 SQL 语句在线修改 Pump/Drainer 状态 #9789 支持给 SQL 文本加上 HASH 指纹，方便追查慢 SQL #9662 新增 log_bin 系统变量，默认：0，管理 binlog 开启状态，当前仅支持查看状态 #9343 支持通过配置文件管理发送 binlog 策略 #9864 支持通过内存表 INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0-rc.1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.1/</guid>
      <description>TiDB 3.0.0-rc.1 Release Notes 发版日期：2019 年 5 月 10 日
TiDB 版本：3.0.0-rc.1
TiDB Ansible 版本：3.0.0-rc.1
Overview 2019 年 5 月 10 日，TiDB 发布 3.0.0-rc.1 版，对应的 TiDB Ansible 版本为 3.0.0-rc.1。相比 3.0.0-beta.1 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。
TiDB   SQL 优化器
 利用列之间的顺序相关性提升代价估算准确度，并提供启发式参数 tidb_opt_correlation_exp_factor 用于控制在相关性无法被直接用于估算的场景下对索引扫描的偏好程度。#9839 当过滤条件中包含相关列时，在抽取复合索引的访问条件时尽可能多地匹配索引的前缀列。#10053 用动态规划决定连接的执行顺序，当参与连接的表数量不多于 tidb_opt_join_reorder_threshold 时启用。#8816 在构造 Index Join 的的内表中，以复合索引作为访问条件时，尽可能多地匹配索引的前缀列。#8471 提升对单列索引上值为 NULL 的行数估算准确度。#9474 在逻辑优化阶段消除聚合函数时特殊处理 GROUP_CONCAT ，防止产生错误的执行结果。#9967 当过滤条件为常量时，正确地将它下推到连接算子的子节点上。#9848 在逻辑优化阶段列剪裁时特殊处理一些函数，例如 RAND() ，防止产生和 MySQL 不兼容的执行结果。#10064 支持 FAST ANALYZE，通过tidb_enable_fast_analyze 变量控制。该特性通过用对 Region 进行采样取代扫描整个 region 的方式加速统计信息收集。#10258 支持 SQL PLAN MANAGEMENT。该特性通过对 SQL 进行执行计划绑定，以确保执行稳定性。该特性目前处于测试阶段，仅支持对 SELECT 语句使用绑定的执行计划，不建议在生产场景中直接使用。#10284    执行引擎</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0-rc.2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.2/</guid>
      <description>TiDB 3.0.0-rc.2 Release Notes 发版日期：2019 年 5 月 28 日
TiDB 版本：3.0.0-rc.2
TiDB Ansible 版本：3.0.0-rc.2
Overview 2019 年 5 月 28 日，TiDB 发布 3.0.0-rc.2 版本，对应的 TiDB Ansible 版本为 3.0.0-rc.2。相比 3.0.0-rc.1 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。
TiDB   SQL 优化器
 在更多的场景中支持 Index Join #10540 支持导出历史统计信息 #10291 支持对单调递增的索引列增量 Analyze #10355 忽略 Order By 子句中的 NULL 值 #10488 修复精简列信息时逻辑算子 UnionAll 的 Schema 信息的计算不正确的问题 #10384 下推 Not 操作符时避免修改原表达式 #10363 支持导入导出列的关联性信息 #10573    执行引擎
 有唯一索引的虚拟生成列可以在 replace on duplicate key update/insert on duplicate key update 语句中被正确地处理 #10370 修复 CHAR 列上的扫描范围计算 #10124 修复 PointGet 处理负数不正确问题 #10113 合并具有相同窗口名的窗口函数，提高执行效率 #9866 窗口函数中 Range Frame 可以无需 Order By 子句 #10496    Server</description>
    </item>
    
    <item>
      <title>TiDB 3.0.0-rc.3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.0-rc.3/</guid>
      <description>TiDB 3.0.0-rc.3 Release Notes 发版日期：2019 年 6 月 21 日
TiDB 版本：3.0.0-rc.3
TiDB Ansible 版本：3.0.0-rc.3
Overview 2019 年 6 月 21 日，TiDB 发布 3.0.0-rc.3 版本，对应的 TiDB Ansible 版本为 3.0.0-rc.3。相比 3.0.0-rc.2 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。
TiDB   SQL 优化器
 删除收集虚拟生成列的统计信息功能 #10629 修复点查时主键常量溢出的问题 #10699 修复 fast analyze 因使用未初始化的信息导致 panic #10691 修复 prepare create view 语句执行过程中因列信息错误导致执行失败的问题 #10713 修复在处理 window function 时列信息未拷贝的问题 #10720 修复 index join 中内表过滤条件在某些情况下的选择率估计错误的问题 #10854 新增变量 stats-lease 值为 0 时系统自动加载统计数据功能 #10811    执行引擎</description>
    </item>
    
    <item>
      <title>TiDB 3.0.1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.1/</guid>
      <description>TiDB 3.0.1 Release Notes 发版日期：2019 年 7 月 16 日
TiDB 版本：3.0.1
TiDB Ansible 版本：3.0.1
TiDB  新增对 MAX_EXECUTION_TIME 特性的支持 #11026 新增 tidb_wait_split_region_finish_backoff Session 变量，用于控制 Region 打散的 Backoff 时间 #11166 新增根据负载情况自动调整 Auto ID 分配的步长功能，步长自动调整范围最小 1000，最大 2000000 #11006 新增 ADMIN PLUGINS ENABLE/ADMIN PLUGINS DISABLE SQL 语句，管理 Plugin 的动态开启或关闭 #11157 Audit Plugin 新增审记连接功能 #11013 修改 Region 打散时的默认行为为等待 PD 调度完成 #11166 禁止 Window Function 在 Prepare Plan Cache 中被缓存，避免某些情况下出现结果不正确的问题 #11048 禁止使用 Alter 语句修改 Stored Generated Column 的定义 #11068 禁止将 Virtual Generated Column 更改为 Stored Generated Column #11068 禁止改变带有索引的 Generated Column 的表达式 #11068 支持 TiDB 在 ARM64 架构下的编译 #11150 支持修改 Database/Table 的 Collate，条件限制为 Database/Table 字符集必须是 UTF8/UTF8MB4 #11086 修复 UPDATE … SELECT 语句中，SELECT 子查询没有解析到 UPDATE 表达式中的列而被误裁剪，导致报错的问题 #11252 修复点查时，某列被查询多次而且结果为 NULL 时会 Panic 的问题 #11226 修复 RAND 函数由于非线程安全的 rand.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.10 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.10/</guid>
      <description>TiDB 3.0.10 Release Notes 发版日期：2020 年 02 月 20 日
TiDB 版本：3.0.10
TiDB Ansible 版本：3.0.10
TiDB  修复 IndexLookUpJoin 在利用 OtherCondition 构造 InnerRange 时出现错误 Join 结果 #14599 删除 tidb_pprof_sql_cpu 配置项，新增 Server 级别的 tidb_pprof_sql_cpu 变量 #14416 修复用户只在具有全局权限时才能查询所有数据库的问题 #14386 修复执行 point-get 时由于事务超时导致数据的可见性不符合预期的问题 #14480 将悲观事务激活的时机改为延迟激活，与乐观事务模型保持一致 #14474 修复 unixtimestamp 表达式在计算分区表分区的时区不正确的问题 #14476 新增tidb_session_statement_deadlock_detect_duration_seconds 监控项，用于监控死锁检测时间 #14484 修复 GC worker 由于部分逻辑不正确导致系统 panic 的问题 #14439 修复 IsTrue 函数的表达式名称不正确的问题 #14516 修复部分内存使用统计不准确的问题 #14533 修复统计信息 CM-Sketch 初始化时由于处理逻辑不正确导致系统 panic 的问题 #14470 修复查询分区表时分区裁剪（partition pruning）不准确的问题 #14546 修复 SQL 绑定中 SQL 语句默认数据库名设置不正确的问题 #14548 修复 json_key 与 MySQL 不兼容的问题 #14561 新增分区表自动更新统计信息的功能 #14566 修复执行 point-get时 plan id 会变化的问题，正常情况 plan id 始终是 1 #14595 修复 SQL 绑定不完全匹配时处理逻辑不正确导致系统 panic 的问题 #14263 新增 tidb_session_statement_pessimistic_retry_count 监控项，用于监控悲观事务加锁失败后重试次数 #14619 修复 show binding 语句权限检查不正确的问题 #14618 修复由于 backoff 的逻辑里没有检查 killed 标记，导致 kill 无法正确执行的问题 #14614 通过减少持有内部锁的时间来提高 statement summary 的性能 #14627 修复 TiDB 从字符串解析成时间与 MySQL 不兼容的问题 #14570 新增审计日志记录用户登录失败的功能 #14620 新增 tidb_session_ statement_lock_keys_count 监控项，用于监控悲观事务的 lock keys 的数量 #14634 修复 json 对 &amp;amp; &amp;lt; &amp;gt; 等字符输出转义不正确的问题 #14637 修复 hash-join 在建 hash-table 时由于内存使用过多导致系统 panic 的问题 #14642 修复 SQL 绑定处理不合法记录时处理逻辑不正确导致 panic 的问题 #14645 修复 Decimal 除法计算与 MySQL 不兼容的问题，Decimal 除法计算中增加 Truncated 错误检测 #14673 修复给用户授权不存在的表执行成功的问题 #14611  TiKV  Raftstore  修复由于 Region merge 失败导致系统 Panic #6460 或者数据丢失 #598 的问题 #6481 支持 yield 优化调度公平性，支持预迁移 leader 优化 leader 调度的稳定性 #6563    PD  当系统流量有变化时，系统自动更新 Region 缓存信息，解决缓存失效的问题 #2103 采用 leader 租约时间确定 TSO 的有效时间 #2117  Tools  TiDB Binlog  Drainer 支持 relay log #893   TiDB Lightning  优化配置项，部分配置项在没有设置的时候使用默认配置 #255 修复在非 server mode 模式下 web 界面无法打开的问题 #259    TiDB Ansible  修复某些场景获取不到 PD Leader 导致命令执行失败的问题 #1121 TiDB Dashboard 新增 Deadlock Detect Duration 监控项 #1127 TiDB Dashboard 新增 Statement Lock Keys Count 监控项 #1132 TiDB Dashboard 新增 Statement Pessimistic Retry Count 监控项 #1133  </description>
    </item>
    
    <item>
      <title>TiDB 3.0.11 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.11/</guid>
      <description>TiDB 3.0.11 Release Notes 发版日期：2020 年 03 月 04 日
TiDB 版本：3.0.11
TiDB Ansible 版本：3.0.11
TiDB 3.0.11 兼容性变化  TiDB  新增 max-index-length 配置项，用于控制索引支持的最大长度，用户可自由选择兼容 v3.0.7 之前版本或者兼容 MySQL #15057    新功能   TiDB
 新增在 information_schema.PARTITIONS 表中显示分区表的分区元信息的功能 #14849    TiDB Binlog
 新增 TiDB 集群之间数据双向复制功能 #884 #909    TiDB Lightning
 新增配置 TLS 功能 #44 #270    TiDB Ansible
 优化 create_user.yml 的逻辑，中控机使用的用户不必和 ansible_user 一致 #1184    Bug 修复   TiDB</description>
    </item>
    
    <item>
      <title>TiDB 3.0.12 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.12/</guid>
      <description>TiDB 3.0.12 Release Notes 发版日期：2020 年 03 月 16 日
TiDB 版本：3.0.12
TiDB Ansible 版本：3.0.12
TiDB 3.0.12 兼容性变化  TiDB  修复慢日志中记录 prewrite binlog 的时间部分计时不准确问题。原本计时的字段名是 Binlog_prewrite_time，这次修正后，名称更改为 Wait_prewrite_binlog_time。#15276    新功能   TiDB
 支持通过 alter instance 语句动态加载已被替换的证书文件 #15080 #15292 添加 cluster-verify-cn 配置项，配置后必须是对应 CN 证书才使用 status 服务 #15164 在每个 TiDB server 中添加对 DDL 请求的一个限流的功能，从而降低 DDL 请求冲突报错频率 #15148 支持在 binlog 写入失败时，TiDB 退出 #15339    Tools
 TiDB Binlog  Drainer 新增 kafka-client-id 配置项，支持连接 Kafka 客户端配置客户端 ID #929      Bug 修复   TiDB</description>
    </item>
    
    <item>
      <title>TiDB 3.0.2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.2/</guid>
      <description>TiDB 3.0.2 Release Notes 发版日期：2019 年 8 月 7 日
TiDB 版本：3.0.2
TiDB Ansible 版本：3.0.2
TiDB  SQL 优化器  修复当同一张表在查询里出现多次且逻辑上查询结果恒为空时报错 “Can’t find column in schema” 的问题 #11247 修复了 TIDB_INLJ Hint 无法以指定表为 Inner 表构建 IndexJoin 时仍，会强制将其作为 Outer 表构建 IndexJoin，同时 Hint 可能会在不应生效的地方生效的错误，该错误是由于强制选取 IndexJoin 的判断逻辑有误，以及对表别名的处理有误导致的；该错误仅对包含 TIDB_INLJ 的查询产生影响 #11362 修复某些情况下（例如 SELECT IF(1,c,c) FROM t），查询结果的列名称不正确的问题 #11379 修复 LIKE 表达式某些情况下被隐式转换为 0，导致诸如 SELECT 0 LIKE &#39;a string&#39; 返回结果为 TRUE 的问题 #11411 支持在 SHOW 语句中使用子查询，现在可以支持诸如 SHOW COLUMNS FROM tbl WHERE FIELDS IN (SELECT &#39;a&#39;) 的写法 #11459 修复 outerJoinElimination 优化规则没有正确处理列的别名，导致找不到聚合函数的相关列而查询报错的问题；改进了优化过程中对别名的解析，以使得优化可以覆盖更多类型的查询 #11377 修复 Window Function 中多个违反语义约束（例如 UNBOUNDED PRECEDING 不允许在 Frame 定义的最后）时没有报错的问题 #11543 修复 ERROR 3593 (HY000): You cannot use the window function FUNCTION_NAME in this context 报错信息中，FUNCTION_NAME 不为小写的问题，导致与 MySQL 不兼容 #11535 修复 Window Function 中 IGNORE NULLS 语法尚未实现，但使用时没有报错的问题 #11593 修复优化器对时间类型数据的等值条件代价估算不准确的问题 #11512 支持根据反馈信息对统计信息 Top-N 进行更新 #11507   SQL 执行引擎  修复 INSERT 函数在参数中包含 NULL 时，返回值不为 NULL 的问题 #11248 修复 ADMIN CHECKSUM 语句在检查分区表时计算结果不正确的问题 #11266 修复 INDEX JOIN 在使用前缀索引时可能结果不正确的问题 #11246 修复 DATE_ADD 函数在进行涉及微秒的日期减法时，没有正确地对日期的小数位数进行对齐导致结果不正确的问题 #11288 修复 DATE_ADD 函数没有正确地对 INTERVAL 中的负数部分处理导致结果不正确的问题 #11325 修复 Mod(%)、Multiple(*) 和 Minus(-) 返回结果为 0 时，在小数位数较多（例如 select 0.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.3/</guid>
      <description>TiDB 3.0.3 Release Notes 发版日期：2019 年 8 月 29 日
TiDB 版本：3.0.3
TiDB Ansible 版本：3.0.3
TiDB  SQL 优化器  添加 opt_rule_blacklist 表，用于禁用一些逻辑优化规则，比如 aggregation_eliminate，column_prune 等 #11658 修复 Index join 的 join key 中使用前缀索引或者使用 unsigned 的索引列等于负数时结果不正确的问题 #11759 修复 create … binding ... 的 Select 语句中带有 ” 或者 \ 时解析报错的问题 #11726   SQL 执行引擎  修复 Quote 函数处理 null 值的返回值类型出错的问题 #11619 修复 Max 和 Min 在推导类型时没有去除 NotNullFlag 导致 ifnull 结果错误的问题 #11641 修复对字符形式的 Bit 类型数据比较出错的问题 #11660 减少需要顺序读取数据的并发度，以降低 OOM 出现概率 #11679 修复对应含有多个参数的内置函数（如 if、coalesce 等），在多个参数都为 unsigned 时类型推导不正确的问题 #11621 修复 Div 函数处理 unsigned 的 decimal 类型时与 MySQL 行为不兼容的问题 #11813 修复执行修改 Pump/Drainer 状态的 SQL 时会报 panic 的问题 #11827 修复在 Autocommit = 1 且没有 begin 的时，select .</description>
    </item>
    
    <item>
      <title>TiDB 3.0.4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.4/</guid>
      <description>TiDB 3.0.4 Release Notes 发版日期：2019 年 10 月 8 日
TiDB 版本：3.0.4
TiDB Ansible 版本：3.0.4
  新特性
 新增系统表 performance_schema.events_statements_summary_by_digest，用于排查 SQL 级别的性能问题 TiDB 的 SHOW TABLE REGIONS 语法新增 WHERE 条件子句 Reparo 新增 worker-count 和 txn-batch 配置项，用于控制恢复速率    改进提升
 TiKV 支持批量 Split 和空的 Split 命令，使得 Split 可以批量进行 TiKV 添加 RocksDB 双向链表支持，提升逆序扫性能 Ansible 新增 iosnoop 和 funcslower 两个 perf 工具，方便诊断集群状态 TiDB 优化慢日志输出内容，删除冗余字段    行为变更
 TiDB 修改 txn-local-latches.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.5 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.5/</guid>
      <description>TiDB 3.0.5 Release Notes 发版日期：2019 年 10 月 25 日
TiDB 版本：3.0.5
TiDB Ansible 版本：3.0.5
TiDB  SQL 优化器  支持对 Window Functions 进行边界检查 #12404 修复 partition 表上的 IndexJoin 返回错误结果的问题 #12712 修复外连接 Apply 算子上层的 ifnull 函数返回错误结果的问题 #12694 修复当 UPDATE 的 where 条件中包含子查询时更新失败的问题 #12597 修复当查询条件中包含 cast 函数时 outer join 被错误转化为 inner join 的问题 #12790 修复 AntiSemiJoin 的 join 条件中错误的表达式传递 #12799 修复初始化统计信息时由于浅拷贝造成的统计信息出错问题 #12817 修复 TiDB 中 str_to_date 函数在日期字符串和格式化字符串不匹配的情况下，返回结果与 MySQL 不一致的问题 #12725   SQL 执行引擎  修复在 from_unixtime 函数处理 null 时发生 panic 的问题 #12551 修复 Admin Cancel DDL jobs 时报 invalid list index 错的问题 #12671 修复使用 Window Functions 时发生数组越界的问题 #12660 改进 AutoIncrement 列隐式分配时的行为，与 MySQL 自增锁的默认模式 (&amp;ldquo;consecutive&amp;rdquo; lock mode) 保持一致：对于单行 Insert 语句的多个自增 AutoIncrement ID 的隐式分配，TiDB 保证分配值的连续性。该改进保证 JDBC getGeneratedKeys() 方法在任意场景下都能得到正确的结果。#12602 修复当 HashAgg 作为 Apply 子节点时查询 hang 住的问题 #12766 修复逻辑表达式 AND 或 OR 在涉及类型转换时返回错误结果的问题 #12811   Server  实现修改事务 TTL 的接口函数，以助后续支持大事务 #12397 支持将事务的 TTL 按需延长（最长可到 10min），用于支持悲观事务 #12579 将 TiDB 缓存 schema 变更及相关表信息的次数从 100 调整为 1024，且支持通过 tidb_max_delta_schema_count 系统变量修改 #12502 更新了 kvrpc.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.6 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.6/</guid>
      <description>TiDB 3.0.6 Release Notes 发版日期：2019 年 11 月 28 日
TiDB 版本：3.0.6
TiDB Ansible 版本：3.0.6
TiDB  SQL 优化器  修复窗口函数 AST Restore SQL 文本后结果不正确问题，over w 不应被 restore 成 over (w) #12933 修复 stream aggregation 下推给 double read 的问题 #12690 修复 SQL bind 中引号处理不正确的问题 #13117 优化 select max(_tidb_rowid) from t 场景，避免全表扫 #13095 修复当查询语句中包含变量赋值表达式时查询结果不正确的问题 #13231 修复 UPDATE 语句中同时包含子查询和 generated column 时结果错误的问题；修复 UPDATE 语句中包含不同数据库的两个表名相同的表时，UPDATE 执行报错的问题 #13350 支持用 _tidb_rowid 做点查 #13416 修复分区表统计信息使用错误导致生成执行计划不正确的问题 #13628   SQL 执行引擎  修复 year 类型对于无效值的处理时和 MySQL 不兼容问题 #12745 在 INSERT ON DUPLICATE UPDATE 语句中复用 Chunk 以降低内存开销 #12998 添加内置函数 JSON_VALID 的支持 #13133 支持在分区表上执行 ADMIN CHECK TABLE #13140 修复对空表进行 FAST ANALYZE 时 panic 的问题 #13343 修复在包含多列索引的空表上执行 Fast Analyze 时 panic 的问题 #13394 修复当 WHERE 子句上有 UNIQUE KEY 的等值条件时，估算行数大于 1 的问题 #13382 修复当 TiDB 开启 Streaming 后返回数据有可能重复的问题 #13254 将 CMSketch 中出现次数最多的 N 个值抽取出来，提高估算准确度 #13429   Server  当 gRPC 请求超时时，提前让发往 TiKV 的请求失败 #12926 添加以下虚拟表：#13009  performance_schema.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.7 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.7/</guid>
      <description>TiDB 3.0.7 Release Notes 发版日期：2019 年 12 月 4 日
TiDB 版本：3.0.7
TiDB Ansible 版本：3.0.7
TiDB  修复 TiDB server 本地时间落后于 TSO 时间时，可能造成锁的 TTL 过大的问题 #13868 修复从字符串解析日期时，由于使用本地时区 (gotime.Local) 而导致解析结果的时区不正确的问题 #13793 修复 builtinIntervalRealSig 的实现中，binSearch 方法不会返回 error，导致最终结果可能不正确的问题 #13767 修复整型数据被转换为无符号浮点/Decimal 类型时，精度可能丢失造成数据错误的问题 #13755 修复 Natural Outer Join 和 Outer Join 使用 USING 语法时，not null 标记没有被重置导致结果错误的问题 #13739 修复更新统计信息时可能存在数据竞争，导致统计信息不准确的问题 #13687  TiKV  判断死锁检测服务的第一个 Region 时，加上 Region 合法检测，防止信息不完整的 Region 导致误判 #6110 修复潜在的内存泄漏问题 #6128  </description>
    </item>
    
    <item>
      <title>TiDB 3.0.8 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.8/</guid>
      <description>TiDB 3.0.8 Release Notes 发版日期：2019 年 12 月 31 日
TiDB 版本：3.0.8
TiDB Ansible 版本：3.0.8
TiDB  SQL 优化器  修复 SQL Binding 因为 cache 更新不及时，导致绑定计划错误的问题 #13891 修复当 SQL 包含符号列表（类似于 &amp;ldquo;?, ?, ?&amp;rdquo; 这样的占位符）时，SQL Binding 可能失效的问题 #14004 修复 SQL Binding 由于原 SQL 以 ; 结尾而不能创建/删除的问题 #14113 修复 PhysicalUnionScan 算子没有正确设置统计信息，导致查询计划可能选错的问题 #14133 移除 minAutoAnalyzeRatio 约束使自动 analyze 更及时 #14015   SQL 执行引擎  修复 INSERT/REPLACE/UPDATE ... SET ... = DEFAULT 语法会报错的问题，修复 DEFAULT 表达式与虚拟生成列配合使用会报错的问题 #13682 修复 INSERT 语句在进行字符串类型到浮点类型转换时，可能会报错的问题 #14011 修复 HashAgg Executor 并发值未被正确初始化，导致聚合操作执行在一些情况下效率低的问题 #13811 修复 group by item 被括号包含时执行报错的问题 #13658 修复 TiDB 没有正确计算 group by item，导致某些情况下 OUTER JOIN 执行会报错的问题 #14014 修复向 Range 分区表写入超过 Range 外的数据时，报错信息不准确的问题 #14107 鉴于 MySQL 8 即将废弃 PadCharToFullLength，revert PR #10124 并撤销 PadCharToFullLength 的效果，以避免一些特殊情况下查询结果不符合预期 #14157 修复 ExplainExec 中没有保证 close() 的调用而导致 EXPLAIN ANALYZE 时造成 goroutine 泄露的问题 #14226   DDL  优化 &amp;ldquo;change column&amp;rdquo;/&amp;ldquo;modify column&amp;rdquo; 的输出的报错信息，让人更容易理解 #13796 新增 SPLIT PARTITION TABLE 语法，支持分区表切分 Region 功能 #13929 修复创建索引时，没有正确检查长度，导致索引长度超过 3072 字节没有报错的问题 #13779 修复由于分区表添加索引时若花费时间过长，可能导致输出 GC life time is shorter than transaction duration 报错信息的问题 #14132 修复在 DROP COLUMN/MODIFY COLUMN/CHANGE COLUMN 时没有检查外键导致执行 SELECT * FROM information_schema.</description>
    </item>
    
    <item>
      <title>TiDB 3.0.9 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.0.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.0.9/</guid>
      <description>TiDB 3.0.9 Release Notes 发版日期：2020 年 01 月 14 日
TiDB 版本：3.0.9
TiDB Ansible 版本：3.0.9
TiDB  Executor  修复聚合函数作用于枚举和集合列时结果不正确的问题 #14364   Server  支持系统变量 auto_increment_increment 和 auto_increment_offset #14396 新增 tidb_tikvclient_ttl_lifetime_reach_total 监控项，监控悲观事务 TTL 达到 10 分钟的数量 #14300 执行 SQL 过程中当发生 panic 时输出导致 panic 的 SQL 信息 #14322 statement summary 系统表新增 plan 和 plan_digest 字段，记录当前正在执行的 plan 和 plan 的签名 #14285 配置项 stmt-summary.max-stmt-count 的默认值从 100 调整至 200 #14285 slow query 表新增 plan_digest 字段，记录 plan 的签名 #14292   DDL  修复 alter table .</description>
    </item>
    
    <item>
      <title>TiDB 3.1 Beta Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta/</guid>
      <description>TiDB 3.1 Beta Release Notes 发版日期：2019 年 12 月 20 日
TiDB 版本：3.1.0-beta
TiDB Ansible 版本：3.1.0-beta
TiDB  SQL 优化器  丰富 SQL hint #12192   新功能  TiDB 支持 Follower Read 功能 #12535    TiKV  支持分布式备份恢复功能 #5532 TiKV 支持 Follower Read 功能 #5562  PD  支持分布式备份恢复功能 #1896  </description>
    </item>
    
    <item>
      <title>TiDB 3.1 Beta.1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta.1/</guid>
      <description>TiDB 3.1 Beta.1 Release Notes 发版日期：2020 年 1 月 10 日
TiDB 版本：3.1.0-beta.1
TiDB Ansible 版本：3.1.0-beta.1
TiKV  backup  备份文件的名称由 start_key 改为 start_key 的 hash 值，减少文件名的长度，方便阅读 #6198 关闭 RocksDB force_consistency_checks 检查功能，避免一致性检查误报的问题 #6249 新增增量备份功能 #6286   sst_importer  修复恢复后 SST 文件没有 MVCC Properties 的问题 #6378 新增 tikv_import_download_duration、tikv_import_download_bytes、tikv_import_ingest_duration、tikv_import_ingest_bytes、tikv_import_error_counter 等监控项，用于观察 Download SST 和 Ingest SST 的开销 #6404   raftstore  修复因 Follower Read 在 leader 变更时读到旧数据的问题，导致事务的隔离性被破坏的问题 #6343    Tools  BR (Backup and Restore)  修复备份进度信息不准确的问题 #127 提升 split Region 的性能 #122 新增备份恢复分区表的功能 #137 新增自动调度 PD schedulers 功能 #123 修复非 PKIsHandle 表恢复后数据覆盖的问题 #139    TiDB Ansible  新增初始化阶段自动关闭操作系统 THP 的功能 #1086 新增 BR 组件的 Grafana 监控 #1093 优化 TiDB Lightning 部署，自动创建相关目录 #1104  </description>
    </item>
    
    <item>
      <title>TiDB 3.1 Beta.2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/3.1.0-beta.2/</guid>
      <description>TiDB 3.1 Beta.2 Release Notes 发版日期：2020 年 3 月 9 日
TiDB 版本：3.1.0-beta.2
TiDB Ansible 版本：3.1.0-beta.2
TiDB 3.1.0-beta.2 兼容性变化  Tools  TiDB Lightning  优化配置项，部分配置项在没有进行配置的时候使用 TiDB Lightning 配置参数中的默认配置 #255 新增 --tidb-password 命令行参数，用于设置 TiDB 的密码 #253      新功能   TiDB
 支持在列属性上添加 AutoRandom 关键字，控制系统自动为主键分配随机整数，避免 AUTO_INCREMENT 自增主键带来的写入热点问题 #14555 新增通过 DDL 语句为表创建、删除列存储副本的功能 #14537 新增优化器可自主选择不同的存储引擎的功能 #14537 新增 SQL Hint 支持不同的存储引擎的功能 #14537 新增通过 tidb_replic_read 系统变量从 Follower 上读取数据的功能 #13464    TiKV</description>
    </item>
    
    <item>
      <title>TiDB 3.1 升级操作指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/upgrade/from-previous-version/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/upgrade/from-previous-version/</guid>
      <description>TiDB 3.1 升级操作指南 本文档适用于从 TiDB 2.0、2.1、3.0 版本升级至 TiDB 3.1 版本以及 TiDB 3.1 低版本升级至 TiDB 3.1 高版本。目前，TiDB 3.1 版本兼容 TiDB Binlog Cluster 版本。
升级兼容性说明  不支持在升级后回退至 2.1.x 或更旧版本 从 2.0.6 之前的版本升级到 3.1 之前，需要确认集群中是否存在正在运行中的 DDL 操作，特别是耗时的 Add Index 操作，等 DDL 操作完成后再执行升级操作 2.1 及之后版本启用了并行 DDL，早于 2.0.1 版本的集群，无法滚动升级到 3.1，可以选择下面两种方案：  停机升级，直接从早于 2.0.1 的 TiDB 版本升级到 3.1 先滚动升级到 2.0.1 或者之后的 2.0.x 版本，再滚动升级到 3.1 版本     注意：
在升级的过程中不要执行 DDL 请求，否则可能会出现行为未定义的问题。
 在中控机器上安装 Ansible 及其依赖  注意：</description>
    </item>
    
    <item>
      <title>TiDB Ansible 常见运维操作</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/maintain/ansible-operations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/maintain/ansible-operations/</guid>
      <description>TiDB Ansible 常见运维操作 启动集群 此操作会按顺序启动整个 TiDB 集群所有组件（包括 PD、TiDB、TiKV 等组件和监控组件）。
 ansible-playbook start.yml 关闭集群 此操作会按顺序关闭整个 TiDB 集群所有组件（包括 PD、TiDB、TiKV 等组件和监控组件）。
 ansible-playbook stop.yml 清除集群数据 此操作会关闭 TiDB、Pump、TiKV、PD 服务，并清空 Pump、TiKV、PD 数据目录。
 ansible-playbook unsafe_cleanup_data.yml 销毁集群 此操作会关闭集群，并清空部署目录，若部署目录为挂载点，会报错，可忽略。
 ansible-playbook unsafe_cleanup.yml </description>
    </item>
    
    <item>
      <title>TiDB Binlog kafka 部署方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/tidb-binlog-kafka/</guid>
      <description>TiDB Binlog Kafka 部署方案 本文档介绍如何部署 Kafka 版本的 TiDB Binlog。
TiDB Binlog 简介 TiDB Binlog 是用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB Binlog 支持以下功能场景:
 数据同步：同步 TiDB 集群数据到其他数据库 实时备份和恢复：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB Binlog Kafka 架构 首先介绍 TiDB Binlog 的整体架构。
TiDB Binlog 集群主要分为三个组件：
Pump Pump 是一个守护进程，在每个 TiDB 主机的后台运行。其主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入 Kafka 中。
Drainer Drainer 从 Kafka 中收集 Binlog，并按照 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件。
Kafka &amp;amp; ZooKeeper Kafka 集群用来存储由 Pump 写入的 Binlog 数据，并提供给 Drainer 进行读取。</description>
    </item>
    
    <item>
      <title>TiDB Binlog Local 部署方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/tidb-binlog-local/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/tidb-binlog-local/</guid>
      <description>TiDB Binlog Local 部署方案 TiDB Binlog Local 简介 TiDB Binlog 是用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB Binlog 支持以下功能场景:
 数据同步：同步 TiDB 集群数据到其他数据库。 实时备份和恢复：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。  TiDB Binlog Local 架构 下图为 TiDB Binlog Local的整体架构。
TiDB Binlog Local 主要分为两个组件：
  Pump 是一个守护进程，在每个 TiDB 的主机上后台运行。他的主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入磁盘文件
  Drainer 从各个 Pump 节点收集 Binlog，并按照在 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件
  TiDB Binlog Local 安装 TiDB Binlog Local 下载 TiDB Binlog 包含在 tidb-enterprise-tools 安装包中，可在此下载。</description>
    </item>
    
    <item>
      <title>TiDB Binlog Relay Log</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/relay-log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/relay-log/</guid>
      <description>TiDB Binlog Relay Log Drainer 同步 binlog 时会拆分上游的事务，并将拆分的事务并发同步到下游。在极端情况下，上游集群不可用并且 Drainer 异常退出后，下游集群（MySQL 或 TiDB）可能处于数据不一致的中间状态。在此场景下，Drainer 借助 relay log 可以确保将下游集群同步到一个一致的状态。
Drainer 同步时的一致性状态 下游集群达到一致的状态是指：下游集群的数据等同于上游设置了 tidb_snapshot = ts 的快照。
checkpoint 状态一致性是指：Drainer checkpoint 通过 consistent 保存了同步的一致性状态。Drainer 运行时 consistent 为 false，Drainer 正常退出后 consistent 更新为 true。
查询下游 checkpoint 表的示例如下：
mysql&amp;gt; select * from tidb_binlog.checkpoint; +---------------------+----------------------------------------------------------------+ | clusterID | checkPoint | +---------------------+----------------------------------------------------------------+ | 6791641053252586769 | {&amp;#34;consistent&amp;#34;:false,&amp;#34;commitTS&amp;#34;:414529105591271429,&amp;#34;ts-map&amp;#34;:{}} | +---------------------+----------------------------------------------------------------+ 工作原理 Drainer 开启 relay log 后会先将 binlog event 写到磁盘上，然后再同步给下游集群。如果上游集群不可用，Drainer 可以通过读取 relay log 把下游集群恢复到一个一致的状态。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 常见错误修复</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/troubleshoot/error-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/troubleshoot/error-handling/</guid>
      <description>TiDB Binlog 常见错误修复 本文档介绍 TiDB Binlog 中常见的错误以及修复方法。
Drainer 同步数据到 Kafka 时报错 &amp;ldquo;kafka server: Message was too large, server rejected it to avoid allocation error&amp;rdquo; 报错原因：如果在 TiDB 中执行了大事务，则生成的 binlog 数据会比较大，可能超过了 Kafka 的消息大小限制。
解决方法：需要调整 Kafka 的配置参数，如下所示。
message.max.bytes=1073741824 replica.fetch.max.bytes=1073741824 fetch.message.max.bytes=1073741824 Pump 报错 &amp;ldquo;no space left on device&amp;rdquo; 报错原因：本地磁盘空间不足，Pump 无法正常写 binlog 数据。
解决方法：需要清理磁盘空间，然后重启 Pump。
Pump 启动时报错 &amp;ldquo;fail to notify all living drainer&amp;rdquo; 报错原因：Pump 启动时需要通知所有 Online 状态的 Drainer，如果通知失败则会打印该错误日志。
解决方法：可以使用 binlogctl 工具查看所有 Drainer 的状态是否有异常，保证 Online 状态的 Drainer 都在正常工作。如果某个 Drainer 的状态和实际运行情况不一致，则使用 binlogctl 修改状态，然后再重启 Pump。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 常见问题</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/faq/</guid>
      <description>TiDB Binlog 常见问题 本文介绍 TiDB Binlog 使用过程中的常见问题及解决方案。
开启 binog 对 TiDB 的性能有何影响？   对于查询无影响。
  对于有写入或更新数据的事务有一点性能影响。延迟上，在 Prewrite 阶段要并发写一条 p-binlog 成功后才可以提交事务，一般写 binlog 比 KV Prewrite 快，所以不会增加延迟。可以在 Pump 的监控面板看到写 binlog 的响应时间。
  Drainer 同步下游 TiDB/MySQL 的帐号需要哪些权限？ Drainer 同步帐号需要有如下权限：
 Insert Update Delete Create Drop Alter Execute Index Select  Pump 磁盘快满了怎么办？ 确认 GC 正常：
 确认 pump 监控面板 gc_tso 时间是否与配置一致，版本 &amp;lt;= v3.0.0 的 pump 会保证非 offline 状态 Drainer 消费了数据才会 gc，如果有不再使用的 Drainer 需要使用 binlogctl 下线。  如 gc 正常以下调整可以降低单个 pump 需要的空间大小：</description>
    </item>
    
    <item>
      <title>TiDB Binlog 故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/troubleshoot/binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/troubleshoot/binlog/</guid>
      <description>TiDB Binlog 故障诊断 本文总结了在 TiDB Binlog 的使用过程中遇到问题的诊断流程，并指引用户通过监控、状态、日志等信息查找相应的解决方案。
如果你在使用 TiDB Binlog 时出现了异常，请尝试以下方式排查问题：
  查看各个监控指标是否异常，参见TiDB Binlog 集群监控。
  使用 binlogctl 工具查看各个 Pump、Drainer 的状态是否有异常。
  查看 Pump、Drainer 日志中是否有 ERROR、WARN，并根据详细的日志信息初步判断问题原因。
  通过以上方式定位到问题后，在 FAQ 以及 常见错误及修复 中查找解决方案，如果没有查找到解决方案或者提供的解决方案无法解决问题，请提交 issue 或者联系相关技术支持人员。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 教程</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tidb-binlog/</guid>
      <description>TiDB Binlog 教程 本文档主要介绍如何使用 TiDB Binlog 将数据从 TiDB 推送到 MariaDB 实例。文中的 TiDB Binlog 集群包含 Pump 和 Drainer 的单个节点，TiDB 集群包含 TiDB、TiKV 和 Placement Driver (PD) 各组件的单个节点。
希望上手实践 TiDB Binlog 工具的用户需要对 TiDB 架构有一定的了解，最好有创建过 TiDB 集群的经验。该文档也有助于简单快速了解 TiDB Binlog 架构以及相关概念。
 警告：
该文档中部署 TiDB 的操作指导不适用于在生产或研发环境中部署 TiDB 的情况。
 该文档假设用户使用的是现代 Linux 发行版本中的 x86-64。示例中使用的是 VMware 中运行的 CentOS 7 最小化安装。建议在一开始就进行清洁安装，以避免受现有环境中未知情况的影响。如果不想使用本地虚拟环境，也可以使用云服务启动 CentOS 7 VM。
TiDB Binlog 简介 TiDB Binlog 用于收集 TiDB 中二进制日志数据、提供实时数据备份和同步以及将 TiDB 集群的数据增量同步到下游。
TiDB Binlog 支持以下功能场景：
 增量备份，将 TiDB 集群中的数据增量同步到另一个集群，或通过 Kafka 增量同步到选择的下游。 当使用 TiDB DM (Data Migration) 将数据从上游 MySQL 或者 MariaDB 迁移到 TiDB 集群时，可使用 TiDB Binlog 保持 TiDB 集群与其一个独立下游 MySQL 或 MariaDB 实例或集群同步。当 TiDB 集群上游数据迁移过程中出现问题，下游数据同步过程中可使用 TiDB Binlog 恢复数据到原先的状态。  更多信息参考 TiDB Binlog Cluster 版本用户文档。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 术语表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/glossary/</guid>
      <description>学习 TiDB Binlog 相关术语</description>
    </item>
    
    <item>
      <title>TiDB Binlog 版本升级方法</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/upgrade/</guid>
      <description>TiDB Binlog 版本升级方法 如未特别指明，文中出现的 TiDB Binlog 均指最新的 Cluster 版本。
本文会分 Ansible 部署和手动部署两种情况介绍 TiDB Binlog 版本升级的方法，另外有一小节介绍如何从更早的不兼容版本（Kafka/Local 版本）升级到最新版本。
Ansible 部署 本节适用于使用 TiDB Ansible Playbook 部署的情况。
升级 Pump  将新版本的二进制文件 pump 复制到 {{ resources_dir }}/bin 目录中 执行 ansible-playbook rolling_update.yml --tags=pump 命令来滚动升级 Pump  升级 Drainer  将新版本的二进制文件 drainer 复制到 {{ resources_dir }}/bin 目录中 执行 ansible-playbook stop_drainer.yml --tags=drainer 命令 执行 ansible-playbook start_drainer.yml --tags=drainer 命令  手动部署 升级 Pump 对集群里的每个 Pump 逐一升级，确保集群中总有 Pump 可以接收 TiDB 发来的 Binlog。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/overview/</guid>
      <description>TiDB Binlog 简介 TiDB Binlog 是一个用于收集 TiDB 的 binlog，并提供准实时备份和同步功能的商业工具。
TiDB Binlog 支持以下功能场景：
 数据同步：同步 TiDB 集群数据到其他数据库 实时备份和恢复：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB Binlog 整体架构 TiDB Binlog 集群主要分为 Pump 和 Drainer 两个组件，以及 binlogctl 工具：
Pump Pump 用于实时记录 TiDB 产生的 Binlog，并将 Binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。
Drainer Drainer 从各个 Pump 中收集 Binlog 进行归并，再将 Binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。
binlogctl 工具 binlogctl 是一个 TiDB Binlog 配套的运维工具，具有如下功能：
 获取 TiDB 集群当前的 TSO 查看 Pump/Drainer 状态 修改 Pump/Drainer 状态 暂停/下线 Pump/Drainer  主要特性  多个 Pump 形成一个集群，可以水平扩容。 TiDB 通过内置的 Pump Client 将 Binlog 分发到各个 Pump。 Pump 负责存储 Binlog，并将 Binlog 按顺序提供给 Drainer。 Drainer 负责读取各个 Pump 的 Binlog，归并排序后发送到下游。 Drainer 支持 relay log 功能，通过 relay log 保证下游集群的一致性状态。  注意事项   需要使用 TiDB v2.</description>
    </item>
    
    <item>
      <title>TiDB Binlog 运维</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/tidb-binlog/</guid>
      <description>了解如何在 Kubernetes 上运维 TiDB 集群的 TiDB Binlog。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 配置说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/configs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/configs/</guid>
      <description>TiDB Binlog 配置说明 本文档介绍 TiDB Binlog 的各项配置说明。
Pump 本节介绍 Pump 的配置项。可以在 Pump Configuration 中查看完整的 Pump 配置文件示例。
addr  HTTP API 的监听地址，格式为 host:port。 默认：&amp;quot;127.0.0.1:8250&amp;quot;  advertise-addr  对外可访问的 HTTP API 地址。这个地址会被注册到 PD，格式为 host:port。 默认：与 addr 的配置相同。  socket  HTTP API 监听的 Unix socket 地址。 默认：&amp;quot;&amp;quot;  pd-urls  由逗号分隔的 PD URL 列表。如果指定了多个地址，PD 客户端在连接一个地址时出错时会自动尝试连接另一个地址。 默认：&amp;quot;http://127.0.0.1:2379&amp;quot;  data-dir  本地存放 binlog 及其索引的目录。 默认：&amp;quot;data.pump&amp;quot;  heartbeat-interval  心跳间隔，即每隔指定秒数向 PD 汇报最新的状态。 默认：2  gen-binlog-interval  指定写入 fake binlog 的间隔秒数。 默认：3  gc  指定 binlog 可在本地存储的天数（整型）。超过指定天数的 binlog 会被自动删除。 默认：7  log-file  保存日志文件的路径。如果为空，日志不会被保存。 默认：&amp;quot;&amp;quot;  log-level  Log 等级。 默认：&amp;quot;info&amp;quot;  node-id  Pump 节点的 ID，用于在集群中识别这个进程。 默认：主机名:端口号，例如 node-1:8250。  security 以下是与安全相关的配置项。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 集群监控</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/monitor/</guid>
      <description>TiDB Binlog 集群监控 使用 Ansible 成功部署 TiDB Binlog 集群后，可以进入 Grafana Web 界面（默认地址: http://grafana_ip:3000，默认账号：admin，密码：admin）查看 Pump 和 Drainer 的运行状态。
监控指标 Pump    metric 名称 说明     Storage Size 记录磁盘的总空间大小 (capacity)，以及可用磁盘空间大小 (available)   Metadata 记录每个 Pump 的可删除 binlog 的最大 tso (gc_tso)，以及保存的 binlog 的最大的 commit tso (max_commit_tso)。   Write Binlog QPS by Instance 每个 Pump 接收到的写 binlog 请求的 QPS   Write Binlog Latency 记录每个 Pump 写 binlog 的延迟时间   Storage Write Binlog Size Pump 写 binlog 数据的大小   Storage Write Binlog Latency Pump 中的 storage 模块写 binlog 数据的延迟   Pump Storage Error By Type Pump 遇到的 error 数量，按照 error 的类型进行统计   Query TiKV Pump 通过 TiKV 查询事务状态的次数    Drainer    metric 名称 说明     Checkpoint TSO Drainer 已经同步到下游的 binlog 的最大 TSO 对应的时间。可以通过该指标估算同步延迟时间   Pump Handle TSO 记录 Drainer 从各个 Pump 获取到的 binlog 的最大 TSO 对应的时间   95% Binlog Reach Duration By Pump 记录 binlog 从写入 Pump 到被 Drainer 获取到这个过程的延迟时间   Error By Type Drainer 遇到的 error 数量，按照 error 的类型进行统计   SQL Query Time Drainer 在下游执行 SQL 的耗时   Drainer Event 各种类型 event 的数量，event 包括 ddl、insert、delete、update、flush、savepoint   Execute Time 写入 binlog 到同步下游模块所消耗的时间   95% Binlog Size Drainer 从各个 Pump 获取到 binlog 数据的大小   DL Job Count Drainer 处理的 DDL 的数量   Queue Size Drainer 内部工作队列大小    监控报警规则 本节介绍了 TiDB Binlog 组件的报警项及相应的报警规则。根据严重级别，报警项可分为三类，按照严重程度由高到低依次为：紧急级别 (Emergency)、重要级别 (Critical)、警告级别 (Warning)。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 集群运维</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/maintain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/maintain/</guid>
      <description>TiDB Binlog 集群运维 本文首先介绍 Pump 和 Drainer 的状态及启动、退出的内部处理流程，然后说明如何通过 binlogctl 工具或者直接在 TiDB 执行 SQL 操作来管理 binlog 集群，最后的 FAQ 部分会介绍一些常见问题以及处理方法。
Pump/Drainer 的状态 Pump/Drainer 中状态的定义：
 online：正常运行中 pausing：暂停中 paused：已暂停 closing：下线中 offline：已下线  这些状态由 Pump/Drainer 服务自身进行维护，并定时将状态信息更新到 PD 中。
Pump/Drainer 的启动、退出流程 Pump   启动：Pump 启动时会通知所有 online 状态的 Drainer，如果通知成功，则 Pump 将状态设置为 online，否则 Pump 将报错，然后将状态设置为 paused 并退出进程。
  退出：Pump 进程正常退出前要选择进入暂停或者下线状态；非正常退出（kill -9、进程 panic、宕机）都依然保持 online 状态。
 暂停：使用 kill（非 kill -9）、Ctrl+C 或者使用 binlogctl 的 pause-pump 命令都可以暂停 Pump。接收到暂停指令后，Pump 会变更状态为 pausing，并停止接受 binlog 的写请求，也停止向 Drainer 提供 binlog 数据。安全退出所有线程后，更新状态为 paused 然后退出进程。 下线：仅在使用 binlogctl 的 offline-pump 命令的情况下才会下线 Pump。接收到下线指令后，Pump 会变更状态为 closing，并停止接受 binlog 的写请求。Pump 继续向 Drainer 提供 binlog，等待所有 binlog 数据都被 Drainer 消费后再将状态设置为 offline 并退出进程。    Drainer   启动：Drainer 启动时将状态设置为 online，并尝试从所有非 offline 状态的 Pump 获取 binlog，如果获取 binlog 失败，会不断尝试重新获取。</description>
    </item>
    
    <item>
      <title>TiDB Binlog 集群部署</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/deploy/</guid>
      <description>TiDB Binlog 集群部署 服务器要求 Pump 和 Drainer 均可部署和运行在 Intel x86-64 架构的 64 位通用硬件服务器平台上。在开发、测试和生产环境下，对服务器硬件配置的要求和建议如下：
   服务 部署数量 CPU 磁盘 内存     Pump 3 8核+ SSD, 200 GB+ 16G   Drainer 1 8核+ SAS, 100 GB+ （如果输出 binlog 为本地文件，磁盘大小视保留数据天数而定） 16G    使用 TiDB Ansible 部署 TiDB Binlog 第 1 步：下载 TiDB Ansible   以 TiDB 用户登录中控机并进入 /home/tidb 目录。以下为 TiDB Ansible 分支与 TiDB 版本的对应关系，版本选择可咨询官方 info@pingcap.</description>
    </item>
    
    <item>
      <title>TiDB Controller 使用说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-control/</guid>
      <description>TiDB Controller 使用说明 TiDB Controller 是 TiDB 的命令行工具，用于获取 TiDB 状态信息，多用于调试。
源码编译 编译环境要求：Go Version 1.7 以上
编译步骤：在 TiDB Controller 项目根目录，使用 make 命令进行编译，生成 tidb-ctl。
编译文档：帮助文档在 doc 文件夹下，如丢失或需要更新，可通过 make doc 命令生成帮助文档。
使用介绍 tidb-ctl 的使用由命令（包括子命令）、选项和参数组成。命令即不带 - 或者 -- 的字符，选项即带有 - 或者 -- 的字符，参数即命令或选项字符后紧跟的传递给命令和选项的字符。
如：tidb-ctl schema in mysql -n db
 schema: 命令 in: schema 的子命令 mysql: in 的参数 -n: 选项 db: -n 的参数  获取帮助 tidb-ctl -h/--help 用于获取帮助信息。tidb-ctl 由多层命令组成，tidb-ctl 及其所有子命令都可以通过 -h/--help 来获取使用帮助。
连接 tidb-ctl 与连接相关的参数有 4 个，分别为：</description>
    </item>
    
    <item>
      <title>TiDB Data Migration 教程</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/data-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/data-migration/</guid>
      <description>TiDB Data Migration 教程 TiDB Data Migration (DM) 是一体化的数据同步任务管理平台，支持将大量、复杂的生产环境中的数据从 MySQL 或 MariaDB 迁移到 TiDB。
DM 功能如下：
 数据迁移  支持导出与导入源数据库的初始全量数据，并在数据迁移过程中读取、应用来自源数据库存储的 binlog，从而保持数据的同步。 通过合并上游的多个 MySQL 或 MariaDB 实例或集群的表，DM 能迁移生产环境中的分库分表。   将 TiDB 作为 MySQL 或 MariaDB 的从库时，DM 能持续提高数据库水平扩展的能力，或在无需 ETL 作业的情况下，在 TiDB 上进行数据实时分析。  本教程主要介绍如何使用 DM 迁移上游多个 MySQL 实例的一个分片表。包括两种场景：
 合并若干个互不冲突的表或分片，即这些表或分片的表结构并不会造成唯一键的冲突； 合并唯一键存在冲突的表。  本教程假设目前使用的是一台新的、纯净版 CentOS 7 实例，你能（使用 VMware、VirtualBox 及其他工具）在本地虚拟化或在供应商提供的平台上部署一台小型的云虚拟主机。因为需要运行多个服务，建议内存最好在 1 GB 以上。
 警告：
本教程中 TiDB 的部署方法并不适用于生产或开发环境。
 Data Migration 架构 TiDB Data Migration 平台由 3 部分组成：DM-master、DM-worker 和 dmctl。</description>
    </item>
    
    <item>
      <title>TiDB Data Migration 术语表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/glossary/</guid>
      <description>学习 TiDB Data Migration 相关术语</description>
    </item>
    
    <item>
      <title>TiDB Docker 部署方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/docker/</guid>
      <description>TiDB Docker 部署方案 本文介绍如何使用 Docker 部署一个多节点的 TiDB 集群。
 警告：
对于生产环境，不要使用 Docker 进行部署，而应使用 Ansible 部署 TiDB 集群。
 环境准备 安装 Docker Docker 可以方便地在 Linux / Mac OS / Windows 平台安装，安装方法请参考 Docker 官方文档。
拉取 TiDB 的 Docker 镜像 部署 TiDB 集群主要包括 3 个服务组件:
 TiDB TiKV PD  对应的最新 Docker 镜像可以通过 Docker 官方镜像仓库 获取：
 docker pull pingcap/tidb:latest  docker pull pingcap/tikv:latest  docker pull pingcap/pd:latest 部署一个多节点集群 假设我们打算在 6 台主机上部署一个 TiDB 集群:</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs-cn/v3.1/faq/tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/faq/tidb/</guid>
      <description>FAQ 一、 TiDB 介绍、架构、原理 1.1 TiDB 介绍及整体架构 1.1.1 TiDB 整体架构 TiDB 简介
1.1.2 TiDB 是什么？ TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。
1.1.3 TiDB 是基于 MySQL 开发的吗？ 不是，虽然 TiDB 支持 MySQL 语法和协议，但是 TiDB 是由 PingCAP 团队完全自主开发的产品。
1.1.4 TiDB、TiKV、Placement Driver (PD) 主要作用？  TiDB 是 Server 计算层，主要负责 SQL 的解析、制定查询计划、生成执行器。 TiKV 是分布式 Key-Value 存储引擎，用来存储真正的数据，简而言之，TiKV 是 TiDB 的存储引擎。 PD 是 TiDB 集群的管理组件，负责存储 TiKV 的元数据，同时也负责分配时间戳以及对 TiKV 做负载均衡调度。  1.</description>
    </item>
    
    <item>
      <title>TiDB in Kubernetes Sysbench 性能测试</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-in-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-in-k8s/</guid>
      <description>TiDB in Kubernetes Sysbench 性能测试 随着 TiDB Operator GA 发布，越来越多用户开始使用 TiDB Operator 在 Kubernetes 中部署管理 TiDB 集群。在本次测试中，我们选择 GKE 平台做了一次深入、全方位的测试，方便大家了解 TiDB 在 Kubernetes 中性能影响因素。
目的  测试典型公有云平台上 TiDB 性能数据 测试公有云平台磁盘、网络、CPU 以及不同 Pod 网络下对 TiDB 性能的影响  环境 版本与配置 本次测试统一使用 TiDB v3.0.1 版本进行测试。
TiDB Operator 使用 v1.0.0 版本。
PD、TiDB 和 TiKV 实例数均为 3 个。各组件分别作了如下配置，未配置部分使用默认值。
PD:
[log] level = &amp;#34;info&amp;#34; [replication] location-labels = [&amp;#34;region&amp;#34;, &amp;#34;zone&amp;#34;, &amp;#34;rack&amp;#34;, &amp;#34;host&amp;#34;] TiDB:
[log] level = &amp;#34;error&amp;#34; [prepared-plan-cache] enabled = true [tikv-client] max-batch-wait-time = 2000000 TiKV:</description>
    </item>
    
    <item>
      <title>TiDB Lightning TiDB-Backend</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/tidb-backend/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/tidb-backend/</guid>
      <description>了解 TiDB Lightning TiDB-backend。</description>
    </item>
    
    <item>
      <title>TiDB Lightning Web 界面</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/web/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/web/</guid>
      <description>了解 TiDB Lightning 的服务器模式——通过 Web 界面来控制 TiDB Lightning。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 常见的错误用法</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/error-case-handling/lightning-misuse-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/error-case-handling/lightning-misuse-handling/</guid>
      <description>TiDB Lightning 常见的错误用法 本文介绍了 TiDB Lightning 使用过程中常见的出错场景以及相应的处理方式。
报错：checksum mismatched remote vs local 在数据导入过程中遇到下面的报错
Error: checksum mismatched remote vs local =&amp;gt; (checksum: 3828723015727756136 vs 7895534721177712659) (total_kvs: 1221416844 vs 1501500000) (total_bytes:237660308510 vs 292158203078) 原因   先前使用过 TiDB Lightning 进行数据导入，但是对应的 checkpoint 的数据没有被清理，存在残留的数据。可以通过查看 TiDB Lightning 第一次启动 log 来确认：
 [checkpoint] driver = file，如果对应 TiDB Lightning 导入时间点的 log 存在 open checkpoint file failed, going to create a new one，那么 checkpoint 已经被正确清理，否则存在残留数据可能导致导入数据缺失； [checkpoint] driver = mysql，可以通过使用 TiDB API curl http://{TiDBIP}:10080/schema/{checkpoint.</description>
    </item>
    
    <item>
      <title>TiDB Lightning 常见问题</title>
      <link>https://pingcap.com/docs-cn/v3.1/faq/tidb-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/faq/tidb-lightning/</guid>
      <description>TiDB Lightning 常见问题 本文列出了一些使用 TiDB Lightning 时可能会遇到的问题与解决办法。
 注意：
使用 TiDB Lightning 的过程中如遇错误，参考 TiDB Lightning 故障诊断进行排查。
 TiDB Lightning 对 TiDB/TiKV/PD 的最低版本要求是多少？ TiDB Lightning 的版本应与集群相同。最低版本要求是 2.0.9，但建议使用最新的稳定版本 3.0。
TiDB Lightning 支持导入多个库吗？ 支持。
TiDB Lightning 对下游数据库的账号权限要求是怎样的？ TiDB Lightning 需要以下权限：
 SELECT UPDATE ALTER CREATE DROP  如果选择 TiDB-backend 模式，或目标数据库用于存储断点，则 TiBD Lightning 额外需要以下权限：
 INSERT DELETE  Importer-backend 无需以上两个权限，因为数据直接被 Ingest 到 TiKV 中，所以绕过了 TiDB 的权限系统。只要 TiKV、TiKV Importer 和 TiDB Lightning 的端口在集群之外不可访问，就可以保证安全。
如果 TiDB Lightning 配置项 checksum = true，则 TiDB Lightning 需要有下游 TiDB admin 用户权限。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/troubleshoot/tidb-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/troubleshoot/tidb-lightning/</guid>
      <description>TiDB Lightning 故障诊断 当 Lightning 遇到不可恢复的错误时便会异常退出，并在日志中记下错误原因。一般可在日志底部找到，也可以搜索 [error] 字符串找出中间发生的错误。本文主要描述一些常见的错误及其解决方法。
导入速度太慢 TiDB Lightning 的正常速度为每条线程每 2 分钟导入一个 256 MB 的数据文件，如果速度远慢于这个数值就是有问题。导入的速度可以检查日志提及 restore chunk … takes 的记录，或者观察 Grafana 的监控信息。
导入速度太慢一般有几个原因：
原因 1：region-concurrency 设定太高，线程间争用资源反而减低了效率。
 从日志的开头搜寻 region-concurrency 能知道 Lightning 读到的参数是多少。 如果 Lightning 与其他服务（如 Importer）共用一台服务器，必需手动将 region-concurrency 设为该服务器 CPU 数量的 75%。 如果 CPU 设有限额（例如从 Kubernetes 指定的上限），Lightning 可能无法自动判断出来，此时亦需要手动调整 region-concurrency。  原因 2：表结构太复杂。
每条索引都会额外增加键值对。如果有 N 条索引，实际导入的大小就差不多是 Mydumper 文件的 N+1 倍。如果索引不太重要，可以考虑先从 schema 去掉，待导入完成后再使用 CREATE INDEX 加回去。
原因 3：Lightning 版本太旧。
试试最新的版本吧！可能会有改善。
checksum failed: checksum mismatched remote vs local 原因：本地数据源跟目标数据库某个表的校验和不一致。这通常有更深层的原因：</description>
    </item>
    
    <item>
      <title>TiDB Lightning 教程</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tidb-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tidb-lightning/</guid>
      <description>TiDB Lightning 教程 TiDB Lightning 是一个将全量数据高速导入到 TiDB 集群的工具，目前支持 Mydumper 或 CSV 输出格式的数据源。你可以在以下两种场景下使用 Lightning：
 迅速导入大量新数据。 备份恢复所有数据。  TiDB Lightning 主要包含两个部分:
 tidb-lightning（“前端”）：主要完成适配工作，通过读取数据源，在下游 TiDB 集群建表、将数据转换成键/值对 (KV 对) 发送到 tikv-importer、检查数据完整性等。 tikv-importer（“后端”）：主要完成将数据导入 TiKV 集群的工作，把 tidb-lightning 写入的 KV 对缓存、排序、切分并导入到 TiKV 集群。  本教程假设使用的是若干新的、纯净版 CentOS 7 实例，你可以（使用 VMware、VirtualBox 及其他工具）在本地虚拟化或在供应商提供的平台上部署一台小型的云虚拟主机。因为 TiDB Lightning 对计算机资源消耗较高，建议分配 4 GB 以上的内存。
 警告：
本教程中的部署方法只适用于测试及功能体验，并不适用于生产或开发环境。
 准备全量备份数据 我们使用 mydumper 从 MySQL 导出数据，如下：
 ./bin/mydumper -h 127.0.0.1 -P 3306 -u root -t 16 -F 256 -B test -T t1,t2 --skip-tz-utc -o /data/my_database/ 其中：</description>
    </item>
    
    <item>
      <title>TiDB Lightning 断点续传</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/checkpoints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/checkpoints/</guid>
      <description>TiDB Lightning 断点续传 大量的数据导入一般耗时数小时至数天，长时间运行的进程会有一定机率发生非正常中断。如果每次重启都从头开始， 就会浪费掉之前已成功导入的数据。为此，Lightning 提供了“断点续传”的功能，即使 tidb-lightning 崩溃，在重启时仍然接着之前的进度继续工作。
本文主要介绍 TiDB Lightning 断点续传的启用与配置、断点的存储，以及断点续传的控制。
断点续传的启用与配置 [checkpoint] # 启用断点续传。 # 导入时，Lightning 会记录当前进度。 # 若 Lightning 或其他组件异常退出，在重启时可以避免重复再导入已完成的数据。 enable = true # 存储断点的方式 # - file：存放在本地文件系统（要求 v2.1.1 或以上） # - mysql：存放在兼容 MySQL 的数据库服务器 driver = &amp;#34;file&amp;#34; # 存储断点的架构名称（数据库名称） # 仅在 driver = &amp;#34;mysql&amp;#34; 时生效 # schema = &amp;#34;tidb_lightning_checkpoint&amp;#34; # 断点的存放位置 # # 若 driver = &amp;#34;file&amp;#34;，此参数为断点信息存放的文件路径。 # 如果不设置改参数则默认为 `/tmp/CHECKPOINT_SCHEMA.pb` # # 若 driver = &amp;#34;mysql&amp;#34;，此参数为数据库连接参数 (DSN)，格式为“用户:密码@tcp(地址:端口)/”。 # 默认会重用 [tidb] 设置目标数据库来存储断点。 # 为避免加重目标集群的压力，建议另外使用一个兼容 MySQL 的数据库服务器。 # dsn = &amp;#34;/tmp/tidb_lightning_checkpoint.</description>
    </item>
    
    <item>
      <title>TiDB Lightning 术语表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/glossary/</guid>
      <description>了解 TiDB Lightning 相关的术语及定义。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 监控告警</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/monitor/</guid>
      <description>TiDB Lightning 监控告警 tidb-lightning 和 tikv-importer 都支持使用 Prometheus 采集监控指标 (metrics)。本文主要介绍 TiDB Lightning 的监控配置与监控指标。
监控配置  如果是使用 TiDB Ansible 部署 Lightning，只要将服务器地址加到 inventory.ini 文件里的 [monitored_servers] 部分即可。 如果是手动部署 Lightning，则参照以下步骤进行配置。  tikv-importer tikv-importer v2.1 使用 Pushgateway 来推送监控指标。需要配置 tikv-importer.toml 来连接 Pushgateway：
[metric] # 给 Prometheus 客户端的推送任务名称。 job = &amp;#34;tikv-importer&amp;#34; # 给 Prometheus 客户端的推送间隔。 interval = &amp;#34;15s&amp;#34; # Prometheus Pushgateway 地址。 address = &amp;#34;&amp;#34; tidb-lightning 只要 Prometheus 能发现 tidb-lightning 的监控地址，就能收集监控指标。
监控的端口可在 tidb-lightning.toml 中配置：
[lightning] # 用于调试和 Prometheus 监控的 HTTP 端口。输入 0 关闭。 pprof-port = 8289 .</description>
    </item>
    
    <item>
      <title>TiDB Lightning 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/overview/</guid>
      <description>TiDB Lightning 简介 TiDB Lightning 是一个将全量数据高速导入到 TiDB 集群的工具，有以下两个主要的使用场景：一是大量新数据的快速导入；二是全量数据的备份恢复。目前，支持 Mydumper 或 CSV 输出格式的数据源。你可以在以下两种场景下使用 Lightning：
 迅速导入大量新数据。 备份恢复所有数据。  TiDB Lightning 整体架构 TiDB Lightning 主要包含两个部分：
 tidb-lightning（“前端”）：主要完成适配工作，通过读取数据源，在下游 TiDB 集群建表、将数据转换成键值对（KV 对）发送到 tikv-importer、检查数据完整性等。 tikv-importer（“后端”）：主要完成将数据导入 TiKV 集群的工作，对 tidb-lightning 写入的键值对进行缓存、排序、切分操作并导入到 TiKV 集群。  TiDB Lightning 整体工作原理如下：
  在导数据之前，tidb-lightning 会自动将 TiKV 集群切换为“导入模式” (import mode)，优化写入效率并停止自动压缩。
  tidb-lightning 会在目标数据库建立架构和表，并获取其元数据。
  每张表都会被分割为多个连续的区块，这样来自大表 (200 GB+) 的数据就可以用增量方式导入。
  tidb-lightning 会通过 gRPC 让 tikv-importer 为每一个区块准备一个“引擎文件 (engine file)”来处理键值对。tidb-lightning 会并发读取 SQL dump，将数据源转换成与 TiDB 相同编码的键值对，然后发送到 tikv-importer 里对应的引擎文件。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 表库过滤</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/table-filter/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/table-filter/</guid>
      <description>使用黑白名单把一些表剔出要导入的范围。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 部署与执行</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/deployment/</guid>
      <description>TiDB Lightning 部署与执行 本文主要介绍 TiDB Lightning 使用 Importer-backend（默认）进行数据导入的硬件需求，以及使用 Ansible 部署与手动部署 TiDB Lightning 这两种部署方式。
如果你想改用 TiDB-backend 进行数据导入，参考 TiDB Lightning TiDB-backend 中的硬件需求与部署方式。
注意事项 在使用 TiDB Lightning 前，需注意以下事项：
  TiDB Lightning 运行后，TiDB 集群将无法正常对外提供服务。
  若 tidb-lightning 崩溃，集群会留在“导入模式”。若忘记转回“普通模式”，集群会产生大量未压缩的文件，继而消耗 CPU 并导致延迟。此时，需要使用 tidb-lightning-ctl 手动将集群转回“普通模式”：
 bin/tidb-lightning-ctl -switch-mode=normal   TiDB Lightning 需要下游 TiDB 有如下权限：
   权限 作用域     SELECT Tables   INSERT Tables   UPDATE Tables   DELETE Tables   CREATE Databases, tables   DROP Databases, tables   ALTER Tables    如果配置项 checksum = true，则 TiDB Lightning 需要有下游 TiDB admin 用户权限。</description>
    </item>
    
    <item>
      <title>TiDB Lightning 配置参数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tidb-lightning/config/</guid>
      <description>使用配置文件或命令行配置 TiDB Lightning。</description>
    </item>
    
    <item>
      <title>TiDB Operator 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/tidb-operator-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/tidb-operator-overview/</guid>
      <description>TiDB Operator 简介 TiDB Operator 是 Kubernetes 上的 TiDB 集群自动运维系统，提供包括部署、升级、扩缩容、备份恢复、配置变更的 TiDB 全生命周期管理。借助 TiDB Operator，TiDB 可以无缝运行在公有云或私有部署的 Kubernetes 集群上。
 注意：
每个 Kubernetes 集群中只能部署一个 TiDB Operator。
 TiDB Operator 整体架构 其中，TidbCluster 是由 CRD（CustomResourceDefinition）定义的自定义资源，用于描述用户期望的 TiDB 集群状态。TiDB 集群的编排和调度逻辑则由下列组件负责：
 tidb-controller-manager 是一组 Kubernetes 上的自定义控制器。这些控制器会不断对比 TidbCluster 对象中记录的期望状态与 TiDB 集群的实际状态，并调整 Kubernetes 中的资源以驱动 TiDB 集群满足期望状态； tidb-scheduler 是一个 Kubernetes 调度器扩展，它为 Kubernetes 调度器注入 TiDB 集群特有的调度逻辑。  此外，TiDB Operator 还提供了命令行接口 tkctl 用于运维集群和诊断集群问题。
上图是 TiDB Operator 的控制流程解析。由于 TiDB 集群还需要监控、初始化、定时备份、Binlog 等组件，TiDB Operator 中使用 Helm Chart 封装了 TiDB 集群定义。整体的控制流程如下：</description>
    </item>
    
    <item>
      <title>TiDB Pre-GA Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/prega/</guid>
      <description>TiDB Pre-GA Release Notes 2017 年 8 月 30 日，TiDB 发布 Pre-GA 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL 查询优化器  调整代价模型 优化索引选择，支持不同类型字段比较的索引选择 支持基于贪心算法的 Join Reorder   大量 MySQL 兼容性相关功能 支持 Natural Join 完成 JSON 类型支持 (Experimental)，包括对 JSON 中的字段查询、更新、建索引 裁剪无用数据，减小执行器内存消耗 支持在 SQL 语句中设置优先级，并根据查询类型自动设置部分语句的优先级 完成表达式重构，执行速度提升 30% 左右  PD  支持手动切换 PD 集群 Leader  TiKV  Raft Log 使用独立的 RocksDB 实例 使用 DeleteRange 加快删除副本速度 Coprocessor 支持更多运算符下推 提升性能，提升稳定性  TiSpark Beta Release  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/rc1/</guid>
      <description>TiDB RC1 Release Notes 2016 年 12 月 23 日，分布式关系型数据库 TiDB 正式发布 RC1。
TiKV  提升写入速度 降低磁盘空间占用 支持百 TB 级别数据 提升稳定性，集群规模支持 200 个节点 提供 Raw KV API，以及 Golang client  PD  PD 调度策略框架优化，策略更加灵活合理 添加 label 支持，支持跨 DC 调度 提供 PD Controler，方便操作 PD 集群  TiDB  SQL 查询优化器  支持 eager aggregate 更详细的 explain 信息 union 算子并行化 子查询性能优化 条件下推优化 优化 CBO 框架   重构 time 相关类型的实现，提升和 MySQL 的兼容性 支持更多的 MySQL 内建函数 Add Index 语句提速 支持用 change column 语句修改列名；支持使用 Alter table 的 modify column 和 change column 完成部分列类型转换  工具  Loader：兼容 Percona 的 Mydumper 数据格式，提供多线程导入、出错重试、断点续传等功能，并且针对 TiDB 有优化 开发完成一键部署工具  </description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/rc2/</guid>
      <description>TiDB RC2 Release Notes 2017 年 3 月 1 日，TiDB 正式发布 RC2 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。对于 OLTP 场景，读取性能提升 60%，写入性能提升 30%。另外提供了权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推   支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息    TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/rc3/</guid>
      <description>TiDB RC3 Release Notes 2017 年 6 月 16 日，TiDB 正式发布 RC3 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了负载均衡调度策略和流程。功能方面进一步完善权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。另外 DDL 的速度也得到显著的提升。 同时为了简化运维工作，开源了 TiDB Ansible 项目，可以一键部署/升级/启停 TiDB 集群。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推   支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息    TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/rc4/</guid>
      <description>TiDB RC4 Release Notes 2017 年 8 月 4 日，TiDB 正式发布 RC4 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了写入速度，计算任务调度支持优先级，避免分析型大事务影响在线事务。SQL 优化器全新改版，查询代价估算更加准确，且能够自动选择 Join 物理算子。功能方面进一步 MySQL 兼容性。 同时为了更好的支持 OLAP 业务，开源了 TiSpark 项目，可以通过 Spark 读取和分析 TiKV 中的数据。
TiDB  SQL 查询优化器重构  更好的支持 TopN 查询 支持 Join 算子根据代价自动选择 更完善的 Projection Elimination   Schema 版本检查区分 Table，避免 DDL 干扰其他正在执行的事务 支持 BatchIndexJoin 完善 Explain 语句 提升 Index Scan 性能 大量 MySQL 兼容性相关功能 支持 Json 类型及其操作 支持查询优先级、隔离级别的设置  PD  支持通过 PD 设置 TiKV location labels 调度优化  支持 PD 主动向 TiKV 下发调度命令 加快 region heartbeat 响应速度 优化 balance 算法   优化数据加载，加快 failover 速度  TiKV  支持查询优先级设置 支持 RC 隔离级别 完善 Jepsen，提升稳定性 支持 Document Store Coprocessor 支持更多下推函数 提升性能，提升稳定性  TiSpark Beta Release  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB Sysbench 性能对比测试报告 - v2.0.0 对比 v1.0.0</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v2/</guid>
      <description>TiDB Sysbench 性能对比测试报告 - v2.0.0 对比 v1.0.0 测试目的 对比 TiDB 2.0 版本和 1.0 版本在 OLTP 场景下的性能。
测试版本、时间、地点 TiDB 版本：v1.0.8 Vs v2.0.0-rc6
时间：2018 年 4 月
地点：北京
测试环境 IDC 机器
   类别 名称     OS Linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz   RAM 128GB   DISK Optane 500GB SSD * 1    测试方案 TiDB 版本信息 v1.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench 性能对比测试报告 - v2.1 对比 v2.0</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v3/</guid>
      <description>TiDB Sysbench 性能对比测试报告 - v2.1 对比 v2.0 测试目的 对比 TiDB 2.1 版本和 2.0 版本在 OLTP 场景下的性能。
测试版本、时间、地点 TiDB 版本：v2.1.0-rc.2 vs. v2.0.6
时间：2018 年 9 月
地点：北京
测试环境 IDC 机器：
   类别 名称     OS Linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz   RAM 128GB   DISK Optane 500GB SSD * 1    Sysbench 版本：1.</description>
    </item>
    
    <item>
      <title>TiDB Sysbench 性能对比测试报告 - v3.0 对比 v2.1</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/sysbench-v4/</guid>
      <description>TiDB Sysbench 性能对比测试报告 - v3.0 对比 v2.1 测试目的 对比 TiDB 3.0 版本和 2.1 版本在 OLTP 场景下的性能。
测试版本、时间、地点 TiDB 版本：v3.0.0 vs. v2.1.13
时间：2019 年 6 月
地点：北京
测试环境 测试在 AWS EC2 上进行，使用 CentOS-7.6.1810-Nitro (ami-028946f4cffc8b916) 镜像，各组件实例类型如下：
   组件 实例类型     PD r5d.xlarge   TiKV c5d.4xlarge   TiDB c5.4xlarge    Sysbench 版本：1.0.17
测试方案 使用 Sysbench 向集群导入 16 张表，每张数据 1000 万。起 3 个 sysbench 分别向 3 个 TiDB 发压，请求并发数逐步增加，单次测试时间 5 分钟。</description>
    </item>
    
    <item>
      <title>TiDB TPC-C 性能对比测试报告 - v3.0 对比 v2.1</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/tpcc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/tpcc/</guid>
      <description>TiDB TPC-C 性能对比测试报告 - v3.0 对比 v2.1 测试目的 对比 TiDB 3.0 版本和 2.1 版本的 TPC-C 性能表现。
测试版本、时间、地点 TiDB 版本：v3.0.0 vs. v2.1.13
时间：2019 年 6 月
地点：北京
测试环境 IDC 机器：
   类别 名称     OS Linux (CentOS 7.3.1611)   CPU 40 vCPUs, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz   RAM 128GB   DISK 1.5TB SSD * 2    本文使用开源的 BenchmarkSQL 5.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G 性能测试报告</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/tpch-v2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/tpch-v2/</guid>
      <description>TiDB TPC-H 50G 性能测试报告 测试目的 测试 TiDB 在 OLAP 场景下 2.0 和 2.1 版本的性能对比。
 注意：
不同的测试环境可能使测试结果发生改变。
 测试环境 测试机器信息   系统信息
   机器 IP 操作系统 内核版本 文件系统类型     10.0.1.4 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.5 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.6 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.7 CentOS 7.5.1804 64bit 3.10.0-862.3.3.el7.x86_64 ext4   10.0.1.8 CentOS 7.5.1804 64bit 3.</description>
    </item>
    
    <item>
      <title>TiDB TPC-H 50G 性能测试报告</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/tpch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/tpch/</guid>
      <description>TiDB TPC-H 50G 性能测试报告 测试目的 测试 TiDB 在 OLAP 场景下 1.0 和 2.0 版本的性能对比。
 注意：
不同的测试环境可能使测试结果发生改变。
 测试环境 测试机器信息   系统信息
   机器 IP 操作系统 内核版本 文件系统类型     172.16.31.2 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.3 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.4 Ubuntu 17.10 64bit 4.13.0-16-generic ext4   172.16.31.6 CentOS 7.4.1708 64bit 3.10.0-693.11.6.el7.x86_64 ext4   172.16.31.8 CentOS 7.4.1708 64bit 3.</description>
    </item>
    
    <item>
      <title>TiDB 专用系统变量和语法</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/tidb-specific-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/tidb-specific-variables/</guid>
      <description>TiDB 专用系统变量和语法 TiDB 在 MySQL 的基础上，定义了一些专用的系统变量和语法用来优化性能。
系统变量 变量可以通过 SET 语句设置，例如
 set @@tidb_distsql_scan_concurrency = 10; 如果需要设置全局变量，执行
 set @@global.tidb_distsql_scan_concurrency = 10; tidb_snapshot 作用域：SESSION
默认值：空字符串
这个变量用来设置当前会话期待读取的历史数据所处时刻。比如当设置为 &amp;ldquo;2017-11-11 20:20:20&amp;rdquo; 时或者一个 TSO 数字 &amp;ldquo;400036290571534337&amp;rdquo;，当前会话将能读取到该时刻的数据。
tidb_import_data 作用域：SESSION
默认值：0
这个变量用来表示当前状态是否为从 dump 文件中导入数据。 当这个变量被设置为 1 时，唯一索引约束不被检查以加速导入速度。 这个变量不对外用，只是给 lightning 使用，请用户不要自行修改。
tidb_opt_agg_push_down 作用域：SESSION
默认值：0
这个变量用来设置优化器是否执行聚合函数下推到 Join 之前的优化操作。 当查询中聚合操作执行很慢时，可以尝试设置该变量为 1。
tidb_auto_analyze_ratio 作用域：GLOBAL
默认值：0.5
这个变量用来设置自动 ANALYZE 更新的阈值。当某个表 tbl 的修改行数与总行数的比值大于 tidb_auto_analyze_ratio，并且当前时间在 tidb_auto_analyze_start_time 和 tidb_auto_analyze_end_time 之间时，TiDB 会在后台执行 ANALYZE TABLE tbl 语句以自动更新该表的统计信息。注意：只有在 TiDB 的启动配置文件中开启了 run-auto-analyze 选项，该 TiDB 才会触发 auto_analyze。</description>
    </item>
    
    <item>
      <title>TiDB 中的基本 SQL 操作</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/explore-sql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/explore-sql/</guid>
      <description>TiDB 中的基本 SQL 操作 成功部署 TiDB 集群之后，便可以在 TiDB 中执行 SQL 语句了。因为 TiDB 兼容 MySQL，你可以使用 MySQL 客户端连接 TiDB，并且大多数情况下可以直接执行 MySQL 语句。
本文介绍 CRUD 操作等基本的 SQL 语句。完整的 SQL 语句列表，参见 TiDB SQL 语法详解。
创建、查看和删除数据库 使用 CREATE DATABASE 语句创建数据库。语法如下：
 CREATE DATABASE db_name [options]; 例如，要创建一个名为 samp_db 的数据库，可使用以下语句：
 CREATE DATABASE IF NOT EXISTS samp_db; 使用 SHOW DATABASES 语句查看数据库：
 SHOW DATABASES; 使用 DROP DATABASE 语句删除数据库，例如：
 DROP DATABASE samp_db; 创建、查看和删除表 使用 CREATE TABLE 语句创建表。语法如下：
 CREATE TABLE table_name column_name data_type constraint; 例如：</description>
    </item>
    
    <item>
      <title>TiDB 主从集群的数据校验</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/tidb-diff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/tidb-diff/</guid>
      <description>TiDB 主从集群的数据校验 用户可以使用 TiDB Binlog 搭建 TiDB 的主从集群，Drainer 在把数据同步到 TiDB 时，保存 checkpoint 的同时也会将上下游的 TSO 对应关系保存为 ts-map。在 sync-diff-inspector 中配置 snapshot 即可对 TiDB 主从集群的数据进行校验。
获取 ts-map 在下游 TiDB 中执行以下 SQL 语句：
 select * from tidb_binlog.checkpoint; +---------------------+---------------------------------------------------------------------------------------------------------+ | clusterID | checkPoint | +---------------------+---------------------------------------------------------------------------------------------------------+ | 6711243465327639221 | {&amp;#34;commitTS&amp;#34;:409622383615541249,&amp;#34;ts-map&amp;#34;:{&amp;#34;master-ts&amp;#34;:409621863377928194,&amp;#34;slave-ts&amp;#34;:409621863377928345}} | +---------------------+---------------------------------------------------------------------------------------------------------+ 从结果中可以获取 ts-map 信息。
配置 snapshot 使用上一步骤获取的 ts-map 信息来配置上下游数据库的 snapshot 信息。其中的 Databases config 部分示例配置如下：
######################### Databases config ######################### # 源数据库实例的配置 [[source-db]] host = &amp;#34;127.0.0.1&amp;#34; port = 4000 user = &amp;#34;root&amp;#34; password = &amp;#34;123456&amp;#34; # 源数据库实例的 id，唯一标识一个数据库实例 instance-id = &amp;#34;source-1&amp;#34; # 使用 TiDB 的 snapshot 功能，对应 ts-map 中的 master-ts snapshot = &amp;#34;409621863377928194&amp;#34; # 目标数据库实例的配置 [target-db] host = &amp;#34;127.</description>
    </item>
    
    <item>
      <title>TiDB 乐观事务模型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-optimistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-optimistic/</guid>
      <description>了解 TiDB 的乐观事务模型。</description>
    </item>
    
    <item>
      <title>TiDB 事务概览</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/transactions/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/transactions/overview/</guid>
      <description>了解 TiDB 中的事务。</description>
    </item>
    
    <item>
      <title>TiDB 事务隔离级别</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-isolation/</guid>
      <description>了解 TiDB 事务的隔离级别。</description>
    </item>
    
    <item>
      <title>TiDB 内存控制文档</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/configure/memory-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/configure/memory-control/</guid>
      <description>TiDB 内存控制文档 目前 TiDB 已经能够做到追踪单条 SQL 查询过程中的内存使用情况，当内存使用超过一定阈值后也能采取一些操作来预防 OOM 或者排查 OOM 原因。在 TiDB 的配置文件中，我们可以使用如下配置来控制内存使用超阈值时 TiDB 的行为：
 # Valid options: [&amp;#34;log&amp;#34;, &amp;#34;cancel&amp;#34;] oom-action = &amp;#34;log&amp;#34;  如果上面的配置项使用的是 &amp;ldquo;log&amp;rdquo;，那么当一条 SQL 的内存使用超过一定阈值（由 session 变量 tidb_mem_quota_query 来控制）后，TiDB 会在 log 文件中打印一条 LOG，然后这条 SQL 继续执行，之后如果发生了 OOM 可以在 LOG 中找到对应的 SQL。 如果上面的配置项使用的是 &amp;ldquo;cancel&amp;rdquo;，那么当一条 SQL 的内存使用超过一定阈值后，TiDB 会立即中断这条 SQL 的执行并给客户端返回一个 error，error 信息中会详细写明这条 SQL 执行过程中各个占用内存比较多的物理执行算子的内存使用情况。  如何配置一条 SQL 执行过程中的内存使用阈值 可以在配置文件中设置每个 Query 默认的 Memory Quota，例如将其设置为 32GB：
 mem-quota-query = 34359738368 此外还可通过如下几个 session 变量来控制一条 Query 中的内存使用，大多数用户只需要设置 tidb_mem_quota_query 即可，其他变量是高级配置，大多数用户不需要关心：</description>
    </item>
    
    <item>
      <title>TiDB 命令行参数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/configuration/</guid>
      <description>TiDB 命令行参数 在启动 TiDB 时，你可以使用命令行参数或环境变量来配置 TiDB。本文将详细介绍 TiDB 的命令行启动参数。TiDB 的默认端口为 4000（客户端请求）与 10080（状态报告）。
--advertise-address  登录 TiDB 的 IP 地址 默认：&amp;rdquo;&amp;rdquo; 必须确保用户和集群中的其他机器都能够访问到该 IP 地址  --binlog-socket  TiDB 服务使用 unix socket file 方式接受内部连接，如 Pump 服务 默认：&amp;rdquo;&amp;rdquo; 例如，可以使用 &amp;ldquo;/tmp/pump.sock&amp;rdquo; 来接受 Pump unix socket file 通信  --config  配置文件 默认：&amp;rdquo;&amp;rdquo; 如果你指定了配置文件，TiDB 会首先读取配置文件的配置。如果对应的配置在命令行参数里面也存在，TiDB 就会使用命令行参数的配置来覆盖配置文件中的配置。详细的配置项请参阅 TiDB 配置文件描述。  --cors  用于设置 TiDB HTTP 状态服务的 Access-Control-Allow-Origin 默认：&amp;rdquo;&amp;rdquo;  --host  TiDB 服务监听的 host 默认：&amp;ldquo;0.0.0.0&amp;rdquo; 0.0.0.0 默认会监听所有的网卡地址。如果有多块网卡，可以指定对外提供服务的网卡，如 192.</description>
    </item>
    
    <item>
      <title>TiDB 工具下载</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/download/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/download/</guid>
      <description>TiDB 工具下载 本页面汇总了 TiDB 周边工具官方维护版本的下载链接。
TiDB Binlog 如需下载最新版本的 TiDB Binlog，直接下载 TiDB 安装包即可，因为 TiDB Binlog 包含在 TiDB 安装包中。
以下表格中也提供了 Kafka 版本的 TiDB Binlog 下载链接。
   安装包 操作系统 架构 SHA256 校验和     https://download.pingcap.org/tidb-{version}-linux-amd64.tar.gz (TiDB Binlog) Linux amd64 https://download.pingcap.org/tidb-{version}-linux-amd64.sha256   https://download.pingcap.org/tidb-binlog-kafka-linux-amd64.tar.gz（Kafka 版本的 TiDB Binlog） Linux amd64 https://download.pingcap.org/tidb-binlog-kafka-linux-amd64.sha256     注意：
下载链接中的 {version} 为 TiDB 的版本号。例如，v3.0.5 版本的下载链接为 https://download.pingcap.org/tidb-v3.0.5-linux-amd64.tar.gz。
 TiDB Lightning 使用下表中的链接下载 TiDB Lightning：
   安装包 操作系统 架构 SHA256 校验和     https://download.</description>
    </item>
    
    <item>
      <title>TiDB 悲观事务模型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-pessimistic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/transactions/transaction-pessimistic/</guid>
      <description>了解 TiDB 的悲观事务模型。</description>
    </item>
    
    <item>
      <title>TiDB 整体架构</title>
      <link>https://pingcap.com/docs-cn/v3.1/architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/architecture/</guid>
      <description>TiDB 整体架构 要深入了解 TiDB 的水平扩展和高可用特点，首先需要了解 TiDB 的整体架构。TiDB 集群主要包括三个核心组件：TiDB Server，PD Server 和 TiKV Server。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark 组件和简化云上部署管理的 TiDB Operator 组件。
TiDB Server TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。
PD Server Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。
PD 通过 Raft 协议保证数据的安全性。Raft 的 leader server 负责处理所有操作，其余的 PD server 仅用于保证高可用。建议部署奇数个 PD 节点。
TiKV Server TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。</description>
    </item>
    
    <item>
      <title>TiDB 核心特性</title>
      <link>https://pingcap.com/docs-cn/v3.1/key-features/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/key-features/</guid>
      <description>TiDB 核心特性 本文详细介绍 TiDB 的两大核心特性：水平扩展与高可用。
水平扩展 无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。
高可用 高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。
  TiDB
TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。
  PD
PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。
  TiKV</description>
    </item>
    
    <item>
      <title>TiDB 版本发布历史</title>
      <link>https://pingcap.com/docs-cn/v3.1/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/releases/rn/</guid>
      <description>TiDB 版本发布历史 TiDB 历史版本发布声明如下：
3.1  3.1.0-beta.2 3.1.0-beta.1 3.1.0-beta  3.0  3.0.12 3.0.11 3.0.10 3.0.9 3.0.8 3.0.7 3.0.6 3.0.5 3.0.4 3.0.3 3.0.2 3.0.1 3.0 GA 3.0.0-rc.3 3.0.0-rc.2 3.0.0-rc.1 3.0.0-beta.1 3.0.0-beta  2.1  2.1.19 2.1.18 2.1.17 2.1.16 2.1.15 2.1.14 2.1.13 2.1.12 2.1.11 2.1.10 2.1.9 2.1.8 2.1.7 2.1.6 2.1.5 2.1.4 2.1.3 2.1.2 2.1.1 2.1 GA 2.1 RC5 2.1 RC4 2.1 RC3 2.1 RC2 2.1 RC1 2.1 Beta  2.0  2.</description>
    </item>
    
    <item>
      <title>TiDB 生态工具使用指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/user-guide/</guid>
      <description>TiDB 生态工具使用指南 目前 TiDB 生态工具较多，有些工具之间有功能重叠，也有些属于版本迭代关系。本文档将对各个工具进行介绍，说明各个工具之间的关系，并且说明各个版本、场景下应该使用哪些工具。
TiDB 生态工具概览 TiDB 生态工具可以分为几种：
 数据导入类，包括全量导入工具、备份和恢复工具、增量导入工具等 数据导出类，包括全量导出工具、增量导出工具等  下面将分别介绍这两类工具。
数据导入类 全量导入工具 Loader（停止维护，不推荐使用） Loader 是一款轻量级的全量数据导入工具，数据以 SQL 的形式导入到 TiDB 中。目前这个工具正在逐步被 TiDB Lightning 替换掉，参见 TiDB Lightning TiDB-backend 文档。
以下是 Loader 的一些基本信息：
 Loader 的输入：Mydumper 输出的文件 Loader 的输出：以 SQL 形式写入 TiDB 适用 TiDB 版本：所有版本 Kubernetes 支持：备份与恢复  全量导入工具 TiDB Lightning TiDB Lightning 是将全量数据快速导入到一个新的 TiDB 集群的工具。
注意用 TiDB Lightning 导入数据到 TiDB 的时候，有两种模式：
 默认模式：tikv-importer 为后端，这种模式下导入数据过程中集群无法提供正常的服务，用于导入大量的数据（TB 级别）。 第二种模式：TiDB 为后端（相当于 Loader 的功能），相对默认模式导入速度较慢，但是可以在线导入。  以下是 TiDB Lightning 的一些基本信息：</description>
    </item>
    
    <item>
      <title>TiDB 用户账户管理</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/security/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/security/user-account-management/</guid>
      <description>TiDB 用户账户管理 本文档主要介绍如何管理 TiDB 用户账户。
用户名和密码 TiDB 将用户账户存储在 mysql.user 系统表里面。每个账户由用户名和 host 作为标识。每个账户可以设置一个密码。
通过 MySQL 客户端连接到 TiDB 服务器，通过指定的账户和密码登录：
 mysql --port 4000 --user xxx --password 使用缩写的命令行参数则是：
 mysql -P 4000 -u xxx -p 添加用户 添加用户有两种方式：
 通过标准的用户管理的 SQL 语句创建用户以及授予权限，比如 CREATE USER 和 GRANT。 直接通过 INSERT、UPDATE 和 DELETE 操作授权表。  推荐使用第一种方式。第二种方式修改容易导致一些不完整的修改，因此不推荐。还有另一种可选方式是使用第三方工具的图形化界面工具。
 CREATE USER [IF NOT EXISTS] user [auth_spec] [, user [auth_spec]] ...  auth_spec: { IDENTIFIED BY &amp;#39;auth_string&amp;#39; | IDENTIFIED BY PASSWORD &amp;#39;hash_string&amp;#39; }  IDENTIFIED BY &#39;auth_string&#39;：设置登录密码时，auth_string 会被 TiDB 经过加密存储在 mysql.</description>
    </item>
    
    <item>
      <title>TiDB 监控框架概述</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/monitor/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/monitor/overview/</guid>
      <description>TiDB 监控框架概述 TiDB 使用开源时序数据库 Prometheus 作为监控和性能指标信息存储方案，使用 Grafana 作为可视化组件进行展示。
Prometheus 在 TiDB 中的应用 Prometheus 是一个拥有多维度数据模型的、灵活的查询语句的时序数据库。Prometheus 作为热门的开源项目，拥有活跃的社区及众多的成功案例。
Prometheus 提供了多个组件供用户使用。目前，TiDB 使用了以下组件：
 Prometheus Server：用于收集和存储时间序列数据。 Client 代码库：用于定制程序中需要的 Metric。 Alertmanager：用于实现报警机制。  其结构如下图所示：
Grafana 在 TiDB 中的应用 Grafana 是一个开源的 metric 分析及可视化系统。TiDB 使用 Grafana 来展示 TiDB 的各项性能指标。如下图所示：</description>
    </item>
    
    <item>
      <title>TiDB 简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/overview/</guid>
      <description>TiDB 简介 TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。
TiDB 具备如下特性：
  高度兼容 MySQL
大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。
  水平弹性扩展
通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。
  分布式事务
TiDB 100% 支持标准的 ACID 事务。
  真正金融级高可用
相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。
  一站式 HTAP 解决方案</description>
    </item>
    
    <item>
      <title>TiDB 系统表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/system-databases/mysql/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/system-databases/mysql/</guid>
      <description>TiDB 系统表 本文档主要介绍 TiDB 支持的系统表。
权限系统表 这些系统表里面包含了用户账户以及相应的授权信息：
 user 用户账户，全局权限，以及其它一些非权限的列 db 数据库级别的权限 tables_priv 表级的权限 columns_priv 列级的权限  服务端帮助信息系统表  help_topic 目前为空  统计信息相关系统表  stats_buckets 统计信息的桶 stats_histograms 统计信息的直方图 stats_meta 表的元信息，比如总行数和修改数  GC Worker 相关系统表  gc_delete_range  其它系统表  GLOBAL_VARIABLES 全局系统变量表 tidb 用于 TiDB 在 bootstrap 的时候记录相关版本信息  </description>
    </item>
    
    <item>
      <title>TiDB 证书鉴权使用指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/security/cert-based-authentication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/security/cert-based-authentication/</guid>
      <description>了解使用 TiDB 的证书鉴权功能。</description>
    </item>
    
    <item>
      <title>TiDB 路线图</title>
      <link>https://pingcap.com/docs-cn/v3.1/roadmap/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/roadmap/</guid>
      <description>TiDB 路线图 TiDB  优化器  统计信息优化 Multi-Column Statistics Cascades Planner Plan Management SQL Tuning Advisor Robust Access Path Selection：增加启发式规则，提升 OLTP 场景中索引选择正确率 Adaptive Query Optimization   执行引擎  算子并行化 内存控制 并发控制 Shuffle 算子 Vectorized 表达式计算 UDF   SQL 功能  支持 View 支持窗口函数 支持 Common Table Expression 支持 Hash 分区表 支持 utf8_general_ci collation   DDL 改进  支持 Table Lock 支持 Change column type 支持单条语句中多个 DDL 操作 支持不可见索引（invisible index）   支持插件系统  支持白名单插件 支持审计日志插件 支持 RBAC 插件 支持诊断插件   支持 Query Tracing 支持行列混合存储引擎 支持 New Storage Row Format，提升性能并减小内存占用 RowID 实现非整数类型 事务  减少读写冲突 优化事务调度机制 改善模型，降低延迟 支持最小事务 (like the mini-transaction of InnoDB)    TiKV  Raft  Region Merge - 合并小的 Region 以减少开销 Local Read Thread - 把读请求放在一个单独的线程处理 批量 Region Split - 加速大的 Region 的分裂 Raft Learner - 支持 Raft learner 使得成员变更过程更加平滑 Raft Pre-voter - 支持 Raft Pre-vote 避免网络隔离带来不必要的选举 Joint Consensus - 安全地进行多个成员变更 多线程 Raftstore - 在多个线程处理不同 Region 的 Raft 逻辑 多线程 Apply Pool - 在多个线程执行不同 Region 已经提交了的命令   Engine  Titan - 把大的 key-values 从 LSM-Tree 中分离出来 可拔插的 Engine 接口 - 简化接口逻辑并且提供可扩展性   Storage  在 scheduler 里做流控提前避免 write stall   Transaction  优化事务冲突 分布式 GC - 把 MVCC 垃圾回收的逻辑分布到 TiKV 控制   Coprocessor  Streaming - 把大的数据集切成小块返回以减少内存消耗 Chunk Execution - 按 chunk 的方式来处理数据以提高性能 请求跟踪 - 提供单个请求执行的详细信息   Tools  TiKV Importer - 通过直接导入 SST 文件的方式加速数据导入   Client  提供 Rust 版本的 TiKV client gRPC 消息批量化 - 减少消息交互的开销    PD  Namespace 完善  不同 Namespace 或者 Table 配置不同的副本策略   Table Region 分散调度 调度支持优先级，更加可控 使用机器学习优化调度 优化 Region 元信息存储 - 把元信息存储在一个独立的存储引擎里  TiSpark  Limit/Order 下推 DAG 接口接入（废除 Select 接口） Index Join 和并行 merge join Data Federation（桥接其他数据源，最好能和社区同步，这个接进来可以比较好扩展 Usecase，如果再做一个 InputFormat 适配就可以接 Hive 和 Presto 这些 Hadoop 上的数仓）  Tools  集群部署工具 高性能数据导入工具（lightning） 集群备份和恢复工具（包括全量+增量备份，Mydumper + drainer/reparo） 改进 TiDB Binlog 架构 数据在线迁移工具（Syncer 升级版） 集群诊断和分析工具  </description>
    </item>
    
    <item>
      <title>TiDB 软件和硬件环境建议配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/hardware-recommendations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/hardware-recommendations/</guid>
      <description>TiDB 软件和硬件环境建议配置 TiDB 作为一款开源分布式 NewSQL 数据库，可以很好的部署和运行在 Intel 架构服务器环境及主流虚拟化环境，并支持绝大多数的主流硬件网络。作为一款高性能数据库系统，TiDB 支持主流的 Linux 操作系统环境。
Linux 操作系统版本要求    Linux 操作系统平台 版本     Red Hat Enterprise Linux 7.3 及以上   CentOS 7.3 及以上   Oracle Enterprise Linux 7.3 及以上   Ubuntu LTS 16.04 及以上     注意：
 TiDB 只支持 Red Hat 兼容内核 (RHCK) 的 Oracle Enterprise Linux，不支持 Oracle Enterprise Linux 提供的 Unbreakable Enterprise Kernel。 TiDB 在 CentOS 7.</description>
    </item>
    
    <item>
      <title>TiDB 配置文件描述</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/configuration-file/</guid>
      <description>TiDB 配置文件描述 TiDB 配置文件比命令行参数支持更多的选项。你可以在 config/config.toml.example 找到默认值的配置文件，重命名为 config.toml 即可。本文档只介绍未包含在命令行参数中的参数。
split-table  为每个 table 建立单独的 Region。 默认值：true 如果需要创建大量的表，我们建议把这个参数设置为 false。  oom-action  指定 TiDB 发生 out-of-memory 错误时的操作。 默认值：&amp;ldquo;log&amp;rdquo; 现在合法的选项是 [&amp;ldquo;log&amp;rdquo;, &amp;ldquo;cancel&amp;rdquo;]，如果为 &amp;ldquo;log&amp;rdquo;，仅仅是打印日志，不作实质处理。如果为 &amp;ldquo;cancel&amp;rdquo;，我们会取消执行这个操作，并且输出日志。  mem-quota-query  单条 SQL 语句可以占用的最大内存阈值。 默认值：34359738368 超过该值的请求会被 oom-action 定义的行为所处理。  enable-streaming  开启 coprocessor 的 streaming 获取数据模式。 默认值：false  lower-case-table-names  这个选项可以设置 TiDB 的系统变量 lower_case_table_names 的值。 默认值：2 具体可以查看 MySQL 关于这个变量的描述   注意：
目前 TiDB 只支持将该选项的值设为 2，即按照大小写来保存表名，按照小写来比较（不区分大小写）。
 lease  DDL 租约超时时间。 默认值：45s 单位：秒  compatible-kill-query  设置 KILL 语句的兼容性。 默认值：false TiDB 中 KILL xxx 的行为和 MySQL 中的行为不相同。为杀死一条查询，在 TiDB 里需要加上 TIDB 关键词，即 KILL TIDB xxx。但如果把 compatible-kill-query 设置为 true，则不需要加上 TIDB 关键词。 这种区别很重要，因为当用户按下 Ctrl+C 时，MySQL 命令行客户端的默认行为是：创建与后台的新连接，并在该新连接中执行 KILL 语句。如果负载均衡器或代理已将该新连接发送到与原始会话不同的 TiDB 服务器实例，则该错误会话可能被终止，从而导致使用 TiDB 集群的业务中断。只有当您确定在 KILL 语句中引用的连接正好位于 KILL 语句发送到的服务器上时，才可以启用 compatible-kill-query。  check-mb4-value-in-utf8  开启检查 utf8mb4 字符的开关，如果开启此功能，字符集是 utf8，且在 utf8 插入 mb4 字符，系统将会报错。 默认值：true  treat-old-version-utf8-as-utf8mb4  将旧表中的 utf8 字符集当成 utf8mb4的开关。 默认值：true  alter-primary-key  用于控制添加或者删除主键功能。 默认值：false 默认情况下，不支持增删主键。将此变量被设置为 true 后，支持增删主键功能。不过对在此开关开启前已经存在的表，且主键是整型类型时，即使之后开启此开关也不支持对此列表删除主键。  log 日志相关的配置项。</description>
    </item>
    
    <item>
      <title>TiDB 重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/tidb-dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/tidb-dashboard/</guid>
      <description>TiDB 重要监控指标详解 使用 Ansible 部署 TiDB 集群时，一键部署监控系统 (Prometheus/Grafana)，监控架构请看 TiDB 监控框架概述。
目前 Grafana Dashboard 整体分为 PD、TiDB、TiKV、Node_exporter、Overview 等，TiDB 分为 TiDB 和 TiDB Summary 面板（其中 TiDB 面板包含 TiDB Summary 面板的内容）。
以下为 TiDB Dashboard 部分监控说明：
说明   Query Summary
 Duration：SQL 执行的时间 QPS：每个 TiDB 上的 SQL 执行结果按照 OK/Error 统计 Statement OPS：SQL 执行数量统计（包含 SELECT、INSERT、UPDATE 等） QPS By Instance：每个 TiDB 上的 QPS Failed Query OPM：每个 TiDB 实例上，执行 SQL 语句发生错误按照错误类型的统计（例如语法错误、主键冲突等） Slow query：慢查询处理时间统计（整个慢查询耗时、Coprocessor 耗时、Coprocessor 调度等待时间） 999/99/95/80 Duration：不同类型的 SQL 语句执行耗时统计（不同百分位）    Query Detail</description>
    </item>
    
    <item>
      <title>TiDB 集群扩容缩容方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/scale/horizontally/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/scale/horizontally/</guid>
      <description>TiDB 集群扩容缩容方案 TiDB 集群可以在不影响线上服务的情况下动态进行扩容和缩容。
 注意：
如果使用 Ansible 部署 TiDB 集群，请参考使用 Ansible 扩容缩容。
 下面分别介绍如何增加或者删除 PD，TiKV 以及 TiDB 的节点。
下面用到的 pd-ctl 文档可以参考 pd-control。
PD 假设现在我们有三个 PD 服务，详细信息如下：
   Name ClientUrls PeerUrls     pd1 http://host1:2379|http://host1:2380|    pd2 http://host2:2379|http://host2:2380|    pd3 http://host3:2379|http://host3:2380|     我们可以通过 pd-ctl 来查看当前所有 PD 节点的信息：
 ./pd-ctl -u http://host1:2379 -i &amp;gt;&amp;gt; member 动态添加节点 我们可以使用 join 参数，将一个新的 PD 服务加入到现有的 PD 集群里面。 如果我们需要添加 pd4，只需要在 --join 参数里面填入当前 PD 集群任意一个 PD 服务的 client url，比如：</description>
    </item>
    
    <item>
      <title>TiDB 集群报警规则</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/alert-rules/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/alert-rules/</guid>
      <description>TiDB 集群中各组件的报警规则详解。</description>
    </item>
    
    <item>
      <title>TiDB 集群故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/troubleshoot/cluster-setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/troubleshoot/cluster-setup/</guid>
      <description>TiDB 集群故障诊断 当试用 TiDB 遇到问题时，请先参考本篇文档。如果问题未解决，请按文档要求收集必要的信息通过 Github 提供给 TiDB 开发者。
如何给 TiDB 开发者报告错误 当使用 TiDB 遇到问题并且通过后面所列信息无法解决时，请收集以下信息并创建新 Issue:
 具体的出错信息以及正在执行的操作 当前所有组件的状态 出问题组件 log 中的 error/fatal/panic 信息 机器配置以及部署拓扑 dmesg 中 TiDB 组件相关的问题  数据库连接不上 首先请确认集群的各项服务是否已经启动，包括 tidb-server、pd-server、tikv-server。请用 ps 命令查看所有进程是否在。如果某个组件的进程已经不在了，请参考对应的章节排查错误。
如果所有的进程都在，请查看 tidb-server 的日志，看是否有报错？常见的错误包括：
  InformationSchema is out of date
无法连接 tikv-server，请检查 pd-server 以及 tikv-server 的状态和日志。
  panic
程序有错误，请将具体的 panic log 提供给 TiDB 开发者。
如果是清空数据并重新部署服务，请确认以下信息：
  pd-server、tikv-server 数据都已清空
tikv-server 存储具体的数据，pd-server 存储 tikv-server 中数据的的元信息。如果只清空 pd-server 或只清空 tikv-server 的数据，会导致两边数据不匹配。</description>
    </item>
    
    <item>
      <title>TiDB 集群监控</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/monitor/monitor-a-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/monitor/monitor-a-cluster/</guid>
      <description>TiDB 集群监控 TiDB 提供了以下两种接口来监控集群状态：
 状态接口：通过 HTTP 接口对外汇报组件的信息。 Metrics 接口：使用 Prometheus 记录组件中各种操作的详细信息，使用 Grafana 进行可视化展示。  使用状态接口 状态接口用于监控组件的一些基本信息，并且可以作为 keepalive 的监测接口。另外，通过 PD 的状态接口可以看到整个 TiKV 集群的详细信息。
TiDB Server  TiDB API 地址：http://${host}:${port} 默认端口：10080 各类 api_name 详细信息：参见 TiDB API 文档  以下示例中，通过访问 http://${host}:${port}/status 获取当前 TiDB Server 的状态，并判断该 TiDB Server 是否存活。结果以 JSON 格式返回：
 curl http://127.0.0.1:10080/status { connections: 0, # 当前 TiDB Server 上的客户端连接数 version: &amp;#34;5.7.25-TiDB-v3.0.0-beta-250-g778c3f4a5&amp;#34;, # TiDB 版本号 git_hash: &amp;#34;778c3f4a5a716880bcd1d71b257c8165685f0d70&amp;#34; # TiDB 当前代码的 Git Hash } PD Server  PD API 地址：http://${host}:${port}/pd/api/v1/${api_name} 默认端口：2379 各类 api_name 详细信息：参见 PD API Doc  通过该接口可以获取当前所有 TiKV 节点的状态以及负载均衡信息。下面以一个单节点的 TiKV 集群为例，说明用户需要了解的信息：</description>
    </item>
    
    <item>
      <title>TiDB 高并发写入场景最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/high-concurrency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/high-concurrency/</guid>
      <description>了解 TiDB 在高并发写入场景下的最佳实践。</description>
    </item>
    
    <item>
      <title>TiKV Control 使用说明</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/tikv-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/tikv-control/</guid>
      <description>TiKV Control 使用说明 TiKV Control（以下简称 tikv-ctl）是 TiKV 的命令行工具，用于管理 TiKV 集群。
编译 TiKV 的同时也会编译 tikv-ctl 命令。如果通过 Ansible 部署集群，则对应的 tidb-ansible/resources/bin 目录下会存在 tikv-ctl 二进制文件。如果使用二进制文件部署集群，bin 目录下会包含 tikv-ctl 文件及 tidb-server、pd-server、以及 tikv-server 等其他文件。
通用参数 tikv-ctl 提供以下两种运行模式：
  远程模式。通过 --host 选项接受 TiKV 的服务地址作为参数。在此模式下，如果 TiKV 启用了 SSL，则 tikv-ctl 也需要指定相关的证书文件，例如：
 tikv-ctl --ca-path ca.pem --cert-path client.pem --key-path client-key.pem --host 127.0.0.1:20160 &amp;lt;subcommands&amp;gt; 某些情况下，tikv-ctl 与 PD 进行通信，而不与 TiKV 通信。此时你需要使用 --pd 选项而非 --host 选项，例如：
 tikv-ctl --pd 127.0.0.1:2379 compact-cluster store:&amp;#34;127.0.0.1:20160&amp;#34; compact db:KV cf:default range:([], []) success!</description>
    </item>
    
    <item>
      <title>TiKV 性能参数调优</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/tune-tikv/</guid>
      <description>TiKV 性能参数调优 本文档用于描述如何根据机器配置情况来调整 TiKV 的参数，使 TiKV 的性能达到最优。
TiKV 最底层使用的是 RocksDB 做为持久化存储，所以 TiKV 的很多性能相关的参数都是与 RocksDB 相关的。TiKV 使用了两个 RocksDB 实例，默认 RocksDB 实例存储 KV 数据，Raft RocksDB 实例（简称 RaftDB）存储 Raft 数据。
TiKV 使用了 RocksDB 的 Column Families (CF) 特性。
  默认 RocksDB 实例将 KV 数据存储在内部的 default、write 和 lock 3 个 CF 内。
 default CF 存储的是真正的数据，与其对应的参数位于 [rocksdb.defaultcf] 项中； write CF 存储的是数据的版本信息 (MVCC) 以及索引相关的数据，相关的参数位于 [rocksdb.writecf] 项中； lock CF 存储的是锁信息，系统使用默认参数。    Raft RocksDB 实例存储 Raft log。</description>
    </item>
    
    <item>
      <title>TiKV 配置参数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tikv-server/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tikv-server/configuration/</guid>
      <description>TiKV 配置参数 TiKV 的命令行参数支持一些可读性好的单位转换。
 文件大小（以 bytes 为单位）：KB, MB, GB, TB, PB（也可以全小写） 时间（以毫秒为单位）：ms, s, m, h  -A, --addr  TiKV 监听地址 默认：&amp;ldquo;127.0.0.1:20160&amp;rdquo; 如果部署一个集群，--addr 必须指定当前主机的 IP 地址，例如 &amp;ldquo;192.168.100.113:20160&amp;rdquo;，如果是运行在 docker 则需要指定为 &amp;ldquo;0.0.0.0:20160&amp;rdquo;  --advertise-addr  TiKV 对外访问地址。 默认：${addr} 在某些情况下，譬如 docker，或者 NAT 网络环境，客户端并不能通过 TiKV 自己监听的地址来访问到 TiKV，这时候，你就可以设置 advertise addr 来让 客户端访问 例如，docker 内部 IP 地址为 172.17.0.1，而宿主机的 IP 地址为 192.168.100.113 并且设置了端口映射 -p 20160:20160，那么可以设置为 --advertise-addr=&amp;quot;192.168.100.113:20160&amp;rdquo;，客户端可以通过 192.168.100.113:20160 来找到这个服务  -C, --config  配置文件 默认：&amp;rdquo;&amp;rdquo; 如果你指定了配置文件，TiKV 会首先读取配置文件的配置。然后如果对应的配置在命令行参数里面也存在，TiKV 就会使用命令行参数的配置来覆盖配置文件里面的  --capacity  TiKV 存储数据的容量 默认：0 (无限) PD 需要使用这个值来对整个集群做 balance 操作。（提示：你可以使用 10GB 来替代 10737418240，从而简化参数的传递）  --data-dir  TiKV 数据存储路径 默认：&amp;quot;/tmp/tikv/store&amp;rdquo;  -L, --log  Log 级别 默认：&amp;ldquo;info&amp;rdquo; 我们能选择 trace, debug, info, warn, error, 或者 off  --log-file  Log 文件 默认：&amp;rdquo;&amp;rdquo; 如果没设置这个参数，log 会默认输出到 &amp;ldquo;stderr&amp;rdquo;，如果设置了，log 就会输出到对应的文件里面，在每天凌晨，log 会自动轮转使用一个新的文件，并且将以前的文件改名备份  --pd  PD 地址列表。 默认：&amp;rdquo;&amp;rdquo; TiKV 必须使用这个值连接 PD，才能正常工作。使用逗号来分隔多个 PD 地址，例如： 192.</description>
    </item>
    
    <item>
      <title>TiKV 配置文件描述</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tikv-server/configuration-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tikv-server/configuration-file/</guid>
      <description>TiKV 配置文件描述 TiKV 配置文件比命令行参数支持更多的选项。你可以在 etc/config-template.toml 找到默认值的配置文件，重命名为 config.toml 即可。
本文档只阐述未包含在命令行参数中的参数，命令行参数参见 TiKV 配置参数。
status-thread-pool-size  Http API 服务的工作线程数量。 默认值：1 最小值：1  grpc-compression-type  gRPC 消息的压缩算法，取值：none， deflate， gzip。 默认值：none  grpc-concurrency  gRPC 工作线程的数量。 默认值：4 最小值：1  grpc-concurrent-stream  一个 gRPC 链接中最多允许的并发请求数量。 默认值：1024 最小值：1  server.grpc-raft-conn-num  tikv 节点之间用于 raft 通讯的链接最大数量。 默认值：10 最小值：1  server.grpc-stream-initial-window-size  gRPC stream 的 window 大小。 默认值：2MB 单位：KB|MB|GB 最小值：1KB  server.grpc-keepalive-time  gRPC 发送 keep alive ping 消息的间隔时长。 默认值：10s 最小值：1s  server.</description>
    </item>
    
    <item>
      <title>TiKV 重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/tikv-dashboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/key-monitoring-metrics/tikv-dashboard/</guid>
      <description>TiKV 重要监控指标详解 使用 Ansible 部署 TiDB 集群时，一键部署监控系统 (Prometheus/Grafana)，监控架构请看 TiDB 监控框架概述。
目前 Grafana Dashboard 整体分为 PD、TiDB、TiKV、Node_exporter、Overview 等。
对于日常运维，我们通过观察 TiKV 面板上的 Metrics，可以了解 TiKV 当前的状态。
以下为 TiKV Dashboard 监控说明：
Cluster  Store size：每个 TiKV 实例的使用的存储空间的大小 Available size：每个 TiKV 实例的可用的存储空间的大小 Capacity size：每个 TiKV 实例的存储容量的大小 CPU：每个 TiKV 实例 CPU 的使用率 Memory：每个 TiKV 实例内存的使用情况 IO utilization：每个 TiKV 实例 IO 的使用率 MBps：每个 TiKV 实例写入和读取的数据量大小 QPS：每个 TiKV 实例上各种命令的 QPS Errps：每个 TiKV 实例上 gRPC 消息失败的个数 leader：每个 TiKV 实例 leader 的个数 Region：每个 TiKV 实例 Region 的个数  Errors  Server is busy：各种会导致 server 繁忙的事件个数，如 write stall，channel full 等，正常情况下应当为 0 Server report failures：server 报错的消息个数，正常情况下应当为 0 Raftstore error：每个 TiKV 实例上 raftstore 发生错误的个数 Scheduler error：每个 TiKV 实例上 scheduler 发生错误的个数 Coprocessor error：每个 TiKV 实例上 coprocessor 发生错误的个数 gRPC message error：每个 TiKV 实例上 gRPC 消息发生错误的个数 Leader drop：每个 TiKV 实例上 drop leader 的个数 Leader missing：每个 TiKV 实例上 missing leader 的个数  Server  Leader：每个 TiKV 实例 leader 的个数 Region：每个 TiKV 实例 Region 的个数 CF size：每个 CF 的大小 Store size：每个 TiKV 实例的使用的存储空间的大小 Channel full：每个 TiKV 实例上 channel full 错误的数量，正常情况下应当为 0 Server report failures：server 报错的消息个数，正常情况下应当为 0 Region average written keys：每个 TiKV 实例上所有 Region 的平均 key 写入个数 Region average written bytes：每个 TiKV 实例上所有 Region 的平均写入大小 Active written leaders：每个 TiKV 实例上有效的 leader 个数 Approximate Region size：每个 Region 近似的大小  Raft IO  Apply log duration：Raft apply 日志所花费的时间 Apply log duration per server：每个 TiKV 实例上 Raft apply 日志所花费的时间 Append log duration：Raft append 日志所花费的时间 Append log duration per server：每个 TiKV 实例上 Raft append 日志所花费的时间  Raft process  Ready handled：Raft 中不同 ready 类型的个数 Process ready duration per server：每个 TiKV 实例处理 ready 所花费的时间，99.</description>
    </item>
    
    <item>
      <title>TiSpark 快速入门指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tispark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/tispark/</guid>
      <description>TiSpark 快速入门指南 为了让大家快速体验 TiSpark，通过 TiDB Ansible 安装的 TiDB 集群中默认已集成 Spark、TiSpark jar 包及 TiSpark sample data。
部署信息   Spark 默认部署在 TiDB 实例部署目录下 spark 目录中
  TiSpark jar 包默认部署在 Spark 部署目录 jars 文件夹下：spark/jars/tispark-${name_with_version}.jar
  TiSpark 示例数据和导入脚本可点击 TiSpark 示例数据下载。
 tispark-sample-data/   环境准备 在 TiDB 实例上安装 JDK 在 Oracle JDK 官方下载页面 下载 JDK 1.8 当前最新版，本示例中下载的版本为 jdk-8u141-linux-x64.tar.gz。
解压并根据您的 JDK 部署目录设置环境变量，编辑 ~/.bashrc 文件，比如：
 export JAVA_HOME=/home/pingcap/jdk1.8.0_144 &amp;amp;&amp;amp; export PATH=$JAVA_HOME/bin:$PATH 验证 JDK 有效性：</description>
    </item>
    
    <item>
      <title>TiSpark 用户指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tispark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tispark/</guid>
      <description>TiSpark 用户指南 TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP (Hybrid Transactional/Analytical Processing) 的需求。TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)，也需要你搭建一个 Spark 集群。
本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 的相关信息。
概述 TiSpark 是将 Spark SQL 直接运行在分布式存储引擎 TiKV 上的 OLAP 解决方案。其架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查。 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。 除此之外，用户借助 TiSpark 项目可以在 TiDB 上使用 Spark 生态圈提供的多种工具进行数据处理。例如，使用 TiSpark 进行数据分析和 ETL；使用 TiKV 作为机器学习的数据源；借助调度系统产生定时报表等等。  环境准备 现有 TiSpark 2.</description>
    </item>
    
    <item>
      <title>tkctl 使用指南</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/tools/tkctl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/reference/tools/tkctl/</guid>
      <description>tkctl 使用指南 tkctl (TiDB Kubernetes Control) 是为 TiDB in Kubernetes 设计的命令行工具，用于运维集群和诊断集群问题。
安装 安装 tkctl 时，可以直接下载预编译的可执行文件，也可以自行从源码进行编译。
下载预编译的可执行文件  MacOS Linux Windows  下载解压后，将 tkctl 可执行文件加入到可执行文件路径 (PATH) 中即完成安装。
源码编译 要求：Go 版本 1.11 及以上
 git clone https://github.com/pingcap/tidb-operator.git &amp;amp;&amp;amp; \ GOOS=${YOUR_GOOS} make cli &amp;amp;&amp;amp; \ mv tkctl /usr/local/bin/tkctl 命令自动补全 你可以配置 tkctl 的自动补全以简化使用。
为 BASH 配置自动补全（需要预先安装 bash-completion）的方法如下。
在当前 shell 中设置自动补全：
 source &amp;lt;(tkctl completion bash) 永久设置自动补全：
 echo &amp;#34;if hash tkctl 2&amp;gt;/dev/null; then source &amp;lt;(tkctl completion bash); fi&amp;#34; &amp;gt;&amp;gt; ~/.</description>
    </item>
    
    <item>
      <title>TRACE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/trace/</guid>
      <description>TiDB 数据库中 TRACE 的使用概况。</description>
    </item>
    
    <item>
      <title>TRUNCATE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/truncate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/truncate/</guid>
      <description>TiDB 数据库中 TRUNCATE 的使用概况。</description>
    </item>
    
    <item>
      <title>UPDATE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/update/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/update/</guid>
      <description>TiDB 数据库中 UPDATE 的使用概况。</description>
    </item>
    
    <item>
      <title>USE</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/use/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/statements/use/</guid>
      <description>TiDB 数据库中 USE 的使用概况。</description>
    </item>
    
    <item>
      <title>上游 MySQL 实例配置前置检查</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/precheck/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/precheck/</guid>
      <description>上游 MySQL 实例配置前置检查 本文介绍了 DM 提供的前置检查功能，此功能用于在数据同步任务启动时提前检测出上游 MySQL 实例配置中可能存在的一些错误。
使用命令 check-task 命令用于对上游 MySQL 实例配置是否满足 DM 要求进行前置检查。
检查内容 上下游数据库用户必须具备相应读写权限。当数据同步任务启动时，DM 会自动检查下列权限和配置：
  数据库版本
 5.5 &amp;lt; MySQL 版本 &amp;lt; 8.0 MariaDB 版本 &amp;gt;= 10.1.2    MySQL binlog 配置
 binlog 是否开启（DM 要求 binlog 必须开启） 是否有 binlog_format=ROW（DM 只支持 ROW 格式的 binlog 同步） 是否有 binlog_row_image=FULL（DM 只支持 binlog_row_image=FULL）    上游 MySQL 实例用户的权限
DM 配置中的 MySQL 用户至少需要具备以下权限：
 REPLICATION SLAVE REPLICATION CLIENT RELOAD SELECT    上游 MySQL 表结构的兼容性</description>
    </item>
    
    <item>
      <title>下推到 TiKV 的表达式列表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/expressions-pushed-down/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/expressions-pushed-down/</guid>
      <description>TiDB 中下推到 TiKV 的表达式列表及相关设置。</description>
    </item>
    
    <item>
      <title>不同库名或表名的数据校验</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/route-diff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/route-diff/</guid>
      <description>不同库名或表名的数据校验 用户在使用 DM 等同步工具时，可以设置 route-rules 将数据同步到下游指定表中。sync-diff-inspector 提供了校验不同库名、表名的表的功能。
下面是一个简单的例子：
######################### Tables config ######################### # 配置需要对比的*目标数据库*中的表 [[check-tables]] # 目标库中数据库的名称 schema = &amp;#34;test_2&amp;#34; # 需要检查的表 tables = [&amp;#34;t_2&amp;#34;] # 下面是一个对比不同库名和表名的两个表的配置示例 [[table-config]] # 目标库名 schema = &amp;#34;test_2&amp;#34; # 目标表名 table = &amp;#34;t_2&amp;#34; # 源数据的配置 [[table-config.source-tables]] # 源库的实例 id instance-id = &amp;#34;source-1&amp;#34; # 源数据库的名称 schema = &amp;#34;test_1&amp;#34; # 源表的名称 table = &amp;#34;t_1&amp;#34; 使用该配置会对下游的 test_2.t_2 与实例 source-1 中的 test_1.t_1 进行校验。
如果需要校验大量的不同库名或者表名的表，可以通过 table-rule 设置映射关系来简化配置。可以只配置 schema 或者 table 的映射关系，也可以都配置。例如上游库 test_1 中的所有表都同步到了下游的 test_2 库中，可以使用如下配置进行校验：</description>
    </item>
    
    <item>
      <title>与 MySQL 兼容性对比</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/mysql-compatibility/</guid>
      <description>与 MySQL 兼容性对比 TiDB 支持 MySQL 传输协议及其绝大多数的语法。这意味着您现有的 MySQL 连接器和客户端都可以继续使用。大多数情况下您现有的应用都可以迁移至 TiDB，无需任何代码修改。
当前 TiDB 服务器官方支持的版本为 MySQL 5.7。大部分 MySQL 运维工具（如 PHPMyAdmin, Navicat, MySQL Workbench 等），以及备份恢复工具（如 mysqldump, Mydumper/myloader）等都可以直接使用。
不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持或者是表现与 MySQL 有差异。一些 MySQL 语法在 TiDB 中可以解析通过，但是不会做任何后续的处理，例如 Create Table 语句中 Engine，是解析并忽略。
 注意：
本页内容仅涉及 MySQL 与 TiDB 的总体差异。关于安全特性、悲观事务模型的兼容信息请查看各自具体页面。
 不支持的特性  存储过程与函数 触发器 事件 自定义函数 外键约束 全文/空间函数与索引 非 ascii/latin1/binary/utf8/utf8mb4 的字符集 BINARY 之外的排序规则 增加/删除主键 SYS schema MySQL 追踪优化器 XML 函数 X Protocol Savepoints 列级权限 XA 语法（TiDB 内部使用两阶段提交，但并没有通过 SQL 接口公开） CREATE TABLE tblName AS SELECT stmt 语法 CREATE TEMPORARY TABLE 语法 CHECK TABLE 语法 CHECKSUM TABLE 语法 SELECT INTO FILE 语法  与 MySQL 有差异的特性 自增 ID TiDB 中，自增列只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配 ID 的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。</description>
    </item>
    
    <item>
      <title>与 MySQL 安全特性差异</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/security/compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/security/compatibility/</guid>
      <description>与 MySQL 安全特性差异 除以下功能外，TiDB 支持与 MySQL 5.7 类似的安全特性。
 仅支持 mysql_native_password 身份验证方案。 不支持外部身份验证方式（如 LDAP）。 不支持列级别权限设置。 不支持使用证书验证身份。#9708 不支持密码过期，最后一次密码变更记录以及密码生存期。#9709 不支持权限属性 max_questions，max_updated，max_connections 以及 max_user_connections。 不支持密码验证。#9741 不支持透明数据加密（TDE）。  </description>
    </item>
    
    <item>
      <title>为 TiDB 组件间开启 TLS 和数据加密存储</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/secure/enable-tls-between-components/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/secure/enable-tls-between-components/</guid>
      <description>为 TiDB 组件间开启 TLS 和数据加密存储 本文档介绍 TiDB 集群如何开启 TLS 验证和数据加密存储。
开启 TLS 验证 本部分介绍 TiDB 集群如何开启 TLS 验证，TLS 验证支持：
 TiDB 组件之间的双向验证，包括 TiDB、TiKV、PD 相互之间，TiKV Control 与 TiKV、PD Control 与 PD 的双向认证，以及 TiKV peer 之间、PD peer 之间。一旦开启，所有组件之间均使用验证，不支持只开启某一部分的验证。 MySQL Client 与 TiDB 之间的客户端对服务器身份的单向验证以及双向验证。  MySQL Client 与 TiDB 之间使用一套证书，TiDB 集群组件之间使用另外一套证书。
TiDB 集群组件间开启 TLS（双向认证）   准备证书。
推荐为 TiDB、TiKV、PD 分别准备一个 server 证书，并保证可以相互验证，而它们的各种客户端共用 client 证书。
有多种工具可以生成自签名证书，如 openssl，easy-rsa，cfssl。
这里提供一个使用 cfssl 生成证书的示例：生成自签名证书。
  配置证书。
  TiDB</description>
    </item>
    
    <item>
      <title>从 AWS Aurora MySQL 迁移数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/from-aurora/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/from-aurora/</guid>
      <description>使用 DM 从 AWS Aurora MySQL 迁移数据。</description>
    </item>
    
    <item>
      <title>从 MySQL 迁移数据 —— 以 Amazon Aurora MySQL 为例</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/migrate/from-mysql-aurora/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/migrate/from-mysql-aurora/</guid>
      <description>使用 DM 从 MySQL/Amazon Aurora MySQL 迁移数据。</description>
    </item>
    
    <item>
      <title>位函数和操作符</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/bit-functions-and-operators/</guid>
      <description>位函数和操作符 TiDB 支持使用 MySQL 5.7 中提供的所有位函数和操作符。
位函数和操作符表
   函数和操作符名 功能描述     BIT_COUNT() 返回参数二进制表示中为 1 的个数   &amp;amp; 位与   ~ 按位取反   | 位或   ^ 位亦或   &amp;laquo; 左移   &amp;raquo; 右移    </description>
    </item>
    
    <item>
      <title>使用 BR 进行备份与恢复</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/br/br/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/br/br/</guid>
      <description>了解如何使用 BR 工具进行集群数据备份和恢复。</description>
    </item>
    
    <item>
      <title>使用 DM binary 部署 DM 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/data-migration-with-binary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/data-migration-with-binary/</guid>
      <description>使用 DM binary 部署 DM 集群 本文将介绍如何使用 DM binary 快速部署 DM 集群。
准备工作 下载官方 binary，链接地址：DM 下载。
下载的文件中包括子目录 bin 和 conf。bin 目录下包含 dm-master、dm-worker、dmctl 以及 Mydumper 的二进制文件。conf 目录下有相关的示例配置文件。
使用样例 假设在两台服务器上部署 MySQL，在一台服务器上部署 TiDB（mocktikv 模式），另外在三台服务器上部署两个 DM-worker 实例和一个 DM-master 实例。各个节点的信息如下：
   实例 服务器地址     MySQL1 192.168.0.1   MySQL2 192.168.0.2   TiDB 192.168.0.3   DM-master 192.168.0.4   DM-worker1 192.168.0.5   DM-worker2 192.168.0.6    MySQL1 和 MySQL2 中需要开启 binlog。DM-worker1 负责同步 MySQL1 的数据，DM-worker2 负责同步 MySQL2 的数据。下面以此为例，说明如何部署 DM。</description>
    </item>
    
    <item>
      <title>使用 DM 同步数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/deploy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/deploy/</guid>
      <description>使用 DM 同步数据 本文介绍如何使用 DM (Data Migration) 同步数据。
第 1 步：部署 DM 集群 目前推荐使用 DM-Ansible 部署 DM 集群，具体部署方法参照 使用 DM-Ansible 部署 DM 集群；也可以使用 binary 部署 DM 集群用于体验或者测试，具体部署方法参照使用 DM binary 部署 DM 集群。
 注意：
 在 DM 所有的配置文件中，数据库的密码要使用 dmctl 加密后的密文。如果数据库密码为空，则不需要加密。关于如何使用 dmctl 加密明文密码，参考使用 dmctl 加密上游 MySQL 用户密码。 上下游数据库用户必须拥有相应的读写权限。   第 2 步：检查集群信息 使用 DM-Ansible 部署 DM 集群后，相关配置信息如下：
  DM 集群相关组件配置信息
   组件 主机 端口     dm_worker1 172.</description>
    </item>
    
    <item>
      <title>使用 DM-Ansible 部署 DM 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/data-migration-with-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/data-migration-with-ansible/</guid>
      <description>使用 DM-Ansible 部署 DM 集群 DM-Ansible 是 PingCAP 基于 Ansible 的 Playbooks 研发的 DM (Data Migration) 集群部署工具。本文将介绍如何使用 DM-Ansible 快速部署 DM 集群。
准备工作 在开始之前，先确保您准备好了以下配置的机器：
  部署目标机器若干，配置如下：
 CentOS 7.3 (64-bit) 或更高版本，x86_64 架构（AMD64） 机器之间内网互通 关闭防火墙，或开放服务端口    一台中控机，配置如下：
 包含 Python 2.7 的 CentOS 7.3（64-bit）或更高版本 Ansible 2.5 或更高版本 互联网访问    第 1 步：在中控机上安装依赖包  注意：
请确保使用 root 账户登录中控机。
 根据中控机的操作系统版本，运行相应命令如下：
  CentOS 7：
 yum -y install epel-release git curl sshpass &amp;amp;&amp;amp; \ yum -y install python-pip   Ubuntu：</description>
    </item>
    
    <item>
      <title>使用 Docker Compose 快速构建 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/deploy-tidb-from-docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/deploy-tidb-from-docker-compose/</guid>
      <description>使用 Docker Compose 快速构建 TiDB 集群 本文档介绍如何在单机上通过 Docker Compose 快速一键部署一套 TiDB 测试集群。Docker Compose 可以通过一个 YAML 文件定义多个容器的应用服务，然后一键启动或停止。
 警告：
对于生产环境，不要使用 Docker Compose 进行部署，而应使用 Ansible 部署 TiDB 集群。
 准备环境 确保你的机器上已安装：
 Docker（17.06.0 及以上版本） Docker Compose Git  快速部署   下载 tidb-docker-compose
 git clone https://github.com/pingcap/tidb-docker-compose.git   创建并启动集群
获取最新 Docker 镜像：
 cd tidb-docker-compose &amp;amp;&amp;amp; docker-compose pull &amp;amp;&amp;amp; docker-compose up -d   访问集群
 mysql -h 127.0.0.1 -P 4000 -u root 访问集群 Grafana 监控页面：http://localhost:3000 默认用户名和密码均为 admin。</description>
    </item>
    
    <item>
      <title>使用 Grafana 监控 TiDB 的最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/grafana-monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/grafana-monitor/</guid>
      <description>了解高效利用 Grafana 监控 TiDB 的七个技巧。</description>
    </item>
    
    <item>
      <title>使用 kind 在 Kubernetes 上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-kind/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-kind/</guid>
      <description>使用 kind 在 Kubernetes 上部署 TiDB 集群。</description>
    </item>
    
    <item>
      <title>使用 Mydumper/TiDB Lightning 进行备份与恢复</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/maintain/backup-and-restore/mydumper-lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/maintain/backup-and-restore/mydumper-lightning/</guid>
      <description>使用 Mydumper/TiDB Lightning 进行备份与恢复 本文档将详细介绍如何使用 Mydumper/TiDB Lightning 对 TiDB 进行全量备份与恢复。增量备份与恢复可使用 TiDB Binlog。
这里假定 TiDB 服务信息如下：
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    在这个备份恢复过程中，会用到下面的工具：
 Mydumper 从 TiDB 导出数据 TiDB Lightning 导入数据到 TiDB  使用 Mydumper/TiDB Lightning 全量备份恢复数据 mydumper 是一个强大的数据备份工具，具体可以参考 maxbube/mydumper。
可使用 Mydumper 从 TiDB 导出数据进行备份，然后用 TiDB Lightning 将其导入到 TiDB 里面进行恢复。
 注意：
PingCAP 研发团队对 mydumper 进行了针对 TiDB 的适配性改造，建议使用 PingCAP 官方提供的 Mydumper。由于使用 mysqldump 进行数据备份和恢复都要耗费许多时间，这里也并不推荐。</description>
    </item>
    
    <item>
      <title>使用 SQL 语句检查 TiDB 集群状态</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/check-cluster-status-using-sql-statements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/check-cluster-status-using-sql-statements/</guid>
      <description>使用 SQL 语句检查 TiDB 集群状态 为了方便排查问题，TiDB 提供了一些 SQL 语句和系统表以查询一些有用的信息。
INFORMATION\_SCHEMA 中提供了如下几个系统表，用于查询集群状态，诊断常见的集群问题。
 TABLES TIDB_INDEXES ANALYZE_STATUS TIDB_HOT_REGIONS TIKV_STORE_STATUS TIKV_REGION_STATUS TIKV_REGION_PEERS  除此之外，执行下列语句也可获得对排查问题或查询集群状态有用的信息：
 ADMIN SHOW DDL 可以获得是 DDL owner 角色的 TiDB 的 ID 及 IP:PORT 等具体信息。 SHOW ANALYZE STATUS 和 ANALYZE_STATUS 表的功能相同。 特殊的 EXPLAIN 语句：  EXPLAIN ANALYZE 语句可以获得一个 SQL 语句执行中的一些具体信息。 EXPLAIN FOR CONNECTION 可以获得一个连接中最后执行的查询的执行计划。可以配合 SHOW PROCESSLIST 使用。 关于 EXPLAIN 相关的更具体的信息，参考文档理解 TiDB 执行计划。    </description>
    </item>
    
    <item>
      <title>使用 TiDB Ansible 扩容缩容 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/scale/with-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/scale/with-ansible/</guid>
      <description>使用 TiDB Ansible 扩容缩容 TiDB 集群 TiDB 集群可以在不影响线上服务的情况下进行扩容和缩容。
 注意：
以下缩容示例中，被移除的节点没有混合部署其他服务；如果混合部署了其他服务，不能按如下操作。
 假设拓扑结构如下所示：
   Name Host IP Services     node1 172.16.10.1 PD1   node2 172.16.10.2 PD2   node3 172.16.10.3 PD3, Monitor   node4 172.16.10.4 TiDB1   node5 172.16.10.5 TiDB2   node6 172.16.10.6 TiKV1   node7 172.16.10.7 TiKV2   node8 172.16.10.8 TiKV3   node9 172.16.10.9 TiKV4    扩容 TiDB/TiKV 节点 例如，如果要添加两个 TiDB 节点（node101、node102），IP 地址为 172.</description>
    </item>
    
    <item>
      <title>使用 TiDB Ansible 部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/ansible/</guid>
      <description>使用 TiDB Ansible 部署 TiDB 集群 概述 Ansible 是一款自动化运维工具，TiDB Ansible 是 PingCAP 基于 Ansible playbook 功能编写的集群部署工具。本文档介绍如何使用 TiDB Ansible 部署一个完整的 TiDB 集群。
本部署工具可以通过配置文件设置集群拓扑，完成以下各项运维工作：
 初始化操作系统参数 部署 TiDB 集群（包括 PD、TiDB、TiKV 等组件和监控组件） 启动集群 关闭集群 变更组件配置 集群扩容缩容 升级组件版本 集群开启 binlog 清除集群数据 销毁集群   注意：
对于生产环境，须使用 TiDB Ansible 部署 TiDB 集群。如果只是用于测试 TiDB 或体验 TiDB 的特性，建议使用 Docker Compose 在单机上快速部署 TiDB 集群。
 准备机器   部署目标机器若干
 建议 4 台及以上，TiKV 至少 3 实例，且与 TiDB、PD 模块不位于同一主机，详见部署建议。 推荐安装 CentOS 7.</description>
    </item>
    
    <item>
      <title>使用加密连接</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/secure/enable-tls-clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/secure/enable-tls-clients/</guid>
      <description>使用加密连接 TiDB 服务端默认采用非加密连接，因而具备监视信道流量能力的第三方可以知悉 TiDB 服务端与客户端之间发送和接受的数据，包括但不限于查询语句内容、查询结果等。若信道是不可信的，例如客户端是通过公网连接到 TiDB 服务端的，则非加密连接容易造成信息泄露，建议使用加密连接确保安全性。
TiDB 服务端支持启用基于 TLS（传输层安全）协议的加密连接，协议与 MySQL 加密连接一致，现有 MySQL 客户端如 MySQL 运维工具和 MySQL 驱动等能直接支持。TLS 的前身是 SSL，因而 TLS 有时也被称为 SSL，但由于 SSL 协议有已知安全漏洞，TiDB 实际上并未支持。TiDB 支持的 TLS/SSL 协议版本为 TLS 1.0、TLS 1.1、TLS 1.2。
使用加密连接后，连接将具有以下安全性质：
 保密性：流量明文无法被窃听； 完整性：流量明文无法被篡改； 身份验证（可选）：客户端和服务端能验证双方身份，避免中间人攻击。  TiDB 的加密连接支持默认是关闭的，必须在 TiDB 服务端通过配置开启加密连接的支持后，才能在客户端中使用加密连接。另外，与 MySQL 一致，TiDB 加密连接是以单个连接为单位的，并且是可选的，因而对于开启了加密连接支持的 TiDB 服务端，客户端既可以选择通过加密连接安全地连接到该 TiDB 服务端，也可以选择使用普通的非加密连接。大部分 MySQL 客户端默认不采用加密连接，因此一般还要显式地要求客户端使用加密连接。
简单来说，要使用加密连接必须同时满足以下两个条件：
 TiDB 服务端配置开启加密连接的支持 客户端指定使用加密连接  配置 TiDB 启用加密连接支持 在启动 TiDB 时，至少需要在配置文件中同时指定 ssl-cert 和 ssl-key 参数，才能使 TiDB 服务端接受加密连接。还可以指定 ssl-ca 参数进行客户端身份验证（请参见配置启用身份验证章节）。</description>
    </item>
    
    <item>
      <title>信息函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/information-functions/</guid>
      <description>信息函数 TiDB 支持使用 MySQL 5.7 中提供的大部分信息函数。
支持的函数    函数名 功能描述     BENCHMARK() 循环执行一个表达式   CONNECTION_ID() 返回当前连接的连接 ID (线程 ID)   CURRENT_USER(), CURRENT_USER 返回当前用户的用户名和主机名   DATABASE() 返回默认(当前)的数据库名   FOUND_ROWS() 该函数返回对于一个包含 LIMIT 的 SELECT 查询语句，在不包含 LIMIT 的情况下回返回的记录数   LAST_INSERT_ID() 返回最后一条 INSERT 语句中自增列的值   ROW_COUNT() 影响的行数   SCHEMA() 与 DATABASE() 同义   SESSION_USER() 与 USER() 同义   SYSTEM_USER() 与 USER() 同义   USER() 返回客户端提供的用户名和主机名   VERSION() 返回当前 MySQL 服务器的版本信息   TIDB_VERSION() 返回当前 TiDB 服务器的版本信息    不支持的函数  CHARSET() COERCIBILITY() COLLATION()  </description>
    </item>
    
    <item>
      <title>全量数据导入过程常见报错处理</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/error-case-handling/load-misuse-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/error-case-handling/load-misuse-handling/</guid>
      <description>全量数据导入过程常见报错处理 本文介绍了使用 Loader 或者 TiDB Data Migration（以下简称为 DM）进行全量数据导入过程中常见的因为使用造成的出错场景，以及这些错误发生的原因和处理方式。
报错：Try adjusting the `max_allowed_packet` variable 在全量数据导入过程中遇到下面的报错
packet for query is too large. Try adjusting the &amp;#39;max_allowed_packet&amp;#39; variable 原因  MySQL client 和 MySQL/TiDB Server 都有 max_allowed_packet 配额的限制，如果在使用过程中违反其中任何一个 max_allowed_packet 配额，客户端程序就会收到对应的报错。目前最新版本的 Syncer、Loader、DM 和 TiDB Server 的默认 max_allowed_packet 配额都为 64M。  请使用最新版本，或者最新稳定版本的工具。下载页面。   Loader 或 DM 的全量数据导入处理模块不支持对 dump sqls 文件进行切分，原因是 Mydumper 采用了最简单的编码实现，正如 Mydumper 代码注释 /* Poor man&#39;s data dump code */ 所言。如果在 Loader 或 DM 实现文件切分，那么需要在 TiDB parser 基础上实现一个完备的解析器才能正确的处理数据切分，但是随之会带来以下的问题：  工作量大 复杂度高,不容易保证正确性 性能的极大降低    解决方案   依据上面的原因，在代码层面不能简单的解决这个困扰，我们推荐的方式是：利用 Mydumper 提供的控制 Insert Statement 大小的功能 -s, --statement-size: Attempted size of INSERT statement in bytes, default 1000000&amp;quot;。</description>
    </item>
    
    <item>
      <title>关键字和保留字</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/keywords-and-reserved-words/</guid>
      <description>关键字和保留字 关键字在 SQL 中有特殊的意义， 例如 SELECT，UPDATE，DELETE，在作为表名跟函数名的时候，需要特殊对待，例如作为表名，保留字需要被反引号包住：
 CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27)  CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.09 sec) BEGIN 和 END 是关键字， 但不是保留字，所以不需要反引号：
 CREATE TABLE `select` (BEGIN int, END int); Query OK, 0 rows affected (0.09 sec) 有一种特殊情况， 如果使用了限定符 .，那么也不需要用反引号：
 CREATE TABLE test.select (BEGIN int, END int); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>其他函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/miscellaneous-functions/</guid>
      <description>其他函数 TiDB 支持使用 MySQL 5.7 中提供的大部分其他函数。
支持的函数    函数名 功能描述     ANY_VALUE() 在 ONLY_FULL_GROUP_BY 模式下，防止带有 GROUP BY 的语句报错   DEFAULT() 返回表的某一列的默认值   INET_ATON() 将 IP 地址转换为数值   INET_NTOA() 将数值转换为 IP 地址   INET6_ATON() 将 IPv6 地址转换为数值   INET6_NTOA() 将数值转换为 IPv6 地址   IS_IPV4() 判断参数是否为 IPv4 地址   IS_IPV4_COMPAT() 判断参数是否为兼容 IPv4 的地址   IS_IPV4_MAPPED() 判断参数是否为 IPv4 映射的地址   IS_IPV6() 判断参数是否为 IPv6 地址   NAME_CONST() 可以用于重命名列名   SLEEP() 让语句暂停执行几秒时间   UUID() 返回一个通用唯一识别码 (UUID)   VALUES() 定义 INSERT 语句使用的值    不支持的函数    函数名 功能描述     GET_LOCK() 获取命名锁，详见 TiDB #10929   RELEASE_LOCK() 释放命名锁，详见 TiDB #10929   UUID_SHORT() 基于特定假设提供唯一的 UUID，目前这些假设在 TiDB 中不存在，详见 TiDB #4620   MASTER_WAIT_POS() 与 MySQL 同步相关    </description>
    </item>
    
    <item>
      <title>函数和操作符概述</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/reference/</guid>
      <description>函数和操作符概述 TiDB 中函数和操作符使用方法与 MySQL 基本一致，详情参见: Functions and Operators。
在 SQL 语句中，表达式可用于诸如 SELECT 语句的 ORDER BY 或 HAVING 子句，SELECT/DELETE/UPDATE 语句的 WHERE 子句，或 SET 语句之类的地方。
可使用字面值，列名，NULL，内置函数，操作符等来书写表达式。其中有些表达式下推到 TiKV 上执行，详见下推到 TiKV 的表达式列表。</description>
    </item>
    
    <item>
      <title>分区表</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/partitioning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/partitioning/</guid>
      <description>分区表 本文介绍 TiDB 的分区表。
分区类型 本节介绍在 TiDB 中的分区类型。当前支持的类型包括 Range 分区和 Hash 分区。Range 分区可以用于解决业务中大量删除带来的性能问题，支持快速删除分区。Hash 分区则可以用于大量写入场景下的数据打散。
Range 分区 一个表按 range 分区是指，对于表的每个分区中包含的所有行，按分区表达式计算的值都落在给定的范围内。Range 必须是连续的，并且不能有重叠，通过使用 VALUES LESS THAN 操作进行定义。
下列场景中，假设你要创建一个人事记录的表：
 CREATE TABLE employees ( id INT NOT NULL, fname VARCHAR(30), lname VARCHAR(30), hired DATE NOT NULL DEFAULT &amp;#39;1970-01-01&amp;#39;, separated DATE NOT NULL DEFAULT &amp;#39;9999-12-31&amp;#39;, job_code INT NOT NULL, store_id INT NOT NULL ); 你可以根据需求按各种方式进行 range 分区。其中一种方式是按 store_id 列进行分区。你可以这样做：
 CREATE TABLE employees ( id INT NOT NULL, fname VARCHAR(30), lname VARCHAR(30), hired DATE NOT NULL DEFAULT &amp;#39;1970-01-01&amp;#39;, separated DATE NOT NULL DEFAULT &amp;#39;9999-12-31&amp;#39;, job_code INT NOT NULL, store_id INT NOT NULL ) PARTITION BY RANGE (store_id) ( PARTITION p0 VALUES LESS THAN (6), PARTITION p1 VALUES LESS THAN (11), PARTITION p2 VALUES LESS THAN (16), PARTITION p3 VALUES LESS THAN (21) ); 在这个分区模式中，所有 store_id 为 1 到 5 的员工，都存储在分区 p0 里面，store_id 为 6 到 10 的员工则存储在分区 p1 里面。range 分区要求，分区的定义必须是有序的，按从小到大递增。</description>
    </item>
    
    <item>
      <title>分库分表合并同步</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/shard-merge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/shard-merge/</guid>
      <description>分库分表合并同步 本文介绍了 DM 提供的分库分表合并同步功能。此功能用于将上游 MySQL/MariaDB 实例中结构相同的表同步到下游 TiDB 的同一个表中。DM 不仅支持同步上游的 DML 数据，也支持协调同步多个上游分表的 DDL 表结构变更。
 注意：
要执行分库分表合并同步任务，必须在任务配置文件中设置 is-sharding: true。
 使用限制 DM 进行分表 DDL 的同步有以下几点使用限制：
  在一个逻辑 sharding group（需要合并同步到下游同一个表的所有分表组成的 group）内，所有上游分表必须以相同的顺序执行相同的 DDL 语句（库名和表名可以不同），并且只有在所有分表执行完当前一条 DDL 语句后，下一条 DDL 语句才能执行。
 比如，如果在 table_1 表中先增加列 a 后再增加列 b，则在 table_2 表中就不能先增加列 b 后再增加列 a，因为 DM 不支持以不同的顺序来执行相同的 DDL 语句。    对于每个逻辑 sharding group，推荐使用一个独立的任务进行同步。
 如果一个任务内存在多个 sharding group，则必须等待一个 sharding group 的 DDL 语句同步完成后，才能开始对其他 sharding group 执行 DDL 语句。    在一个逻辑 sharding group 内，所有上游分表都应该执行对应的 DDL 语句。</description>
    </item>
    
    <item>
      <title>分库分表场景下的数据校验</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/shard-diff/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/sync-diff-inspector/shard-diff/</guid>
      <description>分库分表场景下的数据校验 sync-diff-inspector 支持对分库分表场景进行数据校验。例如有两个 MySQL 实例，使用同步工具 DM 同步到一个 TiDB 中，场景如图所示：
则需要为 table-0 在 table-config 中进行特殊配置，设置 is-sharding=true，并且在 table-config.source-tables 中配置上游表信息。完整的示例配置如下：
# Diff Configuration. ######################### Global config ######################### # 日志级别，可以设置为 info、debug log-level = &amp;#34;info&amp;#34; # sync-diff-inspector 根据主键／唯一键／索引将数据划分为多个 chunk， # 对每一个 chunk 的数据进行对比。使用 chunk-size 设置 chunk 的大小 chunk-size = 1000 # 检查数据的线程数量 check-thread-count = 4 # 抽样检查的比例，如果设置为 100 则检查全部数据 sample-percent = 100 # 通过计算 chunk 的 checksum 来对比数据，如果不开启则逐行对比数据 use-checksum = true # 如果设置为 true 则只会通过计算 checksum 来校验数据，如果上下游的 checksum 不一致也不会查出数据再进行校验 only-use-checksum = false # 是否使用上次校验的 checkpoint，如果开启，则只校验上次未校验以及校验失败的 chunk use-checkpoint = true # 不对比数据 ignore-data-check = false # 不对比表结构 ignore-struct-check = false # 保存用于修复数据的 sql 的文件名称 fix-sql-file = &amp;#34;fix.</description>
    </item>
    
    <item>
      <title>分表合并数据迁移最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/best-practice-dm-shard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/best-practice-dm-shard/</guid>
      <description>使用 DM 对分库分表进行合并迁移时的最佳实践。</description>
    </item>
    
    <item>
      <title>切换 DM-worker 与上游 MySQL 实例的连接</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/master-slave-switch/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/usage-scenarios/master-slave-switch/</guid>
      <description>了解如何切换 DM-worker 与上游 MySQL 实例的连接。</description>
    </item>
    
    <item>
      <title>加密和压缩函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/encryption-and-compression-functions/</guid>
      <description>加密和压缩函数 TiDB 支持使用 MySQL 5.7 中提供的大部分加密和压缩函数。
支持的函数    函数名 功能描述     MD5()  计算字符串的 MD5 校验和    PASSWORD() 计算并返回密码字符串   RANDOM_BYTES() 返回随机字节向量   SHA1(), SHA()  计算 SHA-1 160 位校验和    SHA2()  计算 SHA-2 校验和    AES_DECRYPT() 使用 AES 解密   AES_ENCRYPT() 使用 AES 加密   COMPRESS() 返回经过压缩的二进制字符串   UNCOMPRESS() 解压缩字符串   UNCOMPRESSED_LENGTH()  返回字符串解压后的长度   CREATE_ASYMMETRIC_PRIV_KEY() 创建私钥   CREATE_ASYMMETRIC_PUB_KEY() 创建公钥   CREATE_DH_PARAMETERS() 创建 DH 共享密钥   CREATE_DIGEST() 从字符串创建摘要   ASYMMETRIC_DECRYPT() 使用公钥或私钥解密密文   ASYMMETRIC_DERIVE() 从非对称密钥导出对称密钥   ASYMMETRIC_ENCRYPT() 使用公钥或私钥加密明文   ASYMMETRIC_SIGN() 从摘要创建签名   ASYMMETRIC_VERIFY() 验证签名字符串是否匹配摘要字符串    不支持的函数  DES_DECRYPT()、DES_ENCRYPT()、OLD_PASSWORD() 和 ENCRYPT()：这些函数在 MySQL 5.</description>
    </item>
    
    <item>
      <title>升级 TiDB Operator</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/upgrade/tidb-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/upgrade/tidb-operator/</guid>
      <description>升级 TiDB Operator 本文介绍如何升级 TiDB Operator。升级 TiDB Operator 和自定义 TiDB Operator 类似，修改 values.yaml 中的镜像版本，然后执行 helm upgrade：
 helm upgrade tidb-operator pingcap/tidb-operator --version=&amp;lt;chart-version&amp;gt; -f /home/tidb/tidb-operator/values-tidb-operator.yaml 当新版本 tidb-operator 发布，只要更新 values.yaml 中的 operatorImage 然后执行上述命令就可以。但是安全起见，最好从新版本 tidb-operator chart 中获取新版本 values.yaml 并和旧版本 values.yaml 合并生成新的 values.yaml，然后升级。
TiDB Operator 是用来管理 TiDB 集群的，也就是说，如果 TiDB 集群已经启动并正常运行，你甚至可以停掉 TiDB Operator，而 TiDB 集群仍然能正常工作，直到你需要维护 TiDB 集群，比如伸缩、升级等等。
升级 Kubernetes 当你的 Kubernetes 集群有版本升级，请确保 kubeSchedulerImageTag 与之匹配。默认情况下，这个值是由 Helm 在安装或者升级过程中生成的，要修改它你需要执行 helm upgrade。</description>
    </item>
    
    <item>
      <title>升级后常见问题</title>
      <link>https://pingcap.com/docs-cn/v3.1/faq/upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/faq/upgrade/</guid>
      <description>升级后常见问题 本文列出了一些升级后可能会遇到的问题与解决办法。
执行 DDL 操作时遇到的字符集 (charset) 问题 TiDB 在 v2.1.0 以及之前版本（包括 v2.0 所有版本）中，默认字符集是 UTF8。从 v2.1.1 开始，默认字符集变更为 UTF8MB4。如果在 v2.1.0 及之前版本中，建表时显式指定了 table 的 charset 为 UTF8，那么升级到 v2.1.1 之后，执行 DDL 操作可能会失败。
要避免该问题，需注意以下两个要点：
  在 v2.1.3 之前，TiDB 不支持修改 column 的 charset。所以，执行 DDL 操作时，新 column 的 charset 需要和旧 column 的 charset 保持一致。
  在 v2.1.3 之前，即使 column 的 charset 和 table 的 charset 不一样，show create table 也不会显示 column 的 charset，但可以通过 HTTP API 获取 table 的元信息来查看 column 的 charset，下文提供了示例。</description>
    </item>
    
    <item>
      <title>在 AWS EKS 上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/aws-eks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/aws-eks/</guid>
      <description>在 AWS EKS 上部署 TiDB 集群 本文介绍了如何使用个人电脑（Linux 或 macOS 系统）在 AWS EKS (Elastic Kubernetes Service) 上部署 TiDB 集群。
环境配置准备 部署前，请确认已安装以下软件并完成配置：
  awscli &amp;gt;= 1.16.73，控制 AWS 资源
要与 AWS 交互，必须配置 awscli。最快的方式是使用 aws configure 命令:
 aws configure 替换下面的 AWS Access Key ID 和 AWS Secret Access Key：
AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Default region name [None]: us-west-2 Default output format [None]: json  注意：</description>
    </item>
    
    <item>
      <title>在 GCP GKE 上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/gcp-gke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/gcp-gke/</guid>
      <description>了解如何在 GCP GKE 上部署 TiDB 集群。</description>
    </item>
    
    <item>
      <title>在 GCP 上通过 Kubernetes 部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-gke/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-gke/</guid>
      <description>在 GCP 上通过 Kubernetes 部署 TiDB 集群教程</description>
    </item>
    
    <item>
      <title>在 Kubernetes 上部署 TiDB Operator</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/tidb-operator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/tidb-operator/</guid>
      <description>了解如何在 Kubernetes 上部署 TiDB Operator</description>
    </item>
    
    <item>
      <title>在 Minikube 集群上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-minikube/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/get-started/deploy-tidb-from-kubernetes-minikube/</guid>
      <description>在 Minikube 集群上部署 TiDB 集群</description>
    </item>
    
    <item>
      <title>在标准 Kubernetes 上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/general-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/general-kubernetes/</guid>
      <description>在标准 Kubernetes 上部署 TiDB 集群 本文主要描述了如何在标准的 Kubernetes 集群上通过 TiDB Operator 部署 TiDB 集群。
前置条件  参考 TiDB Operator 完成集群中的 TiDB Operator 部署； 参考 使用 Helm 安装 Helm 并配置 PingCAP 官方 chart 仓库。  配置 TiDB 集群 通过下面命令获取待安装的 tidb-cluster chart 的 values.yaml 配置文件：
 mkdir -p /home/tidb/&amp;lt;release-name&amp;gt; &amp;amp;&amp;amp; \ helm inspect values pingcap/tidb-cluster --version=&amp;lt;chart-version&amp;gt; &amp;gt; /home/tidb/&amp;lt;release-name&amp;gt;/values-&amp;lt;release-name&amp;gt;.yaml  注意：
 /home/tidb 可以替换为你想用的目录。 release-name 将会作为 Kubernetes 相关资源（例如 Pod，Service 等）的前缀名，可以起一个方便记忆的名字，要求全局唯一，通过 helm ls -q 可以查看集群中已经有的 release-name。 chart-version 是 tidb-cluster chart 发布的版本，可以通过 helm search -l tidb-cluster 查看当前支持的版本。 下文会用 values.</description>
    </item>
    
    <item>
      <title>在阿里云上部署 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/alibaba-cloud/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/alibaba-cloud/</guid>
      <description>在阿里云上部署 TiDB 集群 本文介绍了如何使用个人电脑（Linux 或 macOS 系统）在阿里云上部署 TiDB 集群。
环境需求   aliyun-cli &amp;gt;= 3.0.15 并且配置 aliyun-cli
 注意：
Access Key 需要具有操作相应资源的权限。
   kubectl &amp;gt;= 1.12
  helm &amp;gt;= 2.9.1 且 &amp;lt;= 2.11.0
  jq &amp;gt;= 1.6
  terraform 0.12.*
  你可以使用阿里云的云命令行服务来进行操作，云命令行中已经预装并配置好了所有工具。
权限 完整部署集群需要具备以下权限：
 AliyunECSFullAccess AliyunESSFullAccess AliyunVPCFullAccess AliyunSLBFullAccess AliyunCSFullAccess AliyunEIPFullAccess AliyunECIFullAccess AliyunVPNGatewayFullAccess AliyunNATGatewayFullAccess  概览 默认配置下，会创建：
 一个新的 VPC 一台 ECS 实例作为堡垒机 一个托管版 ACK（阿里云 Kubernetes）集群以及一系列 worker 节点：  属于一个伸缩组的 2 台 ECS 实例（2 核 2 GB）托管版 Kubernetes 的默认伸缩组中必须至少有两台实例，用于承载整个的系统服务，例如 CoreDNS 属于一个伸缩组的 3 台 ecs.</description>
    </item>
    
    <item>
      <title>基于 Helm Charts 实现的 TiDB 集群备份恢复</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/charts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/charts/</guid>
      <description>基于 Helm Charts 实现的 TiDB 集群备份与恢复 本文详细描述了如何对 Kubernetes 上的 TiDB 集群进行数据备份和数据恢复。本文使用的备份和恢复方式是基于 Helm Charts 实现的。
TiDB Operator 1.1 及以上版本推荐使用基于 CRD 的实现的备份和恢复方式，详情可参阅以下文档：
 备份 TiDB 集群到 GCS 恢复 GCS 上的备份数据 备份 TiDB 集群到兼容 S3 的存储 恢复 S3 兼容存储上的备份数据  Kubernetes 上的 TiDB 集群支持两种备份策略：
 全量备份（定时执行或 Ad-hoc）：使用 mydumper 获取集群的逻辑备份； 增量备份：使用 TiDB Binlog 将 TiDB 集群的数据实时复制到其它数据库中或实时获得增量数据备份；  目前，Kubernetes 上的 TiDB 集群只对 mydumper 获取的全量备份数据提供自动化的数据恢复操作。恢复 TiDB-Binlog 获取的增量数据需要手动进行。
全量备份 全量备份使用 mydumper 来获取 TiDB 集群的逻辑备份数据。全量备份任务会创建一个 PVC (PersistentVolumeClaim) 来存储数据。</description>
    </item>
    
    <item>
      <title>基于角色的访问控制</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/security/role-based-access-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/security/role-based-access-control/</guid>
      <description>基于角色的访问控制 TiDB 的基于角色的访问控制 (RBAC) 系统的实现类似于 MySQL 8.0 的 RBAC 系统。TiDB 兼容大部分 MySQL RBAC 系统的语法。
本文档主要介绍 TiDB 基于角色的访问控制相关操作及实现。
角色访问控制相关操作 角色是一系列权限的集合。用户可以创建角色、删除角色、将权限赋予角色；也可以将角色授予给其他用户，被授予的用户在启用角色后，可以得到角色所包含的权限。
创建角色 创建角色 r_1 和 r_2：
 CREATE ROLE `r_1`@`%`, `r_2`@`%`; 角色名的格式和规范可以参考 TiDB 用户账户管理。
角色会被保存在 mysql.user 表中，如果表中有同名角色或用户，角色会创建失败并报错。 创建角色的用户需要拥有 CREATE ROLE 或 CREATE USER 权限。
删除角色 删除角色 r_1 和 r_2：
 DROP ROLE `r_1`@`%`, `r_2`@`%`; 这个操作会清除角色在 mysql.user 表里面的记录项，并且清除在授权表里面的相关记录，解除和其相关的授权关系。 执行删除角色的用户需要拥有 DROP ROLE 或 DROP USER 权限。
授予角色权限 为角色授予权限和为用户授予权限操作相同，可参考 TiDB 权限管理。
为 analyst 角色授予数据库 test 的读权限：</description>
    </item>
    
    <item>
      <title>备份 TiDB 集群到 GCS</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/backup-gcs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/backup-gcs/</guid>
      <description>备份 TiDB 集群到 GCS 本文档详细描述了如何将 Kubernetes 上 TiDB 集群的数据备份到 Google Cloud Storage (GCS) 上。本文档中的“备份”，均是指全量备份（Ad-hoc 全量备份和定时全量备份），底层通过使用 mydumper 获取集群的逻辑备份，然后再将备份数据上传到远端 GCS。
本文使用的备份方式基于 TiDB Operator 新版（v1.1 及以上）的 CustomResourceDefinition (CRD) 实现。基于 Helm Charts 的备份和恢复方式可参考基于 Helm Charts 实现的 TiDB 集群备份与恢复。
Ad-hoc 全量备份 Ad-hoc 全量备份通过创建一个自定义的 Backup custom resource (CR) 对象来描述一次备份。TiDB Operator 根据这个 Backup 对象来完成具体的备份过程。如果备份过程中出现错误，程序不会自动重试，此时需要手动处理。
为了更好地描述备份的使用方式，本文档提供如下备份示例。示例假设对部署在 Kubernetes test1 这个 namespace 中的 TiDB 集群 demo1 进行数据备份，下面是具体操作过程。
Ad-hoc 全量备份环境准备   下载文件 backup-rbac.yaml，并执行以下命令在 test1 这个 namespace 中创建备份需要的 RBAC 相关资源：
 kubectl apply -f backup-rbac.</description>
    </item>
    
    <item>
      <title>备份 TiDB 集群到兼容 S3 的存储</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/backup-s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/backup-s3/</guid>
      <description>备份 TiDB 集群到兼容 S3 的存储 本文详细描述了如何将 Kubernetes 上的 TiDB 集群数据备份到兼容 S3 的存储上。本文档中的“备份”，均是指全量备份（Ad-hoc 全量备份和定时全量备份）。底层通过使用 mydumper 获取集群的逻辑备份，然后在将备份数据上传到兼容 S3 的存储上。
本文使用的备份方式基于 TiDB Operator 新版（v1.1 及以上）的 CustomResourceDefinition (CRD) 实现。基于 Helm Charts 实现的备份和恢复方式可参考基于 Helm Charts 实现的 TiDB 集群备份与恢复。
Ad-hoc 全量备份 Ad-hoc 全量备份通过创建一个自定义的 Backup custom resource (CR) 对象来描述一次备份。TiDB Operator 根据这个 Backup 对象来完成具体的备份过程。如果备份过程中出现错误，程序不会自动重试，此时需要手动处理。
目前兼容 S3 的存储中，Ceph 和 Amazon S3 经测试可正常工作。下文对 Ceph 和 Amazon S3 这两种存储的使用进行描述。本文档提供如下备份示例。示例假设对部署在 Kubernetes test1 这个 namespace 中的 TiDB 集群 demo1 进行数据备份，下面是具体操作过程。
Ad-hoc 全量备份环境准备   下载文件 backup-rbac.</description>
    </item>
    
    <item>
      <title>如何对 TiDB 进行 TPC-C 测试</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/how-to-run-tpcc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/how-to-run-tpcc/</guid>
      <description>如何对 TiDB 进行 TPC-C 测试 本文介绍如何对 TiDB 进行 TPC-C 测试。
准备测试程序 TPC-C 是一个对 OLTP（联机交易处理）系统进行测试的规范，使用一个商品销售模型对 OLTP 系统进行测试，其中包含五类事务：
 NewOrder – 新订单的生成 Payment – 订单付款 OrderStatus – 最近订单查询 Delivery – 配送 StockLevel – 库存缺货状态分析  在测试开始前，TPC-C Benchmark 规定了数据库的初始状态，也就是数据库中数据生成的规则，其中 ITEM 表中固定包含 10 万种商品，仓库的数量可进行调整，假设 WAREHOUSE 表中有 W 条记录，那么：
 STOCK 表中应有 W * 10 万条记录（每个仓库对应 10 万种商品的库存数据） DISTRICT 表中应有 W * 10 条记录（每个仓库为 10 个地区提供服务） CUSTOMER 表中应有 W * 10 * 3000 条记录（每个地区有 3000 个客户） HISTORY 表中应有 W * 10 * 3000 条记录（每个客户一条交易历史） ORDER 表中应有 W * 10 * 3000 条记录（每个地区 3000 个订单），并且最后生成的 900 个订单被添加到 NEW-ORDER 表中，每个订单随机生成 5 ~ 15 条 ORDER-LINE 记录。  我们将以 1000 WAREHOUSE 为例进行测试。</description>
    </item>
    
    <item>
      <title>如何用 Sysbench 测试 TiDB</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/how-to-run-sysbench/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/how-to-run-sysbench/</guid>
      <description>如何用 Sysbench 测试 TiDB 本次测试使用的是 TiDB 3.0 Beta 和 Sysbench 1.0.14。建议使用 Sysbench 1.0 或之后的更新版本，可在 Sysbench Release 1.0.14 页面下载。
测试环境   硬件要求
  参考 TiDB 部署文档部署 TiDB 集群。在 3 台服务器的条件下，建议每台机器部署 1 个 TiDB，1 个 PD，和 1 个 TiKV 实例。关于磁盘，以 32 张表、每张表 10M 行数据为例，建议 TiKV 的数据目录所在的磁盘空间大于 512 GB。 对于单个 TiDB 的并发连接数，建议控制在 500 以内，如需增加整个系统的并发压力，可以增加 TiDB 实例，具体增加的 TiDB 个数视测试压力而定。
  IDC 机器：
   类别 名称     OS Linux (CentOS 7.</description>
    </item>
    
    <item>
      <title>字符串函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/string-functions/</guid>
      <description>字符串函数 TiDB 支持使用 MySQL 5.7 中提供的大部分字符串函数。
支持的函数    函数名 功能描述     ASCII() 返回最左字符的数值   BIN() 返回一个数的二进制值的字符串表示   BIT_LENGTH() 返回字符串的位长度   CHAR()  返回由整数的代码值所给出的字符组成的字符串   CHAR_LENGTH() 返回字符串的字符长度   CHARACTER_LENGTH() 与 CHAR_LENGTH() 功能相同   CONCAT() 返回连接的字符串   CONCAT_WS() 返回由分隔符连接的字符串   ELT() 返回指定位置的字符串   EXPORT_SET() 返回一个字符串，其中值位中设置的每个位，可以得到一个 on 字符串，而每个未设置的位，可以得到一个 off 字符串   FIELD() 返回参数在后续参数中出现的第一个位置   FIND_IN_SET() 返回第一个参数在第二个参数中出现的位置   FORMAT() 返回指定小数位数格式的数字   FROM_BASE64() 解码 base-64 表示的字符串，并返回结果   HEX() 返回一个十进制数或字符串值的 16 进制表示   INSERT() 在指定位置插入一个子字符串，最多不超过指定字符数   INSTR() 返回第一次出现的子字符串的索引   LCASE() 与 LOWER() 功能相同   LEFT() 返回最左侧指定长度的字符   LENGTH() 返回字符串长度，单位为字节   LIKE 进行简单模式匹配   LOCATE() 返回第一次出现的子字符串的位置   LOWER() 返回全小写的参数   LPAD() 返回字符串参数，左侧添加指定字符串   LTRIM() 去掉前缀空格   MAKE_SET() 返回一组用逗号分隔的字符串，这些字符串的位数与给定的 bits 参数对应   MID() 返回一个以指定位置开始的子字符串   NOT LIKE 否定简单模式匹配   NOT REGEXP REGEXP 的否定形式   OCT() 返回一个数值的八进制表示，形式为字符串   OCTET_LENGTH() 与 LENGTH() 功能相同   ORD() 返回该参数最左侧字符的字符编码   POSITION() 与 LOCATE() 功能相同   QUOTE() 使参数逃逸，为了在 SQL 语句中使用   REGEXP 使用正则表达式匹配模式   REPEAT() 以指定次数重复一个字符串   REPLACE() 替换所有出现的指定字符串   REVERSE() 反转字符串里的所有字符   RIGHT() 返回指定数量的最右侧的字符   RLIKE 与 REGEXP 功能相同   RPAD() 以指定次数添加字符串   RTRIM() 去掉后缀空格   SPACE() 返回指定数量的空格，形式为字符串   STRCMP() 比较两个字符串   SUBSTR() 返回指定的子字符串   SUBSTRING() 返回指定的子字符串   SUBSTRING_INDEX() 从一个字符串中返回指定出现次数的定界符之前的子字符串   TO_BASE64() 返回转化为 base-64 表示的字符串参数   TRIM() 去掉前缀和后缀空格   UCASE() 与 UPPER() 功能相同   UNHEX() 返回一个数的十六进制表示，形式为字符串   UPPER() 参数转换为大写形式    不支持的函数  LOAD_FILE() MATCH SOUNDEX() SOUNDS LIKE WEIGHT_STRING()  </description>
    </item>
    
    <item>
      <title>字符串类型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/string/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/string/</guid>
      <description>字符串类型 TiDB 支持 MySQL 所有的字符串类型，包括 CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM 以及 SET，完整信息参考这篇文档。
类型定义 CHAR 类型 定长字符串。CHAR 列的长度固定为创建表时声明的长度。长度可以为从 0 到 255 的任何值。当保存 CHAR 值时，在它们的右边填充空格以达到指定的长度。
 [NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name] VARCHAR 类型 变长字符串。M 表示最大列长度，范围是 0 到 65535。VARCHAR 的最大实际长度由最长的行的大小和使用的字符集确定。
 [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name] TEXT 类型 文本串。M 表示最大列长度，范围是 0 到 65535。TEXT 的最大实际长度由最长的行的大小和使用的字符集确定。
 TEXT[(M)] [CHARACTER SET charset_name] [COLLATE collation_name] TINYTEXT 类型 类似于 TEXT，区别在于最大列长度为 255。
 TINYTEXT [CHARACTER SET charset_name] [COLLATE collation_name] MEDIUMTEXT 类型 类似于 TEXT，区别在于最大列长度为 16,777,215。</description>
    </item>
    
    <item>
      <title>字符集支持</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/character-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/character-set/</guid>
      <description>字符集支持 名词解释，下面的阐述中会交错使用中文或者英文，请互相对照：
 Character Set：字符集 Collation：排序规则  目前 TiDB 支持以下字符集：
 SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>字面值</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/literal-values/</guid>
      <description>字面值 String Literals String Literals 是一个 bytes 或者 characters 的序列，两端被单引号 &#39; 或者双引号 &amp;quot; 包围，例如：
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; 如果字符串是连续的，会被合并为一个独立的 string。以下表示是一样的：
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; 如果 ANSI_QUOTES SQL MODE 开启了，那么只有单引号内的会被认为是 String Literals，对于双引号内的字符串，会被认为是一个 identifier。
binary string 是一串 bytes 组成的字符串，每一个 binary string 有一个叫做 binary 的 character set 和 collation。一个非二进制的字符串是一个由字符组成的字符串，它有除 binary 外的 character set和与之兼容的 collation。
对于两种字符串类型，比较都是基于每个字符的数值。对于 binary string 而言，比较单元就是字节，对于非二进制的字符串，那么单元就是字符，而有的字符集支持多字节字符。
一个 String Literal 可以拥有一个可选的 character set introducer 和 COLLATE clause，可以用来指派特定的字符集跟 collation（TiDB 对此只是做了语法上的兼容，并不实质做处理)。</description>
    </item>
    
    <item>
      <title>定位消耗系统资源多的查询</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/maintain/identify-abnormal-queries/identify-expensive-queries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/maintain/identify-abnormal-queries/identify-expensive-queries/</guid>
      <description>定位消耗系统资源多的查询 TiDB 会将执行时间超过 tidb_expensive_query_time_threshold（默认值为 60s），或使用内存超过 mem-quota-query（默认值为 32 GB）的语句输出到 tidb-server 日志文件（默认文件为：“tidb.log”）中，用于在语句执行结束前定位消耗系统资源多的查询语句（以下简称为 expensive query），帮助用户分析和解决语句执行的性能问题。
注意，expensive query 日志和慢查询日志的区别是，慢查询日志是在语句执行完后才打印，expensive query 日志可以将正在执行的语句的相关信息打印出来。当一条语句在执行过程中达到资源使用阈值时（执行时间/使用内存量），TiDB 会即时将这条语句的相关信息写入日志。
Expensive query 日志示例 [2020/02/05 15:32:25.096 +08:00] [WARN] [expensivequery.go:167] [expensive_query] [cost_time=60.008338935s] [wait_time=0s] [request_count=1] [total_keys=70] [process_keys=65] [num_cop_tasks=1] [process_avg_time=0s] [process_p90_time=0s] [process_max_time=0s] [process_max_addr=10.0.1.9:20160] [wait_avg_time=0.002s] [wait_p90_time=0.002s] [wait_max_time=0.002s] [wait_max_addr=10.0.1.9:20160] [stats=t:pseudo] [conn_id=60026] [user=root] [database=test] [table_ids=&amp;#34;[122]&amp;#34;] [txn_start_ts=414420273735139329] [mem_max=&amp;#34;1035 Bytes (1.0107421875 KB)&amp;#34;] [sql=&amp;#34;insert into t select sleep(1) from t&amp;#34;] 字段含义说明 基本字段：
 cost_time：日志打印时语句已经花费的执行时间。 stats：语句涉及到的表或索引使用的统计信息版本。值为 pesudo 时表示无可用统计信息，需要对表或索引进行 analyze。 table_ids：语句涉及到的表的 ID。 txn_start_ts：事务的开始时间戳，也是事务的唯一 ID，可以用这个值在 TiDB 日志中查找事务相关的其他日志。 sql：SQL 语句。  和内存使用相关的字段：</description>
    </item>
    
    <item>
      <title>开发 Java 应用使用 TiDB 的最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/java-app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/java-app/</guid>
      <description>开发 Java 应用使用 TiDB 的最佳实践 本文主要介绍如何开发 Java 应用程序以更好地使用 TiDB，包括开发中的常见问题与最佳实践。
Java 应用中的数据库相关组件 通常 Java 应用中和数据库相关的常用组件有：
 网络协议：客户端通过标准 MySQL 协议和 TiDB 进行网络交互。 JDBC API 及实现：Java 应用通常使用 JDBC (Java Database Connectivity) 来访问数据库。JDBC 定义了访问数据库 API，而 JDBC 实现完成标准 API 到 MySQL 协议的转换，常见的 JDBC 实现是 MySQL Connector/J，此外有些用户可能使用 MariaDB Connector/J。 数据库连接池：为了避免每次创建连接，通常应用会选择使用数据库连接池来复用连接，JDBC DataSource 定义了连接池 API，开发者可根据实际需求选择使用某种开源连接池实现。 数据访问框架：应用通常选择通过数据访问框架 (MyBatis, Hibernate) 的封装来进一步简化和管理数据库访问操作。 业务实现：业务逻辑控制着何时发送和发送什么指令到数据库，其中有些业务会使用 Spring Transaction 切面来控制管理事务的开始和提交逻辑。  如上图所示，应用可能使用 Spring Transaction 来管理控制事务非手工启停，通过类似 MyBatis 的数据访问框架管理生成和执行 SQL，通过连接池获取已池化的长连接，最后通过 JDBC 接口调用实现通过 MySQL 协议和 TiDB 完成交互。
接下来将分别介绍使用各个组件时可能需要关注的问题。</description>
    </item>
    
    <item>
      <title>恢复 GCS 上的备份数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/restore-gcs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/restore-gcs/</guid>
      <description>恢复 GCS 上的备份数据 本文描述了将 Kubernetes 上通过 TiDB Operator 备份的数据恢复到 TiDB 集群的操作过程。底层通过使用 loader 来进行集群恢复。
本文使用的恢复方式基于 TiDB Operator 新版（v1.1 及以上）的 CustomResourceDefinition (CRD) 实现。基于 Helm Charts 实现的备份和恢复方式可参考基于 Helm Charts 实现的 TiDB 集群备份与恢复。
以下示例将存储在 Google Cloud Storage (GCS) 上指定路径上的集群备份数据恢复到 TiDB 集群。
环境准备   下载文件 backup-rbac.yaml，并执行以下命令在 test2 这个 namespace 中创建恢复所需的 RBAC 相关资源：
 kubectl apply -f backup-rbac.yaml -n test2   创建 restore-demo2-tidb-secret secret，该 secret 存放用来访问 TiDB 集群的 root 账号和密钥：
 kubectl create secret generic restore-demo2-tidb-secret --from-literal=user=root --from-literal=password=&amp;lt;password&amp;gt; --namespace=test2   将指定备份数据恢复到 TiDB 集群   创建 restore custom resource (CR)，将指定的备份数据恢复至 TiDB 集群：</description>
    </item>
    
    <item>
      <title>恢复 Kubernetes 上的 TiDB 集群数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/lightning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/lightning/</guid>
      <description>使用 TiDB Lightning 快速恢复 Kubernetes 上的 TiDB 集群数据。</description>
    </item>
    
    <item>
      <title>恢复 S3 兼容存储上的备份数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/restore-s3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/backup-and-restore/restore-s3/</guid>
      <description>恢复 S3 兼容存储上的备份数据 本文描述了将 Kubernetes 上通过 TiDB Operator 备份的数据恢复到 TiDB 集群的操作过程。底层通过使用 loader 来恢复数据。
本文使用的恢复方式基于 TiDB Operator 新版（v1.1 及以上）的 CustomResourceDefinition (CRD) 实现。基于 Helm Charts 实现的备份和恢复方式可参考基于 Helm Charts 实现的 TiDB 集群备份恢复。
以下示例将兼容 S3 的存储（指定路径）上的备份数据恢复到 TiDB 集群。
环境准备   下载文件 backup-rbac.yaml，并在 test2 这个 namespace 中创建恢复所需的 RBAC 资源，所需命令如下：
 kubectl apply -f backup-rbac.yaml -n test2   创建 restore-demo2-tidb-secret secret，该 secret 存放用来访问 TiDB 集群的 root 账号和密钥：
 kubectl create secret generic restore-demo2-tidb-secret --from-literal=user=root --from-literal=password=&amp;lt;password&amp;gt; --namespace=test2   将指定备份数据恢复到 TiDB 集群   创建 restore custom resource (CR)，将指定的备份数据恢复至 TiDB 集群：</description>
    </item>
    
    <item>
      <title>慢查询日志</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/maintain/identify-abnormal-queries/identify-slow-queries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/maintain/identify-abnormal-queries/identify-slow-queries/</guid>
      <description>慢查询日志 TiDB 会将执行时间超过 slow-threshold（默认值为 300 毫秒）的语句输出到 slow-query-file（默认值：&amp;ldquo;tidb-slow.log&amp;rdquo;）日志文件中，用于帮助用户定位慢查询语句，分析和解决 SQL 执行的性能问题。
日志示例 # Time: 2019-08-14T09:26:59.487776265+08:00 # Txn_start_ts: 410450924122144769 # User: root@127.0.0.1 # Conn_ID: 3086 # Query_time: 1.527627037 # Parse_time: 0.000054933 # Compile_time: 0.000129729 # Process_time: 0.07 Request_count: 1 Total_keys: 131073 Process_keys: 131072 Prewrite_time: 0.335415029 Commit_time: 0.032175429 Get_commit_ts_time: 0.000177098 Local_latch_wait_time: 0.106869448 Write_keys: 131072 Write_size: 3538944 Prewrite_region: 1 # DB: test # Is_internal: false # Digest: 50a2e32d2abbd6c1764b1b7f2058d428ef2712b029282b776beb9506a365c0f1 # Stats: t:pseudo # Num_cop_tasks: 1 # Cop_proc_avg: 0.</description>
    </item>
    
    <item>
      <title>成为贡献者</title>
      <link>https://pingcap.com/docs-cn/v3.1/contribute/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/contribute/</guid>
      <description>成为贡献者 成为 TiDB 的贡献者 我们推荐您先尝试解决带 help-wanted 标签的现有 Issue，这些问题非常适合新的贡献者。
一旦您提交给 TiDB/TiKV/TiSpark/PD/TiDB Operator/Docs/Docs-cn 项目的 PR (Pull Request) 被批准且合并，您即成为 TiDB 的贡献者。
在提交 PR 之前，请先签署 CLA。
如果您想实践一个影响范围相对较小的新想法，请遵循以下步骤：
 提交新 Issue，描述您对相关仓库的更改建议。 相关仓库的负责人将及时回复您的 Issue。 如果您的更改建议被接受，您需要先签署 CLA，便可以在您的克隆仓库 (fork) 里开始工作了。 在测试过所做的更改后，您便可以提交包含更改的 PR 了。  我们欢迎并非常感谢您的贡献。有关提交补丁和贡献流程的详细信息，请参阅贡献者指南。
改进文档 我们欢迎更多贡献者来帮助改进文档！
TiDB 文档使用 Markdown 语言，并参考了 Google 开发者文档风格指南进行编写。如果这些概念对您来说比较陌生，请不要担心，我们很乐意为您提供指导。
如要对文档仓库进行贡献，请先 fork docs-cn 仓库，再提交您的 PR。</description>
    </item>
    
    <item>
      <title>手动处理 Sharding DDL Lock</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/manually-handling-sharding-ddl-locks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/manually-handling-sharding-ddl-locks/</guid>
      <description>手动处理 Sharding DDL Lock DM (Data Migration) 使用 sharding DDL lock 来确保分库分表的 DDL 操作可以正确执行。绝大多数情况下，该锁定机制可自动完成；但在部分异常情况发生时，需要使用 unlock-ddl-lock/break-ddl-lock 手动处理异常的 DDL lock。
 注意：
 不要轻易使用 unlock-ddl-lock/break-ddl-lock 命令，除非完全明确当前场景下使用这些命令可能会造成的影响，并能接受这些影响。 在手动处理异常的 DDL lock 前，请确保已经了解 DM 的分库分表合并同步原理。   命令介绍 show-ddl-locks 该命令用于查询当前 DM-master 上存在的 DDL lock 信息。
命令示例  show-ddl-locks [--worker=127.0.0.1:8262] [task-name] 参数解释   worker：
 flag 参数，string，--worker，可选 不指定时，查询所有 DM-worker 相关的 lock 信息；指定时，仅查询与这组 DM-worker 相关的 lock 信息，可重复多次指定    task-name：
 非 flag 参数，string，可选 不指定时，查询与所有任务相关的 lock 信息；指定时，仅查询特定任务相关的 lock 信息    返回结果示例  » show-ddl-locks test { &amp;#34;result&amp;#34;: true, # 查询 lock 操作本身是否成功 &amp;#34;msg&amp;#34;: &amp;#34;&amp;#34;, # 查询 lock 操作失败时的原因或其它描述信息（如不存在任务 lock） &amp;#34;locks&amp;#34;: [ # DM-master 上存在的 lock 信息列表 { &amp;#34;ID&amp;#34;: &amp;#34;test-`shard_db`.</description>
    </item>
    
    <item>
      <title>执行计划绑定</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/execution-plan-bind/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/execution-plan-bind/</guid>
      <description>执行计划绑定 在优化器 Hints 中介绍了可以通过 Hint 的方式选择指定的执行计划，但有的时候需要在不修改 SQL 语句的情况下干预执行计划的选择。执行计划绑定提供了一系列功能使得可以在不修改 SQL 语句的情况下选择指定的执行计划。
语法 创建绑定  CREATE [GLOBAL | SESSION] BINDING FOR SelectStmt USING SelectStmt; 该语句可以在 GLOBAL 或者 SESSION 作用域内为 SQL 绑定执行计划。在不指定作用域时，隐式作用域为 SESSION。被绑定的 SQL 会被参数化后存储到系统表中。在处理 SQL 查询时，只要参数化后的 SQL 和系统表中某个被绑定的 SQL 一致即可使用相应的优化器 Hint。
参数化：把 SQL 中的常量变成变量参数，并对 SQL 中的空格和换行符等做标准化处理。例如：
select * from t where a &amp;gt; 1 -- 参数化后： select * from t where a &amp;gt; ？ 需要注意的是原始 SQL 和绑定 SQL 在参数化以及去掉 Hint 后文本必须相同，否则创建会失败，例如：
 CREATE BINDING FOR SELECT * FROM t WHERE a &amp;gt; 1 USING SELECT * FROM t use index(idx) WHERE a &amp;gt; 2; 可以创建成功，因为原始 SQL 和绑定 SQL 在参数化以及去掉 Hint 后文本都是 select * from t where a &amp;gt; ?</description>
    </item>
    
    <item>
      <title>控制流程函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/control-flow-functions/</guid>
      <description>控制流程函数 TiDB 支持使用 MySQL 5.7 中提供的所有控制流程函数。
   函数名 功能描述     CASE Case 操作符   IF() 构建 if/else   IFNULL() 构建 Null if/else   NULLIF() 如果 expr1 = expr2，返回 NULL    </description>
    </item>
    
    <item>
      <title>提交 Issue</title>
      <link>https://pingcap.com/docs-cn/v3.1/report-issue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/report-issue/</guid>
      <description>提交 Issue 我们正在努力使 TiDB 与 MySQL 5.7 兼容。如果您发现了任何未记录在文档中的表现差异、bug 或奇怪的性能特征，请在 GitHub 中提交新的 Issue。
在 GitHub 上提交的新 Issue 分为以下几种：
 错误报告 (Bug Reports) 功能请求 (Feature Requests) 常规问题 (General Questions) 性能问题 (Performance Questions)  请确保您完全按照 Issue 模板进行填写，以便我们迅速定位问题并作出回应。</description>
    </item>
    
    <item>
      <title>操作符</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/operators/</guid>
      <description>操作符    操作符名 功能描述     AND, &amp;amp;&amp;amp; 逻辑与   = 赋值 (可用于 SET 语句中, 或用于 UPDATE 语句的 SET 中 )   := 赋值   BETWEEN ... AND ... 判断值满足范围   BINARY 将一个字符串转换为一个二进制字符串   &amp;amp; 位与   ~ 位非   \| 位或   ^ 按位异或   CASE case 操作符   DIV 整数除   / 除法   = 相等比较   &amp;lt;=&amp;gt; 空值安全型相等比较   &amp;gt; 大于   &amp;gt;= 大于或等于   IS 判断一个值是否等于一个布尔值   IS NOT 判断一个值是否不等于一个布尔值   IS NOT NULL 非空判断   IS NULL 空值判断   &amp;lt;&amp;lt; 左移   &amp;lt; 小于   &amp;lt;= 小于或等于   LIKE 简单模式匹配   - 减   %, MOD 求余   NOT, !</description>
    </item>
    
    <item>
      <title>支持资源</title>
      <link>https://pingcap.com/docs-cn/v3.1/support-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/support-resources/</guid>
      <description>支持资源 您可以通过以下任何一种方式找到我们的社区成员：
 Slack Channel: https://pingcap.com/tidbslack Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Reddit: https://www.reddit.com/r/TiDB GitHub: https://github.com/pingcap/tidb/issues  有关企业支持合作的信息，请联系我们。</description>
    </item>
    
    <item>
      <title>数值函数与操作符</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/numeric-functions-and-operators/</guid>
      <description>数值函数与操作符 TiDB 支持使用 MySQL 5.7 中提供的所有数值函数与操作符。
算术操作符    操作符名 功能描述     + 加号   - 减号   * 乘号   / 除号   DIV 整数除法   %, MOD 模运算，取余   - 更改参数符号    数学函数    函数名 功能描述     POW() 返回参数的指定乘方的结果值   POWER() 返回参数的指定乘方的结果值   EXP() 返回 e（自然对数的底）的指定乘方后的值   SQRT() 返回非负数的二次方根   LN() 返回参数的自然对数   LOG() 返回第一个参数的自然对数   LOG2() 返回参数以 2 为底的对数   LOG10() 返回参数以 10 为底的对数   PI() 返回 pi 的值   TAN() 返回参数的正切值   COT() 返回参数的余切值   SIN() 返回参数的正弦值   COS() 返回参数的余弦值   ATAN() 返回参数的反正切值   ATAN2(), ATAN() 返回两个参数的反正切值   ASIN() 返回参数的反正弦值   ACOS() 返回参数的反余弦值   RADIANS() 返回由度转化为弧度的参数   DEGREES() 返回由弧度转化为度的参数   MOD() 返回余数   ABS() 返回参数的绝对值   CEIL() 返回不小于参数的最小整数值   CEILING() 返回不小于参数的最小整数值   FLOOR() 返回不大于参数的最大整数值   ROUND() 返回参数最近似的整数或指定小数位数的数值   RAND() 返回一个随机浮点值   SIGN() 返回参数的符号   CONV() 不同数基间转换数字，返回数字的字符串表示   TRUNCATE() 返回被舍位至指定小数位数的数字   CRC32()  计算循环冗余码校验值并返回一个 32 位无符号值     </description>
    </item>
    
    <item>
      <title>数值类型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/numeric/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/numeric/</guid>
      <description>数值类型 TiDB 支持 MySQL 所有的数值类型，按照精度可以分为:
 整数类型（精确值) 浮点类型（近似值) 定点类型（精确值)  整数类型 TiDB 支持 MySQL 所有的整数类型，包括 INTEGER/INT、TINYINT、SMALLINT、MEDIUMINT 以及 BIGINT，完整信息参考这篇文档。
字段说明：
   语法元素 说明     M 类型显示宽度，可选   UNSIGNED 无符号数，如果不加这个标识，则为有符号数   ZEROFILL 补零标识，如果有这个标识，TiDB 会自动给类型增加 UNSIGNED 标识，但是没有做补零的操作    类型定义 BIT 类型 比特值类型。M 表示比特位的长度，取值范围从1到64，其默认值是1。
 BIT[(M)] BOOLEAN 类型 布尔类型，别名为 BOOL，和 TINYINT(1) 等价。零值被认为是 False，非零值认为是 True。在 TiDB 内部，True 存储为 1，False 存储为 0。
 BOOLEAN TINYINT 类型 TINYINT 类型。有符号数的范围是 [-128, 127]。无符号数的范围是 [0, 255]。</description>
    </item>
    
    <item>
      <title>数据同步功能</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/features/overview/</guid>
      <description>DM 提供的功能及其配置介绍</description>
    </item>
    
    <item>
      <title>数据类型概述</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/overview/</guid>
      <description>数据类型概述 TiDB 支持除空间类型 (SPATIAL) 之外的所有 MySQL 数据类型，包括数值型类型、字符串类型、时间和日期类型、JSON 类型。
数据类型定义一般为 T(M[, D])，其中：
 T 表示具体的类型。 M 在整数类型中表示最大显示长度；在浮点数或者定点数中表示精度；在字符类型中表示最大长度。M 的最大值取决于具体的类型。 D 表示浮点数、定点数的小数位长度。 fsp 在时间和日期类型里的 TIME、DATETIME 以及 TIMESTAMP 中表示秒的精度，其取值范围是 0 到 6。值为 0 表示没有小数部分。如果省略，则默认精度为 0。  </description>
    </item>
    
    <item>
      <title>数据类型的默认值</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/default-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/default-values/</guid>
      <description>数据类型的默认值 在一个数据类型描述中的 DEFAULT value 段描述了一个列的默认值。这个默认值必须是常量，不可以是一个函数或者是表达式。但是对于时间类型，可以例外的使用 NOW、CURRENT_TIMESTAMP、LOCALTIME、LOCALTIMESTAMP 等函数作为 DATETIME 或者 TIMESTAMP 的默认值。
BLOB、TEXT 以及 JSON 不可以设置默认值。
如果一个列的定义中没有 DEFAULT 的设置。TiDB 按照如下的规则决定:
 如果该类型可以使用 NULL 作为值，那么这个列会在定义时添加隐式的默认值设置 DEFAULT NULL。 如果该类型无法使用 NULL 作为值，那么这个列在定义时不会添加隐式的默认值设置。  对于一个设置了 NOT NULL 但是没有显式设置 DEFAULT 的列，当 INSERT、REPLACE 没有涉及到该列的值时，TiDB 根据当时的 SQL_MODE 进行不同的行为：
 如果此时是 strict sql mode，在事务中的语句会导致事务失败并回滚，非事务中的语句会直接报错。 如果此时不是 strict sql mode，TiDB 会为这列赋值为列数据类型的隐式默认值。  此时隐式默认值的设置按照如下规则：
 对于数值类型，它们的默认值是 0。当有 AUTO_INCREMENT 参数时，默认值会按照增量情况赋予正确的值。 对于除了时间戳外的日期时间类型，默认值会是该类型的“零值”。时间戳类型的默认值会是当前的时间。 对于除枚举以外的字符串类型，默认值会是空字符串。对于枚举类型，默认值是枚举中的第一个值。  </description>
    </item>
    
    <item>
      <title>日志收集</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/log-collecting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/log-collecting/</guid>
      <description>日志收集 系统与程序的运行日志对排查问题以及实现一些自动化操作可能非常有用。本文将简要说明收集 TiDB 及相关组件日志的方法。
TiDB 与 Kubernetes 组件运行日志 通过 TiDB Operator 部署的 TiDB 各组件默认将日志输出在容器的 stdout 和 stderr 中。对于 Kubernetes 而言，这些日志会被存放在宿主机的 /var/log/containers 目录下，并且文件名中包含了 Pod 和容器名称等信息。因此，对容器中应用的日志收集可以直接在宿主机上完成。
如果在你的现有基础设施中已经有用于收集日志的系统，只需要通过常规方法将 Kubernetes 所在的宿主机上的 /var/log/containers/*.log 文件加入采集范围即可；如果没有可用的日志收集系统，或者希望部署一套独立的系统用于收集相关日志，也可以使用你熟悉的任意日志收集系统或方案。
Kubernetes 官方文档中提供了 ElasticSearch 和 Stackdriver 两种日志收集方案可供参考。
常见的可用于收集 Kubernetes 日志的开源工具有：
 Fluentd Fluent-bit Filebeat Logstash  收集到的日志通常可以汇总存储在某一特定的服务器上，或存放到 ElasticSearch 等专用的存储、分析系统当中。
一些云服务商或专门的性能监控服务提供商也有各自的免费或收费的日志收集方案可以选择。
如果不通过单独的日志收集工具汇总日志，你也可以直接使用 kubectl 工具查看某个容器的运行日志，但这一方法无法查看已销毁容器的日志：
 kubectl logs -n &amp;lt;namespace&amp;gt; &amp;lt;tidbPodName&amp;gt; 若需查看容器重启之前的日志，可以在执行上述命令时添加 -p 参数。
如果需要从多个 Pod 获取日志，可以使用 stern：
 stern -n &amp;lt;namespace&amp;gt; tidb -c slowlog TiDB 慢查询日志 对于 3.</description>
    </item>
    
    <item>
      <title>日期和时间函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/date-and-time-functions/</guid>
      <description>日期和时间函数 TiDB 支持使用 MySQL 5.7 中提供的所有日期和时间函数。
日期时间函数表    函数名 功能描述     ADDDATE() 将时间间隔添加到日期上   ADDTIME() 时间数值相加   CONVERT_TZ() 转换时区   CURDATE() 返回当前日期   CURRENT_DATE(), CURRENT_DATE 与 CURDATE() 同义   CURRENT_TIME(), CURRENT_TIME 与 CURTIME() 同义   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP 与 NOW() 同义   CURTIME() 返回当前时间   DATE() 从日期或日期/时间表达式中提取日期部分   DATE_ADD() 将时间间隔添加到日期上   DATE_FORMAT() 返回满足指定格式的日期/时间   DATE_SUB() 从日期减去指定的时间间隔   DATEDIFF() 返回两个日期间隔的天数   DAY() 与 DAYOFMONTH() 同义   DAYNAME() 返回星期名称   DAYOFMONTH() 返回参数对应的天数部分(1-31)   DAYOFWEEK() 返回参数对应的星期下标   DAYOFYEAR() 返回参数代表一年的哪一天 (1-366)   EXTRACT() 提取日期/时间中的单独部分   FROM_DAYS() 将天数转化为日期   FROM_UNIXTIME() 将 Unix 时间戳格式化为日期   GET_FORMAT() 返回满足日期格式的字符串   HOUR() 提取日期/时间表达式中的小时部分   LAST_DAY 返回参数中月份的最后一天   LOCALTIME(), LOCALTIME 与 NOW() 同义   LOCALTIMESTAMP, LOCALTIMESTAMP() 与 NOW() 同义   MAKEDATE() 根据给定的年份和一年中的天数生成一个日期   MAKETIME() 根据给定的时、分、秒生成一个时间   MICROSECOND() 返回参数的微秒部分   MINUTE() 返回参数的分钟部分   MONTH() 返回参数的月份部分   MONTHNAME() 返回参数的月份名称   NOW() 返回当前日期和时间   PERIOD_ADD() 在年-月表达式上添加一段时间(数个月)   PERIOD_DIFF() 返回间隔的月数   QUARTER() 返回参数对应的季度(1-4)   SEC_TO_TIME() 将秒数转化为 &amp;lsquo;HH:MM:SS&amp;rsquo; 的格式   SECOND() 返回秒数(0-59)   STR_TO_DATE() 将字符串转化为日期   SUBDATE() 当传入三个参数时作为 DATE_SUB() 的同义   SUBTIME() 从一个时间中减去一段时间   SYSDATE() 返回该方法执行时的时间   TIME() 返回参数的时间表达式部分   TIME_FORMAT() 格式化时间   TIME_TO_SEC() 返回参数对应的秒数   TIMEDIFF() 返回时间间隔   TIMESTAMP() 传入一个参数时候,该方法返回日期或日期/时间表达式, 传入两个参数时候, 返回参数的和   TIMESTAMPADD() 在日期/时间表达式上增加一段时间间隔   TIMESTAMPDIFF() 从日期/时间表达式中减去一段时间间隔   TO_DAYS() 将参数转化对应的天数(从第 0 年开始)   TO_SECONDS() 将日期或日期/时间参数转化为秒数(从第 0 年开始)   UNIX_TIMESTAMP() 返回一个 Unix 时间戳   UTC_DATE() 返回当前的 UTC 日期   UTC_TIME() 返回当前的 UTC 时间   UTC_TIMESTAMP() 返回当前的 UTC 日期和时间   WEEK() 返回参数所在的一年中的星期数   WEEKDAY() 返回星期下标   WEEKOFYEAR() 返回参数在日历中对应的一年中的星期数   YEAR() 返回参数对应的年数   YEARWEEK() 返回年数和星期数    </description>
    </item>
    
    <item>
      <title>日期和时间类型</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/date-and-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/data-types/date-and-time/</guid>
      <description>日期和时间类型 TiDB 支持 MySQL 所有的日期和时间类型，包括 DATE、DATETIME、TIMESTAMP、TIME 以及 YEAR，完整信息参考这篇文档。
类型定义 DATE 类型 DATE 类型的格式为 YYYY-MM-DD，支持的范围是 1000-01-01 到 9999-12-31。
 DATE TIME 类型 TIME 类型的格式为 HH:MM:SS[.fraction]，支持的范围是 -838:59:59.000000 到 838:59:59.000000。TIME 不仅可用于指示一天内的时间，还可用于指两个事件之间的时间间隔。fsp 参数表示秒精度，取值范围为：0 ~ 6，默认值为 0。
 TIME[(fsp)]  注意：
注意 TIME 的缩写形式。例如，&amp;lsquo;11:12&amp;rsquo; 表示 &amp;lsquo;11:12:00&amp;rsquo; 而不是 &amp;lsquo;00:11:12&amp;rsquo;。但是，&amp;lsquo;1112&amp;rsquo; 表示 &amp;lsquo;00:11:12&amp;rsquo;。这些差异取决于 : 字符的存在与否。
 DATETIME 类型 DATETIME 类型是日期和时间的组合，格式为 YYYY-MM-DD HH:MM:SS[.fraction]。支持的范围是 1000-01-01 00:00:00.000000 到 9999-12-31 23:59:59.000000。fsp 参数表示秒精度，取值范围为 0~6，默认值为 0。
 DATETIME[(fsp)] TIMESTAMP 类型 TIMESTAMP 类型包含日期和时间，支持的范围是 1970-01-01 00:00:01.000000 到 2038-01-19 03:14:07.</description>
    </item>
    
    <item>
      <title>时区支持</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/configure/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/configure/time-zone/</guid>
      <description>时区支持 TiDB 使用的时区由 time_zone 全局变量和 session 变量决定。time_zone 的默认值是 System，System 对应的实际时区在 TiDB 集群 bootstrap 初始化时设置。具体逻辑如下:
 优先使用 TZ 环境变量 如果失败，则从 /etc/localtime 的实际软链地址提取。 如果上面两种都失败则使用 UTC 作为系统时区。  在运行过程中可以修改全局时区：
 SET GLOBAL time_zone = timezone; TiDB 还可以通过设置 session 变量 time_zone 为每个连接维护各自的时区。默认条件下，这个值取的是全局变量 time_zone 的值。修改 session 使用的时区：
 SET time_zone = timezone; 查看当前使用的时区的值：
 SELECT @@global.time_zone, @@session.time_zone; 设置 time_zone 的值的格式：
 &amp;lsquo;SYSTEM&amp;rsquo; 表明使用系统时间 相对于 UTC 时间的偏移，比如 &amp;lsquo;+10:00&amp;rsquo; 或者 &amp;lsquo;-6:00&amp;rsquo; 某个时区的名字，比如 &amp;lsquo;Europe/Helsinki&amp;rsquo;， &amp;lsquo;US/Eastern&amp;rsquo; 或 &amp;lsquo;MET&amp;rsquo;  NOW() 和 CURTIME() 的返回值都受到时区设置的影响。</description>
    </item>
    
    <item>
      <title>术语表</title>
      <link>https://pingcap.com/docs-cn/v3.1/glossary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/glossary/</guid>
      <description>了解 TiDB 相关术语。</description>
    </item>
    
    <item>
      <title>权限管理</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/security/privilege-system/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/security/privilege-system/</guid>
      <description>权限管理 TiDB 的权限管理系统按照 MySQL 的权限管理进行实现，TiDB 支持大部分的 MySQL 的语法和权限类型。
本文档主要介绍 TiDB 权限相关操作、各项操作需要的权限以及权限系统的实现。
权限相关操作 授予权限 授予 xxx 用户对数据库 test 的读权限：
 GRANT SELECT ON test.* TO &amp;#39;xxx&amp;#39;@&amp;#39;%&amp;#39;; 为 xxx 用户授予所有数据库，全部权限：
 GRANT ALL PRIVILEGES ON *.* TO &amp;#39;xxx&amp;#39;@&amp;#39;%&amp;#39;; GRANT 为一个不存在的用户授予权限时，默认并不会自动创建用户。该行为受 SQL Mode 中的 NO_AUTO_CREATE_USER 控制。 如果从 SQL Mode 中去掉 NO_AUTO_CREATE_USER，当 GRANT 的目标用户不存在时，TiDB 会自动创建用户。
 mysql&amp;gt; select @@sql_mode; | @@sql_mode | +-------------------------------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION | +-------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec)  set @@sql_mode=&amp;#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION&amp;#39;; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>注释语法</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/comment-syntax/</guid>
      <description>注释语法 TiDB 支持三种注释风格：
 用 # 注释一行 用 -- 注释一行，用 -- 注释必须要在其之后留出至少一个空格。 用 /* */ 注释一块，可以注释多行。  例：
 SELECT 1+1; # 注释文字 +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec)  SELECT 1+1; -- 注释文字 +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec)  SELECT 1 /*这是行内注释文字 */ + 1; +--------+ | 1 + 1 | +--------+ | 2 | +--------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>海量 Region 集群调优最佳实践</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/best-practices/massive-regions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/best-practices/massive-regions/</guid>
      <description>了解海量 Region 导致性能问题的原因和优化方法。</description>
    </item>
    
    <item>
      <title>滚动升级 Kubernetes 上的 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/upgrade/tidb-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/upgrade/tidb-cluster/</guid>
      <description>滚动升级 Kubernetes 上的 TiDB 集群 滚动更新 TiDB 集群时，会按 PD、TiKV、TiDB 的顺序，串行删除 Pod，并创建新版本的 Pod，当新版本的 Pod 正常运行后，再处理下一个 Pod。
滚动升级过程会自动处理 PD、TiKV 的 Leader 迁移与 TiDB 的 DDL Owner 迁移。因此，在多节点的部署拓扑下（最小环境：PD * 3、TiKV * 3、TiDB * 2），滚动更新 TiKV、PD 不会影响业务正常运行。
对于有连接重试功能的客户端，滚动更新 TiDB 同样不会影响业务。对于无法进行重试的客户端，滚动更新 TiDB 则会导致连接到被关闭节点的数据库连接失效，造成部分业务请求失败。对于这类业务，推荐在客户端添加重试功能或在低峰期进行 TiDB 的滚动升级操作。
滚动更新可以用于升级 TiDB 版本，也可以用于更新集群配置。
升级 TiDB 版本   修改集群的 values.yaml 文件中的 tidb.image、tikv.image、pd.image 的值为新版本镜像；
  执行 helm upgrade 命令进行升级：
 helm upgrade &amp;lt;release-name&amp;gt; pingcap/tidb-cluster -f values.yaml --version=&amp;lt;chart-version&amp;gt;   查看升级进度：</description>
    </item>
    
    <item>
      <title>理解 TiDB 执行计划</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/understanding-the-query-execution-plan/</guid>
      <description>理解 TiDB 执行计划 TiDB 优化器会根据当前数据表的实际情况来选择最优的执行计划，执行计划由一系列的算子构成。本文将详细解释 TiDB 中 EXPLAIN 语句返回的执行计划信息。
使用 EXPLAIN 来优化 SQL 语句 EXPLAIN 语句的返回结果提供了 TiDB 执行 SQL 查询的详细信息：
 EXPLAIN 可以和 SELECT，DELETE 语句一起使用； 执行 EXPLAIN，TiDB 会返回被 EXPLAIN 的 SQL 语句经过优化器后的最终物理执行计划。也就是说，EXPLAIN 展示了 TiDB 执行该 SQL 语句的完整信息，比如以什么样的顺序，什么方式 JOIN 两个表，表达式树长什么样等等。详见 EXPLAIN 输出格式； TiDB 支持 EXPLAIN [options] FOR CONNECTION connection_id，但与 MySQL 的 EXPLAIN FOR 有一些区别，请参见 EXPLAIN FOR CONNECTION。  通过观察 EXPLAIN 的结果，你可以知道如何给数据表添加索引使得执行计划使用索引从而加速 SQL 语句的执行速度；你也可以使用 EXPLAIN 来检查优化器是否选择了最优的顺序来 JOIN 数据表。
EXPLAIN 输出格式 目前 TiDB 的 EXPLAIN 会输出 4 列，分别是：id，count，task，operator info。执行计划中每个算子都由这 4 列属性来描述，EXPLAIN 结果中每一行描述一个算子。每个属性的具体含义如下：</description>
    </item>
    
    <item>
      <title>生成列</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/generated-columns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/generated-columns/</guid>
      <description>生成列 为了在功能上兼容 MySQL 5.7，TiDB 支持生成列 (generated column)。生成列的主要的作用之一：从 JSON 数据类型中解出数据，并为该数据建立索引。
使用 generated column 对 JSON 建索引 MySQL 5.7 及 TiDB 都不能直接为 JSON 类型的列添加索引，即不支持如下表结构：
 CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON, KEY (address_info) ); 为 JSON 列添加索引之前，首先必须抽取该列为 generated column。
以 city generated stored column 为例，你可以添加索引：
 CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON, city VARCHAR(64) AS (JSON_UNQUOTE(JSON_EXTRACT(address_info, &amp;#39;$.</description>
    </item>
    
    <item>
      <title>生成自签名证书</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/secure/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/secure/generate-self-signed-certificates/</guid>
      <description>生成自签名证书 概述 本文档提供使用 cfssl 生成自签名证书的示例。
假设实例集群拓扑如下：
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    下载 cfssl 假设使用 x86_64 Linux 主机：
 mkdir ~/bin &amp;amp;&amp;amp; curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 &amp;amp;&amp;amp; curl -s -L -o ~/bin/cfssljson https://pkg.</description>
    </item>
    
    <item>
      <title>用户自定义变量</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/user-defined-variables/</guid>
      <description>用户自定义变量 用户自定义变量格式为 @var_name。var_name 目前只支持字母，数字，_$组成。用户自定义变量是大小写不敏感的。
用户自定义变量是跟 session 绑定的，也就是说只有当前连接可以看见设置的用户变量，其他客户端连接无法查看到。
用 SET 语句可以设置用户自定义变量：
 SET @var_name = expr [, @var_name = expr] ...; 或
 SET @var_name := expr; 对于 SET 语句，赋值操作符可以是 = 也可以是 :=
例：
 SET @a1=1, @a2=2, @a3:=4;  SELECT @a1, @a2, @t3, @a4 := @a1+@a2+@a3; +------+------+------+--------------------+ | @a1 | @a2 | @a3 | @a4 := @a1+@a2+@a3 | +------+------+------+--------------------+ | 1 | 2 | 4 | 7 | +------+------+------+--------------------+ 如果设置用户变量用了 HEX 或者 BIT 值，TiDB会把它当成二进制字符串。如果你要将其设置成数字，那么需要手动加上 CAST转换: CAST(.</description>
    </item>
    
    <item>
      <title>离线 TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/offline-ansible/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/orchestrated/offline-ansible/</guid>
      <description>离线 TiDB Ansible 部署方案 准备机器   下载机一台
 该机器需开放外网访问，用于下载 TiDB Ansible、TiDB 及相关软件安装包。 推荐安装 CentOS 7.3 及以上版本 Linux 操作系统。    部署目标机器若干及部署中控机一台
 系统要求及配置参考准备机器。 可以无法访问外网。    在中控机上安装系统依赖包   在下载机上下载系统依赖离线安装包，然后上传至中控机。该离线包仅支持 CentOS 7 系统，包含 pip 及 sshpass。
  在中控机上安装系统依赖包：
 tar -xzvf ansible-system-rpms.el7.tar.gz &amp;amp;&amp;amp; cd ansible-system-rpms.el7 &amp;amp;&amp;amp; chmod u+x install_ansible_system_rpms.sh &amp;amp;&amp;amp; ./install_ansible_system_rpms.sh   安装完成后，可通过 pip -V 验证 pip 是否安装成功：
 pip -V pip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.</description>
    </item>
    
    <item>
      <title>窗口函数</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/window-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/window-functions/</guid>
      <description>窗口函数 TiDB 中窗口函数的使用方法与 MySQL 8.0 基本一致，详情可参见 MySQL 窗口函数。由于窗口函数会使用一些保留关键字，可能导致原先可以正常执行的 SQL 语句在升级 TiDB 后无法被解析语法，此时可以将 tidb_enable_window_function 设置为 0，该参数的默认值为 1。
TiDB 支持的窗口函数如下所示：
   函数名 功能描述     CUME_DIST() 返回一组值中的累积分布   DENSE_RANK() 返回分区中当前行的排名，并且排名是连续的   FIRST_VALUE() 当前窗口中第一行的表达式值   LAG() 分区中当前行前面第 N 行的表达式值   LAST_VALUE() 当前窗口中最后一行的表达式值   LEAD() 分区中当前行后面第 N 行的表达式值   NTH_VALUE() 当前窗口中第 N 行的表达式值   NTILE() 将分区划分为 N 桶，为分区中的每一行分配桶号   PERCENT_RANK() 返回分区中小于当前行的百分比   RANK() 返回分区中当前行的排名，排名可能不连续   ROW_NUMBER() 返回分区中当前行的编号    </description>
    </item>
    
    <item>
      <title>管理数据同步任务</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/manage-tasks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/manage-tasks/</guid>
      <description>管理数据同步任务 本文介绍了如何使用 dmctl 组件来进行数据同步任务的管理和维护。对于用 DM-Ansible 部署的 DM 集群，dmctl 二进制文件路径为 dm-ansible/dmctl。
dmctl 支持交互模式用于人工操作，同时也支持命令模式用于脚本。
dmctl 交互模式 本部分描述了在交互模式下一些 dmctl 命令的基本用法。
dmctl 使用帮助  ./dmctl --help Usage of dmctl: -V prints version and exit -config string path to config file # 按照 DM 提供的加密方法加密数据库密码，用于 DM 的配置文件 -encrypt string encrypt plaintext to ciphertext # DM-master 访问地址，dmctl 与 DM-master 交互以完成任务管理操作 -master-addr string master API server addr -rpc-timeout string rpc timeout, default is 10m (default &amp;#34;10m&amp;#34;) 加密数据库密码 在 DM 相关配置文件中，要求必须使用经 dmctl 加密后的密码，否则会报错。对于同一个原始密码，每次加密后密码不同。</description>
    </item>
    
    <item>
      <title>精度数学</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/precision-math/</guid>
      <description>精度数学 TiDB 中精度数学计算与 MySQL 中基本一致, 详情请参见: Precision Math.
 数值类型 DECIMAL 数据类型的特性  数值类型 精确数值运算的范围包括精确值数据类型(整型和 DECIMAL 类型), 以及精确值数字字面量. 近似值数据类型和近似值数字字面量被作为浮点数来处理.
精确值数字字面量包含整数部分或小数部分, 或二者都包含. 精确值数字字面量可以包含符号位. 例如: 1, .2, 3.4, -5, -6.78, +9.10.
近似值数字字面量以一个包含尾数和指数的科学计数法表示(基数为 10). 其中尾数和指数可以分别或同时带有符号位. 例如: 1.2E3, 1.2E-3, -1.2E3, -1.2E-3.
两个看起来相似的数字可能会被以不同的方式进行处理. 例如, 2.34 是精确值(定点数), 而 2.3E0 是近似值(浮点数).
DECIMAL 数据类型是定点数类型, 其运算是精确计算. FLOAT 和 DOUBLE 数据类型是浮点类型, 其运算是近似计算.
DECIMAL 数据类型的特性 本节讨论 DECIMAL 数据类型的特性, 主要涉及以下几点:
 最大位数 存储格式 存储要求  DECIMAL 列的声明语法为 DECIMAL(M, D). 其中参数值意义及其范围如下:
 M 表示最大的数字位数 (精度).</description>
    </item>
    
    <item>
      <title>系统变量</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/mysql-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/configuration/tidb-server/mysql-variables/</guid>
      <description>系统变量 MySQL 系统变量 (System Variables) 是一些系统参数，用于调整数据库运行时的行为，根据变量的作用范围分为全局范围有效（Global Scope）以及会话级别有效（Session Scope）。TiDB 支持 MySQL5.7 的所有系统变量，大部分变量仅仅是为了兼容性而支持，不会影响运行时行为。
设置系统变量 通过 SET 语句 可以修改系统变量的值。进行修改时，还要考虑变量可修改的范围，不是所有的变量都能在全局/会话范围内进行修改。具体的可修改范围参考 MySQL 动态变量文档。
全局范围值   在变量名前加 GLOBAL 关键词或者是使用 @@global. 作为修饰符:
 SET GLOBAL autocommit = 1;  SET @@global.autocommit = 1;    注意：
在分布式 TiDB 中，GLOBAL 变量的设置会持久化到存储层中，单个 TiDB 实例每 2 秒会主动进行一次全变量的获取并形成 gvc (global variables cache) 缓存，该缓存有效时间最多可持续 2 秒。在设置 GLOBAL 变量之后，为了保证新会话的有效性，请确保两个操作之间的间隔大于 2 秒。相关细节可以查看 Issue #14531。
 会话范围值   在变量名前加 SESSION 关键词或者是使用 @@session. 作为修饰符，或者是不加任何修饰符:</description>
    </item>
    
    <item>
      <title>约束</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/constraints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/constraints/</guid>
      <description>约束 TiDB 支持的基本约束与 MySQL 的基本相同，但有以下区别：
  默认对唯一约束进行惰性检查。通过在事务提交时再进行批量检查，TiDB 能够减少网络开销、提升性能。您可通过设置 tidb_constraint_check_in_place 为 TRUE 改变此行为。
  TiDB 支持创建外键约束，但不会在 DML 语句中对外键进行约束（即外键约束不生效）。
  外键约束 目前，TiDB 支持创建外键。例如：
CREATE TABLE users ( id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, doc JSON ); CREATE TABLE orders ( id INT NOT NULL PRIMARY KEY AUTO_INCREMENT, user_id INT NOT NULL, doc JSON, FOREIGN KEY fk_user_id (user_id) REFERENCES users(id) );  SELECT table_name, column_name, constraint_name, referenced_table_name, referenced_column_name FROM information_schema.</description>
    </item>
    
    <item>
      <title>线上负载与 `ADD INDEX` 相互影响测试</title>
      <link>https://pingcap.com/docs-cn/v3.1/benchmark/add-index-with-load/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/benchmark/add-index-with-load/</guid>
      <description>线上负载与 ADD INDEX 相互影响测试 测试目的 测试 OLTP 场景下，ADD INDEX 与线上负载的相互影响。
测试版本、时间、地点 TiDB 版本：v3.0.1
时间：2019 年 7 月
地点：北京
测试环境 测试在 Kubernetes 集群上进行，部署了 3 个 TiDB 实例，3 个 TiKV 实例和 3 个 PD 实例。
版本信息    组件 GitHash     TiDB 9e4e8da3c58c65123db5f26409759fe1847529f8   TiKV 4151dc8878985df191b47851d67ca21365396133   PD 811ce0b9a1335d1b2a049fd97ef9e186f1c9efc1    Sysbench 版本：1.0.17
TiDB 参数配置 TiDB、TiKV 和 PD 均使用 TiDB Operator 默认配置。
集群拓扑    机器 IP 部署实例     172.</description>
    </item>
    
    <item>
      <title>统计信息简介</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/performance/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/performance/statistics/</guid>
      <description>统计信息简介 TiDB 优化器会根据统计信息来选择最优的执行计划。统计信息收集了表级别和列级别的信息，表的统计信息包括总行数和修改的行数。列的统计信息包括不同值的数量、NULL 的数量、直方图、列上出现次数最多的值 TOPN 以及该列的 Count-Min Sketch 信息。
统计信息的收集 手动收集 可以通过执行 ANALYZE 语句来收集统计信息。
全量收集  注意：
在 TiDB 中执行 ANALYZE TABLE 语句比在 MySQL 或 InnoDB 中耗时更长。InnoDB 采样的只是少量页面，但 TiDB 会完全重构一系列统计信息。适用于 MySQL 的脚本会误以为执行 ANALYZE TABLE 耗时较短。
如需更快的分析速度，可将 tidb_enable_fast_analyze 设置为 1 来打开快速分析功能。该参数的默认值为 0。
快速分析功能开启后，TiDB 会随机采样约 10000 行的数据来构建统计信息。因此在数据分布不均匀或者数据量比较少的情况下，统计信息的准确度会比较差。可能导致执行计划不优，比如选错索引。如果可以接受普通 ANALYZE 语句的执行时间，则推荐关闭快速分析功能。
 可以通过以下几种语法进行全量收集。
收集 TableNameList 中所有表的统计信息：
 ANALYZE TABLE TableNameList [WITH NUM BUCKETS]; WITH NUM BUCKETS 可以用来指定生成直方图的桶数量上限。
收集 TableName 中所有的 IndexNameList 中的索引列的统计信息：
 ANALYZE TABLE TableName INDEX [IndexNameList] [WITH NUM BUCKETS]; IndexNameList 为空时会收集所有索引列的统计信息。</description>
    </item>
    
    <item>
      <title>维护 TiDB 集群所在的 Kubernetes 节点</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/kubernetes-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/kubernetes-node/</guid>
      <description>维护 TiDB 集群所在的 Kubernetes 节点 TiDB 是高可用数据库，可以在部分数据库节点下线的情况下正常运行，因此，我们可以安全地对底层 Kubernetes 节点进行停机维护。在具体操作时，针对 PD、TiKV 和 TiDB 实例的不同特性，我们需要采取不同的操作策略。
本文档将详细介绍如何对 Kubernetes 节点进行临时或长期的维护操作。
环境准备：
 kubectl tkctl jq   注意：
长期维护节点前，需要保证 Kubernetes 集群的剩余资源足够运行 TiDB 集群。
 维护 PD 和 TiDB 实例所在节点 PD 和 TiDB 实例的迁移较快，可以采取主动驱逐实例到其它节点上的策略进行节点维护：
  检查待维护节点上是否有 TiKV 实例：
 kubectl get pod --all-namespaces -o wide | grep &amp;lt;node-name&amp;gt; 假如存在 TiKV 实例，请参考维护 TiKV 实例所在节点。
  使用 kubectl cordon 命令防止新的 Pod 调度到待维护节点上：
 kubectl cordon &amp;lt;node-name&amp;gt;   使用 kubectl drain 命令将待维护节点上的数据库实例迁移到其它节点上：</description>
    </item>
    
    <item>
      <title>表达式求值的类型转换</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/type-conversion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/functions-and-operators/type-conversion/</guid>
      <description>表达式求值的类型转换 TiDB 中表达式求值的类型转换与 MySQL 基本一致，详情参见 MySQL 表达式求值的类型转换。</description>
    </item>
    
    <item>
      <title>表达式语法</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/language-structure/expression-syntax/</guid>
      <description>表达式语法 (Expression Syntax) 在 TiDB 中，以下规则是表达式的语法，你可以在 parser/parser.y 中找到定义。TiDB 的语法解析是基于 yacc 的。
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>视图</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/sql/view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/sql/view/</guid>
      <description>视图 TiDB 支持视图，视图是一张虚拟表，该虚拟表的结构由创建视图时的 SELECT 语句定义。使用视图一方面可以对用户只暴露安全的字段及数据，进而保证底层表的敏感字段及数据的安全。另一方面，将频繁出现的复杂查询定义为视图，可以使复杂查询更加简单便捷。
查询视图 查询一个视图和查询一张普通表类似。但是 TiDB 在真正执行查询视图时，会将视图展开成创建视图时定义的 SELECT 语句，进而执行展开后的查询语句。
样例 以下例子将创建一个视图，并在该视图上进行查询，最后删除该视图。
 create table t(a int, b int); Query OK, 0 rows affected (0.01 sec)  insert into t values(1, 1),(2,2),(3,3); Query OK, 3 rows affected (0.00 sec) Records: 3 Duplicates: 0 Warnings: 0  create table s(a int); Query OK, 0 rows affected (0.01 sec)  insert into s values(2),(3); Query OK, 2 rows affected (0.01 sec) Records: 2 Duplicates: 0 Warnings: 0  create view v as select s.</description>
    </item>
    
    <item>
      <title>访问 Kubernetes 上的 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/access-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/deploy/access-tidb/</guid>
      <description>访问 Kubernetes 上的 TiDB 集群 在 Kubernetes 集群内访问 TiDB 时，使用 TiDB service 域名 &amp;lt;release-name&amp;gt;-tidb.&amp;lt;namespace&amp;gt; 即可。若需要在集群外访问，则需将 TiDB 服务端口暴露出去。在 tidb-cluster Helm chart 中，通过 values.yaml 文件中的 tidb.service 字段进行配置：
 tidb: service: type: NodePort # externalTrafficPolicy: Cluster # annotations: # cloud.google.com/load-balancer-type: Internal NodePort 在没有 LoadBalancer 时，可选择通过 NodePort 暴露。NodePort 有两种模式：
  externalTrafficPolicy=Cluster：集群所有的机器都会给 TiDB 分配 TCP 端口，此为默认值
使用 Cluster 模式时，可以通过任意一台机器的 IP 加同一个端口访问 TiDB 服务，如果该机器上没有 TiDB Pod，则相应请求会转发到有 TiDB Pod 的机器上。
 注意：
该模式下 TiDB 服务获取到的请求源 IP 是主机 IP，并不是真正的客户端源 IP，所以基于客户端源 IP 的访问权限控制在该模式下不可用。</description>
    </item>
    
    <item>
      <title>读取历史数据</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/get-started/read-historical-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/get-started/read-historical-data/</guid>
      <description>读取历史数据 本文档介绍 TiDB 如何读取历史版本数据，包括具体的操作流程以及历史数据的保存策略。
功能说明 TiDB 实现了通过标准 SQL 接口读取历史数据功能，无需特殊的 client 或者 driver。当数据被更新、删除后，依然可以通过 SQL 接口将更新/删除前的数据读取出来。
另外即使在更新数据之后，表结构发生了变化，TiDB 依旧能用旧的表结构将数据读取出来。
操作流程 为支持读取历史版本数据， 引入了一个新的 system variable: tidb_snapshot ，这个变量是 Session 范围有效，可以通过标准的 Set 语句修改其值。其值为文本，能够存储 TSO 和日期时间。TSO 即是全局授时的时间戳，是从 PD 端获取的; 日期时间的格式可以为： “2016-10-08 16:45:26.999”，一般来说可以只写到秒，比如”2016-10-08 16:45:26”。 当这个变量被设置时，TiDB 会用这个时间戳建立 Snapshot（没有开销，只是创建数据结构），随后所有的 Select 操作都会在这个 Snapshot 上读取数据。
 注意：
TiDB 的事务是通过 PD 进行全局授时，所以存储的数据版本也是以 PD 所授时间戳作为版本号。在生成 Snapshot 时，是以 tidb_snapshot 变量的值作为版本号，如果 TiDB Server 所在机器和 PD Server 所在机器的本地时间相差较大，需要以 PD 的时间为准。
 当读取历史版本操作结束后，可以结束当前 Session 或者是通过 Set 语句将 tidb_snapshot 变量的值设为 &amp;ldquo;&amp;quot;，即可读取最新版本的数据。</description>
    </item>
    
    <item>
      <title>跨数据中心部署方案</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/geographic-redundancy/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/geographic-redundancy/overview/</guid>
      <description>跨数据中心部署方案 作为 NewSQL 数据库，TiDB 兼顾了传统关系型数据库的优秀特性以及 NoSQL 数据库可扩展性，以及跨数据中心（下文简称“中心”）场景下的高可用。本文档旨在介绍跨数据中心部署的不同解决方案。
三中心部署方案 TiDB, TiKV, PD 分别分布在 3 个不同的中心，这是最常规，可用性最高的方案。
优点 所有数据的副本分布在三个数据中心，任何一个数据中心失效后，另外两个数据中心会自动发起 leader election，并在合理长的时间内（通常情况 20s 以内）恢复服务，并且不会产生数据丢失。
缺点 性能受网络延迟影响。
 对于写入的场景，所有写入的数据需要同步复制到至少 2 个数据中心，由于 TiDB 写入过程使用两阶段提交，故写入延迟至少需要 2 倍数据中心间的延迟。 对于读请求来说，如果数据 leader 与发起读取的 TiDB 节点不在同一个数据中心，也会受网络延迟影响。 TiDB 中的每个事务都需要向 PD leader 获取 TSO，当 TiDB 与 PD leader 不在同一个数据中心时，它上面运行的事务也会因此受网络延迟影响，每个有写入的事务会获取两次 TSO。  读性能优化 如果不需要每个数据中心同时对外提供服务，可以将业务流量全部派发到一个数据中心，并通过调度策略把 Region leader 和 PD leader 都迁移到同一个数据中心（我们在上文所述的测试中也做了这个优化）。这样一来，不管是从 PD 获取 TSO 还是读取 Region 都不受数据中心间网络的影响。当该数据中心失效后，PD leader 和 Region leader 会自动在其它数据中心选出，只需要把业务流量转移至其他存活的数据中心即可。
两地三中心部署方案 两地三中心的方案与三数据中心类似，算是三机房方案根据业务特点进行的优化，区别是其中有两个数据中心距离很近（通常在同一个城市），网络延迟相对很小。这种场景下，我们可以把业务流量同时派发到同城的两个数据中心，同时控制 Region leader 和 PD leader 也分布在同城的两个数据中心。</description>
    </item>
    
    <item>
      <title>跳过 (skip) 或替代执行 (replace) 异常的 SQL 语句</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/skip-replace-sqls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tools/data-migration/skip-replace-sqls/</guid>
      <description>跳过 (skip) 或替代执行 (replace) 异常的 SQL 语句 本文介绍了如何使用 DM 来处理异常的 SQL 语句。
目前，TiDB 并不完全兼容所有的 MySQL 语法。当使用 DM 从 MySQL 同步数据到 TiDB 时，如果 TiDB 不支持对应的 SQL 语句，可能会造成错误并中断同步任务。在这种情况下，DM 提供以下两种方式来恢复同步：
  使用 dmctl 来手动跳过该 SQL 语句对应的 binlog event。
  使用 dmctl 来手动指定其他 SQL 语句来替代该 SQL 语句对应的 binlog event，并向下游执行。
  如果提前预知将要同步 TiDB 不支持的 SQL 语句，也可以使用 dmctl 来手动预设跳过/替代执行操作。当 DM 尝试将该 SQL 语句对应的 binlog event 同步到下游时，该预设的操作将自动执行，从而避免同步过程被中断。
使用限制   跳过/替代执行操作只适合用于一次性跳过/替代执行下游 TiDB 不支持执行的 SQL 语句，其它同步错误请不要使用此方式进行处理。</description>
    </item>
    
    <item>
      <title>连接器和 API</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/supported-clients/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/supported-clients/</guid>
      <description>连接器和 API 数据库连接器为客户端提供了连接数据库服务端的方式，APIs 提供了使用 MySQL 协议和资源的底层接口。无论是连接器还是 API，都可以用来在不同的语言和环境内连接服务器并执行 sql 语句，包括 odbc、java(jdbc)、Perl、Python、PHP、Ruby 和 C。
TiDB 兼容 MySQL(5.6、5.7) 的所有连接器和 API，包括：
 MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  使用 MySQL 连接器连接 TiDB Oracle 官方提供了以下 API，TiDB 可以兼容所有这些 API。
 MySQL Connector/C++：C++ 语言的客户端库 MySQL Connector/J：Java 语言的客户端库，基于标准 JDBC 接口 MySQL Connector/Net：.</description>
    </item>
    
    <item>
      <title>重启 Kubernetes 上的 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/restart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/restart/</guid>
      <description>了解如何重启 Kubernetes 集群上的 TiDB 集群。</description>
    </item>
    
    <item>
      <title>销毁 Kubernetes 上的 TiDB 集群</title>
      <link>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/destroy-tidb-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/tidb-in-kubernetes/maintain/destroy-tidb-cluster/</guid>
      <description>销毁 Kubernetes 上的 TiDB 集群 本文描述了如何销毁 Kubernetes 集群上的 TiDB 集群
要销毁 TiDB 集群，执行以下命令：
 helm delete &amp;lt;release-name&amp;gt; --purge 上述命令只是删除运行的 Pod，数据仍然会保留。如果你不再需要那些数据，可以通过下面命令清除数据：
 警告：
下列命令会彻底删除数据，务必考虑清楚再执行。
  kubectl delete pvc -n &amp;lt;namespace&amp;gt; -l app.kubernetes.io/instance=&amp;lt;release-name&amp;gt;,app.kubernetes.io/managed-by=tidb-operator  kubectl get pv -l app.kubernetes.io/namespace=&amp;lt;namespace&amp;gt;,app.kubernetes.io/managed-by=tidb-operator,app.kubernetes.io/instance=&amp;lt;release-name&amp;gt; -o name | xargs -I {} kubectl patch {} -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;persistentVolumeReclaimPolicy&amp;#34;:&amp;#34;Delete&amp;#34;}}&amp;#39; </description>
    </item>
    
    <item>
      <title>错误码与故障诊断</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/error-codes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/error-codes/</guid>
      <description>错误码与故障诊断 本篇文档描述在使用 TiDB 过程中会遇到的问题以及解决方法。
错误码 TiDB 兼容 MySQL 的错误码，在大多数情况下，返回和 MySQL 一样的错误码。另外还有一些特有的错误码：
   错误码 说明     8001 请求使用的内存超过 TiDB 内存使用的阈值限制   8002 带有 SELECT FOR UPDATE 语句的事务，在遇到写入冲突时，为保证一致性无法进行重试，事务将进行回滚并返回该错误   8003 ADMIN CHECK TABLE 命令在遇到行数据跟索引不一致的时候返回该错误   8004 单个事务过大，原因及解决方法请参考这里   8005 事务在 TiDB 中遇到了写入冲突，原因及解决方法请参考这里   9001 请求 PD 超时，请检查 PD Server 状态/监控/日志以及 TiDB Server 与 PD Server 之间的网络   9002 请求 TiKV 超时，请检查 TiKV Server 状态/监控/日志以及 TiDB Server 与 TiKV Server 之间的网络   9003 TiKV 操作繁忙，一般出现在数据库负载比较高时，请检查 TiKV Server 状态/监控/日志   9004 当数据库上承载的业务存在大量的事务冲突时，会遇到这种错误，请检查业务代码   9005 某个 Raft Group 不可用，如副本数目不足，出现在 TiKV 比较繁忙或者是 TiKV 节点停机的时候，请检查 TiKV Server 状态/监控/日志   9006 GC Life Time 间隔时间过短，长事务本应读到的数据可能被清理了，应增加 GC Life Time   9007 事务在 TiKV 中遇到了写入冲突，原因及解决方法请参考这里    故障诊断 参见故障诊断文档以及 FAQ。</description>
    </item>
    
    <item>
      <title>集群拓扑信息配置</title>
      <link>https://pingcap.com/docs-cn/v3.1/how-to/deploy/geographic-redundancy/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/how-to/deploy/geographic-redundancy/location-awareness/</guid>
      <description>集群拓扑信息配置 概述 PD 能够根据 TiKV 集群的拓扑结构进行调度，使得 TiKV 的容灾能力最大化。
阅读本章前，请先确保阅读 Ansible 部署方案 和 Docker 部署方案。
TiKV 上报拓扑信息 可以通过 TiKV 的启动参数或者配置文件来让 TiKV 上报拓扑信息给 PD。
假设拓扑结构分为三级：zone &amp;gt; rack &amp;gt; host，可以通过 labels 来指定这些信息。
启动参数：
tikv-server --labels zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt; 配置文件：
 [server] labels = &amp;#34;zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt;&amp;#34; PD 理解 TiKV 拓扑结构 可以通过 PD 的配置文件让 PD 理解 TiKV 集群的拓扑结构。
 [replication] max-replicas = 3 location-labels = [&amp;#34;zone&amp;#34;, &amp;#34;rack&amp;#34;, &amp;#34;host&amp;#34;] 其中 location-labels 需要与 TiKV 的 labels 名字对应，这样 PD 才能知道这些 labels 代表了 TiKV 的拓扑结构。</description>
    </item>
    
    <item>
      <title>集群间双向同步</title>
      <link>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/bi-repl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/v3.1/reference/tidb-binlog/bi-repl/</guid>
      <description>集群间双向同步 本文档介绍如何将一个 TiDB 集群的数据双向同步到另一个 TiDB 集群、双向同步的实现原理、如何开启双向同步、以及如何同步 DDL 操作。
使用场景 当用户需要在两个 TiDB 集群之间双向同步数据时，可使用 TiDB Binlog 进行操作。例如要将集群 A 的数据同步到集群 B，而且要将集群 B 的数据同步到集群 A。
 注意：
写入两个集群的数据无冲突，即不会在两个集群修改表的同一主键或者唯一索引的行。
 使用场景示例图如下：
实现原理 在 A 和 B 两个集群间开启双向同步，则写入集群 A 的数据会同步到集群 B 中，然后这部分数据又会继续同步到集群 A，这样就会出现无限循环同步的情况。如上图所示，在同步数据的过程中 Drainer 对 binlog 加上标记，通过过滤掉有标记的 binlog 来避免循环同步。详细的实现流程如下：
 为两个集群分别启动 TiDB Binlog 同步程序。 待同步的事务经过 A 的 Drainer 时，Drainer 为事务加入 _drainer_repl_mark 标识表，并在表中写入本次 DML event 更新，将事务同步至集群 B。 集群 B 向集群 A 返回带有 _drainer_repl_mark 标识表的 binlog event。集群 B 的 Drainer 在解析该 binlog event 时发现带有 DML event 的标识表，放弃同步该 binlog event 到集群 A。  将集群 B 中的数据同步到 集群 A 的流程与以上流程相同，两个集群可以互为上下游。</description>
    </item>
    
  </channel>
</rss>